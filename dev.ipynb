{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f018bf94",
   "metadata": {},
   "source": [
    "# Strava API Pipeline Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3426fd",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776f027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sqlite3\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Developer Docs\n",
    "# https://developers.strava.com/docs/getting-started/#basic\n",
    "\n",
    "# Streams API Details\n",
    "# https://developers.strava.com/docs/reference/#api-Streams-getActivityStreams\n",
    "\n",
    "# Replace with your actual credentials\n",
    "load_dotenv(dotenv_path=\"secrets.env\")\n",
    "CLIENT_ID = os.environ.get(\"CLIENT_ID\")\n",
    "CLIENT_SECRET = os.environ.get(\"CLIENT_SECRET\")\n",
    "REFRESH_TOKEN = os.environ.get(\"REFRESH_TOKEN\")\n",
    "\n",
    "DB_PATH = 'strava_data.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33d6a5",
   "metadata": {},
   "source": [
    "### Error Troubleshooting\n",
    "\n",
    "HTTP error occurred: 401 Client Error: Unauthorized for url: https://www.strava.com/api/v3/athlete/activities?page=1&per_page=1\n",
    "\n",
    "Go to this link, and note the scopes being used at the end of the URL - \n",
    "https://www.strava.com/oauth/authorize?client_id=64543&response_type=code&redirect_uri=http://localhost/exchange_token&approval_prompt=force&scope=profile:read_all,activity:read_all\n",
    "\n",
    "More details on scope here - https://developers.strava.com/docs/authentication/#detailsaboutrequestingaccess\n",
    "\n",
    "Extract the auth code from the reply URL and assign it using the below cell.\n",
    "\n",
    "Then, run the contents of the Code to Exchange Auth Code for Auth Token section to get a valid AUTH_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "75cd832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTH_CODE = \"b9ac405e2fa9214157b128942becabf9326b4c74\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fdbaa",
   "metadata": {},
   "source": [
    "## Refresh Auth Token\n",
    "### STill Figuring this one out\n",
    "#### The Auth Code input here should be the code extracted from the blank webpage after a user approves a scope request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1564587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old gemini code don't know if useful or not\n",
    "# This SHOULD work \n",
    "def refresh_access_token(client_id, client_secret, refresh_token):\n",
    "    \"\"\"Refreshes the access token using the refresh token.\"\"\"\n",
    "    response = requests.post(\n",
    "        url=\"https://www.strava.com/oauth/token\",\n",
    "        data={\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"grant_type\": \"refresh_token\",\n",
    "            \"refresh_token\": refresh_token,\n",
    "        },\n",
    "    )\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cd1c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84397cd47707a59cd9c93c559cc8900297a2edcf\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    AUTH_TOKEN = refresh_access_token(CLIENT_ID, CLIENT_SECRET, REFRESH_TOKEN)[\"access_token\"]\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    \n",
    "print(AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a8fed",
   "metadata": {},
   "source": [
    "## Get Auth Token\n",
    "#### The Auth Code input here should be the code extracted from the blank webpage after a user approves a scope request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61610c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth_token(client_id, client_secret, auth_code):\n",
    "    \"\"\"Refreshes the access token using the refresh token.\"\"\"\n",
    "    response = requests.post(\n",
    "        url=\"https://www.strava.com/oauth/token\",\n",
    "        data={\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"grant_type\": \"authorization_code\",\n",
    "            \"code\": auth_code,\n",
    "        },\n",
    "    )\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9cf232",
   "metadata": {},
   "source": [
    "#### Code to Exchange Auth Code for Auth Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7ff5a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc5596ec3eb974ce0036c9fdc228ecee00fbf12\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    AUTH_TOKEN = get_auth_token(CLIENT_ID, CLIENT_SECRET, AUTH_CODE)[\"access_token\"]\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    \n",
    "print(AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb74a0",
   "metadata": {},
   "source": [
    "## Base Functions for retreiving activities and timeseries data from Strava API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc673e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activities(access_token, page=1, per_page=30, **optional_parameters):\n",
    "    \"\"\"Retrieves activities from the Strava API.\n",
    "    Optional parameters should be provided at the end of the call like so:\n",
    "    before = epoch_timestamp, after = epoch_timestamp\n",
    "    \"\"\"\n",
    "    url = f\"https://www.strava.com/api/v3/athlete/activities\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    params = {\"page\": page, \"per_page\": per_page}\n",
    "    params.update(optional_parameters)\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_streams(access_token, keys, activity_id):\n",
    "    \"\"\"Retrieves activities from the Strava API.\"\"\"\n",
    "    url = f\"https://www.strava.com/api/v3/activities/\" + str(activity_id) + \"/streams\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    params = {\"keys\" : keys, \"key_by_type\": True}\n",
    "    # valid keys includes [\"time\", \"distance\", \"latlng\", \"altitude\", \"heartrate\", \"cadence\", \"watts\"]\n",
    "    # https://developers.strava.com/docs/reference/#api-models-StreamSet\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_gear(access_token, gear_id):\n",
    "    \"\"\"Retrieves activities from the Strava API.\"\"\"\n",
    "    url = f\"https://www.strava.com/api/v3/gear/\" + str(gear_id)\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    # params = {\"id\" : gear_id}\n",
    "    # valid keys includes [\"time\", \"distance\", \"latlng\", \"altitude\", \"heartrate\", \"cadence\", \"watts\"]\n",
    "    # https://developers.strava.com/docs/reference/#api-models-StreamSet\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d2c4f",
   "metadata": {},
   "source": [
    "## Base functions for storing data in db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd261b9",
   "metadata": {},
   "source": [
    "#### Initialize Activities Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735ef43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_database():\n",
    "    \"\"\"Create the SQLite database and full 'activities' table.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS activities (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        resource_state INTEGER,\n",
    "        athlete_id INTEGER,\n",
    "        athlete_resource_state INTEGER,\n",
    "        name TEXT,\n",
    "        distance REAL,\n",
    "        moving_time INTEGER,\n",
    "        elapsed_time INTEGER,\n",
    "        total_elevation_gain REAL,\n",
    "        type TEXT,\n",
    "        sport_type TEXT,\n",
    "        workout_type INTEGER,\n",
    "        start_date TEXT,\n",
    "        start_date_local TEXT,\n",
    "        timezone TEXT,\n",
    "        utc_offset REAL,\n",
    "        location_city TEXT,\n",
    "        location_state TEXT,\n",
    "        location_country TEXT,\n",
    "        achievement_count INTEGER,\n",
    "        kudos_count INTEGER,\n",
    "        comment_count INTEGER,\n",
    "        athlete_count INTEGER,\n",
    "        photo_count INTEGER,\n",
    "        map_id TEXT,\n",
    "        map_summary_polyline TEXT,\n",
    "        map_resource_state INTEGER,\n",
    "        trainer BOOLEAN,\n",
    "        commute BOOLEAN,\n",
    "        manual BOOLEAN,\n",
    "        private BOOLEAN,\n",
    "        visibility TEXT,\n",
    "        flagged BOOLEAN,\n",
    "        gear_id TEXT,\n",
    "        start_latlng TEXT,\n",
    "        end_latlng TEXT,\n",
    "        average_speed REAL,\n",
    "        max_speed REAL,\n",
    "        average_cadence REAL,\n",
    "        average_watts REAL,\n",
    "        max_watts INTEGER,\n",
    "        weighted_average_watts INTEGER,\n",
    "        device_watts BOOLEAN,\n",
    "        kilojoules REAL,\n",
    "        has_heartrate BOOLEAN,\n",
    "        average_heartrate REAL,\n",
    "        max_heartrate REAL,\n",
    "        heartrate_opt_out BOOLEAN,\n",
    "        display_hide_heartrate_option BOOLEAN,\n",
    "        elev_high REAL,\n",
    "        elev_low REAL,\n",
    "        upload_id INTEGER,\n",
    "        upload_id_str TEXT,\n",
    "        external_id TEXT,\n",
    "        from_accepted_tag BOOLEAN,\n",
    "        pr_count INTEGER,\n",
    "        total_photo_count INTEGER,\n",
    "        has_kudoed BOOLEAN,\n",
    "        import_date TEXT\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b2ad04",
   "metadata": {},
   "source": [
    "#### Activities Individual DB Entry Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecf442b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def insert_activities(activity_list):\n",
    "    \"\"\"Insert activity records, skipping those with duplicate 'id'.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    for activity in activity_list:\n",
    "        try:\n",
    "            c.execute('''\n",
    "            INSERT INTO activities VALUES (\n",
    "                :id, :resource_state, \n",
    "                :athlete_id, :athlete_resource_state,\n",
    "                :name, :distance, :moving_time, :elapsed_time, :total_elevation_gain,\n",
    "                :type, :sport_type, :workout_type, :start_date, :start_date_local,\n",
    "                :timezone, :utc_offset, :location_city, :location_state, :location_country,\n",
    "                :achievement_count, :kudos_count, :comment_count, :athlete_count, :photo_count,\n",
    "                :map_id, :map_summary_polyline, :map_resource_state,\n",
    "                :trainer, :commute, :manual, :private, :visibility, :flagged, :gear_id,\n",
    "                :start_latlng, :end_latlng,\n",
    "                :average_speed, :max_speed, :average_cadence, :average_watts,\n",
    "                :max_watts, :weighted_average_watts, :device_watts, :kilojoules,\n",
    "                :has_heartrate, :average_heartrate, :max_heartrate,\n",
    "                :heartrate_opt_out, :display_hide_heartrate_option,\n",
    "                :elev_high, :elev_low,\n",
    "                :upload_id, :upload_id_str, :external_id, :from_accepted_tag,\n",
    "                :pr_count, :total_photo_count, :has_kudoed, :import_date\n",
    "            )\n",
    "            ''', {\n",
    "                \"id\": activity[\"id\"],\n",
    "                \"resource_state\": activity.get(\"resource_state\"),\n",
    "                \"athlete_id\": activity.get(\"athlete\", {}).get(\"id\"),\n",
    "                \"athlete_resource_state\": activity.get(\"athlete\", {}).get(\"resource_state\"),\n",
    "                \"name\": activity.get(\"name\"),\n",
    "                \"distance\": activity.get(\"distance\"),\n",
    "                \"moving_time\": activity.get(\"moving_time\"),\n",
    "                \"elapsed_time\": activity.get(\"elapsed_time\"),\n",
    "                \"total_elevation_gain\": activity.get(\"total_elevation_gain\"),\n",
    "                \"type\": activity.get(\"type\"),\n",
    "                \"sport_type\": activity.get(\"sport_type\"),\n",
    "                \"workout_type\": activity.get(\"workout_type\"),\n",
    "                \"start_date\": activity.get(\"start_date\"),\n",
    "                \"start_date_local\": activity.get(\"start_date_local\"),\n",
    "                \"timezone\": activity.get(\"timezone\"),\n",
    "                \"utc_offset\": activity.get(\"utc_offset\"),\n",
    "                \"location_city\": activity.get(\"location_city\"),\n",
    "                \"location_state\": activity.get(\"location_state\"),\n",
    "                \"location_country\": activity.get(\"location_country\"),\n",
    "                \"achievement_count\": activity.get(\"achievement_count\"),\n",
    "                \"kudos_count\": activity.get(\"kudos_count\"),\n",
    "                \"comment_count\": activity.get(\"comment_count\"),\n",
    "                \"athlete_count\": activity.get(\"athlete_count\"),\n",
    "                \"photo_count\": activity.get(\"photo_count\"),\n",
    "                \"map_id\": activity.get(\"map\", {}).get(\"id\"),\n",
    "                \"map_summary_polyline\": activity.get(\"map\", {}).get(\"summary_polyline\"),\n",
    "                \"map_resource_state\": activity.get(\"map\", {}).get(\"resource_state\"),\n",
    "                \"trainer\": activity.get(\"trainer\"),\n",
    "                \"commute\": activity.get(\"commute\"),\n",
    "                \"manual\": activity.get(\"manual\"),\n",
    "                \"private\": activity.get(\"private\"),\n",
    "                \"visibility\": activity.get(\"visibility\"),\n",
    "                \"flagged\": activity.get(\"flagged\"),\n",
    "                \"gear_id\": activity.get(\"gear_id\"),\n",
    "                \"start_latlng\": json.dumps(activity.get(\"start_latlng\")),\n",
    "                \"end_latlng\": json.dumps(activity.get(\"end_latlng\")),\n",
    "                \"average_speed\": activity.get(\"average_speed\"),\n",
    "                \"max_speed\": activity.get(\"max_speed\"),\n",
    "                \"average_cadence\": activity.get(\"average_cadence\"),\n",
    "                \"average_watts\": activity.get(\"average_watts\"),\n",
    "                \"max_watts\": activity.get(\"max_watts\"),\n",
    "                \"weighted_average_watts\": activity.get(\"weighted_average_watts\"),\n",
    "                \"device_watts\": activity.get(\"device_watts\"),\n",
    "                \"kilojoules\": activity.get(\"kilojoules\"),\n",
    "                \"has_heartrate\": activity.get(\"has_heartrate\"),\n",
    "                \"average_heartrate\": activity.get(\"average_heartrate\"),\n",
    "                \"max_heartrate\": activity.get(\"max_heartrate\"),\n",
    "                \"heartrate_opt_out\": activity.get(\"heartrate_opt_out\"),\n",
    "                \"display_hide_heartrate_option\": activity.get(\"display_hide_heartrate_option\"),\n",
    "                \"elev_high\": activity.get(\"elev_high\"),\n",
    "                \"elev_low\": activity.get(\"elev_low\"),\n",
    "                \"upload_id\": activity.get(\"upload_id\"),\n",
    "                \"upload_id_str\": activity.get(\"upload_id_str\"),\n",
    "                \"external_id\": activity.get(\"external_id\"),\n",
    "                \"from_accepted_tag\": activity.get(\"from_accepted_tag\"),\n",
    "                \"pr_count\": activity.get(\"pr_count\"),\n",
    "                \"total_photo_count\": activity.get(\"total_photo_count\"),\n",
    "                \"has_kudoed\": activity.get(\"has_kudoed\"),\n",
    "                \"import_date\": datetime.now().isoformat()\n",
    "            })\n",
    "        except sqlite3.IntegrityError:\n",
    "            print(f\"Skipping duplicate activity with id {activity['id']}\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb127101",
   "metadata": {},
   "source": [
    "#### Activities Batch Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2732bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_activities_batch(activity_list):\n",
    "    \"\"\"Efficiently insert multiple activity records into the database.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    data = []\n",
    "    for activity in activity_list:\n",
    "        data.append({\n",
    "            \"id\": activity[\"id\"],\n",
    "            \"resource_state\": activity.get(\"resource_state\"),\n",
    "            \"athlete_id\": activity.get(\"athlete\", {}).get(\"id\"),\n",
    "            \"athlete_resource_state\": activity.get(\"athlete\", {}).get(\"resource_state\"),\n",
    "            \"name\": activity.get(\"name\"),\n",
    "            \"distance\": activity.get(\"distance\"),\n",
    "            \"moving_time\": activity.get(\"moving_time\"),\n",
    "            \"elapsed_time\": activity.get(\"elapsed_time\"),\n",
    "            \"total_elevation_gain\": activity.get(\"total_elevation_gain\"),\n",
    "            \"type\": activity.get(\"type\"),\n",
    "            \"sport_type\": activity.get(\"sport_type\"),\n",
    "            \"workout_type\": activity.get(\"workout_type\"),\n",
    "            \"start_date\": activity.get(\"start_date\"),\n",
    "            \"start_date_local\": activity.get(\"start_date_local\"),\n",
    "            \"timezone\": activity.get(\"timezone\"),\n",
    "            \"utc_offset\": activity.get(\"utc_offset\"),\n",
    "            \"location_city\": activity.get(\"location_city\"),\n",
    "            \"location_state\": activity.get(\"location_state\"),\n",
    "            \"location_country\": activity.get(\"location_country\"),\n",
    "            \"achievement_count\": activity.get(\"achievement_count\"),\n",
    "            \"kudos_count\": activity.get(\"kudos_count\"),\n",
    "            \"comment_count\": activity.get(\"comment_count\"),\n",
    "            \"athlete_count\": activity.get(\"athlete_count\"),\n",
    "            \"photo_count\": activity.get(\"photo_count\"),\n",
    "            \"map_id\": activity.get(\"map\", {}).get(\"id\"),\n",
    "            \"map_summary_polyline\": activity.get(\"map\", {}).get(\"summary_polyline\"),\n",
    "            \"map_resource_state\": activity.get(\"map\", {}).get(\"resource_state\"),\n",
    "            \"trainer\": activity.get(\"trainer\"),\n",
    "            \"commute\": activity.get(\"commute\"),\n",
    "            \"manual\": activity.get(\"manual\"),\n",
    "            \"private\": activity.get(\"private\"),\n",
    "            \"visibility\": activity.get(\"visibility\"),\n",
    "            \"flagged\": activity.get(\"flagged\"),\n",
    "            \"gear_id\": activity.get(\"gear_id\"),\n",
    "            \"start_latlng\": json.dumps(activity.get(\"start_latlng\")),\n",
    "            \"end_latlng\": json.dumps(activity.get(\"end_latlng\")),\n",
    "            \"average_speed\": activity.get(\"average_speed\"),\n",
    "            \"max_speed\": activity.get(\"max_speed\"),\n",
    "            \"average_cadence\": activity.get(\"average_cadence\"),\n",
    "            \"average_watts\": activity.get(\"average_watts\"),\n",
    "            \"max_watts\": activity.get(\"max_watts\"),\n",
    "            \"weighted_average_watts\": activity.get(\"weighted_average_watts\"),\n",
    "            \"device_watts\": activity.get(\"device_watts\"),\n",
    "            \"kilojoules\": activity.get(\"kilojoules\"),\n",
    "            \"has_heartrate\": activity.get(\"has_heartrate\"),\n",
    "            \"average_heartrate\": activity.get(\"average_heartrate\"),\n",
    "            \"max_heartrate\": activity.get(\"max_heartrate\"),\n",
    "            \"heartrate_opt_out\": activity.get(\"heartrate_opt_out\"),\n",
    "            \"display_hide_heartrate_option\": activity.get(\"display_hide_heartrate_option\"),\n",
    "            \"elev_high\": activity.get(\"elev_high\"),\n",
    "            \"elev_low\": activity.get(\"elev_low\"),\n",
    "            \"upload_id\": activity.get(\"upload_id\"),\n",
    "            \"upload_id_str\": activity.get(\"upload_id_str\"),\n",
    "            \"external_id\": activity.get(\"external_id\"),\n",
    "            \"from_accepted_tag\": activity.get(\"from_accepted_tag\"),\n",
    "            \"pr_count\": activity.get(\"pr_count\"),\n",
    "            \"total_photo_count\": activity.get(\"total_photo_count\"),\n",
    "            \"has_kudoed\": activity.get(\"has_kudoed\"),\n",
    "            \"import_date\": datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "    try:\n",
    "        c.executemany('''\n",
    "        INSERT OR IGNORE INTO activities VALUES (\n",
    "            :id, :resource_state, :athlete_id, :athlete_resource_state,\n",
    "            :name, :distance, :moving_time, :elapsed_time, :total_elevation_gain,\n",
    "            :type, :sport_type, :workout_type, :start_date, :start_date_local,\n",
    "            :timezone, :utc_offset, :location_city, :location_state, :location_country,\n",
    "            :achievement_count, :kudos_count, :comment_count, :athlete_count, :photo_count,\n",
    "            :map_id, :map_summary_polyline, :map_resource_state,\n",
    "            :trainer, :commute, :manual, :private, :visibility, :flagged, :gear_id,\n",
    "            :start_latlng, :end_latlng,\n",
    "            :average_speed, :max_speed, :average_cadence, :average_watts,\n",
    "            :max_watts, :weighted_average_watts, :device_watts, :kilojoules,\n",
    "            :has_heartrate, :average_heartrate, :max_heartrate,\n",
    "            :heartrate_opt_out, :display_hide_heartrate_option,\n",
    "            :elev_high, :elev_low,\n",
    "            :upload_id, :upload_id_str, :external_id, :from_accepted_tag,\n",
    "            :pr_count, :total_photo_count, :has_kudoed, :import_date\n",
    "        )\n",
    "        ''', data)\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error inserting batch:\", e)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c38a58a",
   "metadata": {},
   "source": [
    "#### Function to Rebuild single activity from flattened version in db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8b79298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_by_id(activity_id):\n",
    "    \"\"\"Retrieve a single activity and reconstruct its nested format.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\"SELECT * FROM activities WHERE id = ?\", (activity_id,))\n",
    "    row = c.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if row is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"id\": row[\"id\"],\n",
    "        \"resource_state\": row[\"resource_state\"],\n",
    "        \"athlete\": {\n",
    "            \"id\": row[\"athlete_id\"],\n",
    "            \"resource_state\": row[\"athlete_resource_state\"]\n",
    "        },\n",
    "        \"name\": row[\"name\"],\n",
    "        \"distance\": row[\"distance\"],\n",
    "        \"moving_time\": row[\"moving_time\"],\n",
    "        \"elapsed_time\": row[\"elapsed_time\"],\n",
    "        \"total_elevation_gain\": row[\"total_elevation_gain\"],\n",
    "        \"type\": row[\"type\"],\n",
    "        \"sport_type\": row[\"sport_type\"],\n",
    "        \"workout_type\": row[\"workout_type\"],\n",
    "        \"start_date\": row[\"start_date\"],\n",
    "        \"start_date_local\": row[\"start_date_local\"],\n",
    "        \"timezone\": row[\"timezone\"],\n",
    "        \"utc_offset\": row[\"utc_offset\"],\n",
    "        \"location_city\": row[\"location_city\"],\n",
    "        \"location_state\": row[\"location_state\"],\n",
    "        \"location_country\": row[\"location_country\"],\n",
    "        \"achievement_count\": row[\"achievement_count\"],\n",
    "        \"kudos_count\": row[\"kudos_count\"],\n",
    "        \"comment_count\": row[\"comment_count\"],\n",
    "        \"athlete_count\": row[\"athlete_count\"],\n",
    "        \"photo_count\": row[\"photo_count\"],\n",
    "        \"map\": {\n",
    "            \"id\": row[\"map_id\"],\n",
    "            \"summary_polyline\": row[\"map_summary_polyline\"],\n",
    "            \"resource_state\": row[\"map_resource_state\"]\n",
    "        },\n",
    "        \"trainer\": bool(row[\"trainer\"]),\n",
    "        \"commute\": bool(row[\"commute\"]),\n",
    "        \"manual\": bool(row[\"manual\"]),\n",
    "        \"private\": bool(row[\"private\"]),\n",
    "        \"visibility\": row[\"visibility\"],\n",
    "        \"flagged\": bool(row[\"flagged\"]),\n",
    "        \"gear_id\": row[\"gear_id\"],\n",
    "        \"start_latlng\": json.loads(row[\"start_latlng\"]),\n",
    "        \"end_latlng\": json.loads(row[\"end_latlng\"]),\n",
    "        \"average_speed\": row[\"average_speed\"],\n",
    "        \"max_speed\": row[\"max_speed\"],\n",
    "        \"average_cadence\": row[\"average_cadence\"],\n",
    "        \"average_watts\": row[\"average_watts\"],\n",
    "        \"max_watts\": row[\"max_watts\"],\n",
    "        \"weighted_average_watts\": row[\"weighted_average_watts\"],\n",
    "        \"device_watts\": bool(row[\"device_watts\"]),\n",
    "        \"kilojoules\": row[\"kilojoules\"],\n",
    "        \"has_heartrate\": bool(row[\"has_heartrate\"]),\n",
    "        \"average_heartrate\": row[\"average_heartrate\"],\n",
    "        \"max_heartrate\": row[\"max_heartrate\"],\n",
    "        \"heartrate_opt_out\": bool(row[\"heartrate_opt_out\"]),\n",
    "        \"display_hide_heartrate_option\": bool(row[\"display_hide_heartrate_option\"]),\n",
    "        \"elev_high\": row[\"elev_high\"],\n",
    "        \"elev_low\": row[\"elev_low\"],\n",
    "        \"upload_id\": row[\"upload_id\"],\n",
    "        \"upload_id_str\": row[\"upload_id_str\"],\n",
    "        \"external_id\": row[\"external_id\"],\n",
    "        \"from_accepted_tag\": bool(row[\"from_accepted_tag\"]),\n",
    "        \"pr_count\": row[\"pr_count\"],\n",
    "        \"total_photo_count\": row[\"total_photo_count\"],\n",
    "        \"has_kudoed\": bool(row[\"has_kudoed\"])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca75d58",
   "metadata": {},
   "source": [
    "#### Simple Query to get records loaded during current day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c64ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_activities_imported_today(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM activities \n",
    "        WHERE substr(import_date, 1, 10) = ?\n",
    "    \"\"\", (today_str,))\n",
    "    \n",
    "    count = c.fetchone()[0]\n",
    "    conn.close()\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9807a38d",
   "metadata": {},
   "source": [
    "#### Simple Query to Latest record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ff92056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_activity_imported(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT * \n",
    "        FROM activities \n",
    "        WHERE import_date = \n",
    "        (select max(import_date) from activities)\n",
    "    \"\"\")\n",
    "    \n",
    "    record = c.fetchone()\n",
    "    conn.close()\n",
    "    return record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c90103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple Query to get Gear Id from Latest Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "04529122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_gear_ids(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT distinct gear_id \n",
    "        FROM activities \n",
    "    \"\"\")\n",
    "    \n",
    "    record = c.fetchone()\n",
    "    conn.close()\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d36ce",
   "metadata": {},
   "source": [
    "#### Simple Query to Get Specific record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fee55d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_data_all(db_path, activity_id):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Run query and load into DataFrame (with column headers)\n",
    "    df = pd.read_sql_query(\n",
    "        \"SELECT * FROM activities WHERE id = ?\",\n",
    "        conn,\n",
    "        params=(activity_id,)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d568f71",
   "metadata": {},
   "source": [
    "#### Simple Query to get all Activity IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13e15b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_activity_ids(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT id\n",
    "        FROM activities \n",
    "        order by start_date desc\n",
    "              \"\"\")\n",
    "    \n",
    "    count = c.fetchall()\n",
    "    conn.close()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa82278",
   "metadata": {},
   "source": [
    "#### Simple Query to get all Activity IDs with HR and presumably Streams data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "633dd597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_activity_ids_with_HR(db_path):\n",
    "    \"\"\"Get all activity ids that have HR data, which hopefully will help us avoid a 404 call on the streams data.\n",
    "    My thinking is that if no HR data, we probably have no streams data at all.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT id\n",
    "        FROM activities \n",
    "        WHERE has_heartrate = 1\n",
    "        order by start_date desc\n",
    "              \"\"\")\n",
    "    \n",
    "    count = c.fetchall()\n",
    "    conn.close()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b6bcb",
   "metadata": {},
   "source": [
    "## Database Streams Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830ece9",
   "metadata": {},
   "source": [
    "#### Initialize DB  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b271fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_streams_db():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS streams (\n",
    "        activity_id INTEGER PRIMARY KEY,\n",
    "        \n",
    "        time_data TEXT,\n",
    "        time_series_type TEXT,\n",
    "        time_original_size INTEGER,\n",
    "        time_resolution TEXT,\n",
    "\n",
    "        distance_data TEXT,\n",
    "        distance_series_type TEXT,\n",
    "        distance_original_size INTEGER,\n",
    "        distance_resolution TEXT,\n",
    "\n",
    "        latlng_data TEXT,\n",
    "        latlng_series_type TEXT,\n",
    "        latlng_original_size INTEGER,\n",
    "        latlng_resolution TEXT,\n",
    "\n",
    "        altitude_data TEXT,\n",
    "        altitude_series_type TEXT,\n",
    "        altitude_original_size INTEGER,\n",
    "        altitude_resolution TEXT,\n",
    "\n",
    "        velocity_smooth_data TEXT,\n",
    "        velocity_smooth_series_type TEXT,\n",
    "        velocity_smooth_original_size INTEGER,\n",
    "        velocity_smooth_resolution TEXT,\n",
    "\n",
    "        heartrate_data TEXT,\n",
    "        heartrate_series_type TEXT,\n",
    "        heartrate_original_size INTEGER,\n",
    "        heartrate_resolution TEXT,\n",
    "\n",
    "        cadence_data TEXT,\n",
    "        cadence_series_type TEXT,\n",
    "        cadence_original_size INTEGER,\n",
    "        cadence_resolution TEXT,\n",
    "\n",
    "        watts_data TEXT,\n",
    "        watts_series_type TEXT,\n",
    "        watts_original_size INTEGER,\n",
    "        watts_resolution TEXT,\n",
    "\n",
    "        moving_data TEXT,\n",
    "        moving_series_type TEXT,\n",
    "        moving_original_size INTEGER,\n",
    "        moving_resolution TEXT,\n",
    "\n",
    "        grade_smooth_data TEXT,\n",
    "        grade_smooth_series_type TEXT,\n",
    "        grade_smooth_original_size INTEGER,\n",
    "        grade_smooth_resolution TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3edeb1",
   "metadata": {},
   "source": [
    "#### Insert Stream Data for Single Activity ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dc06439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_stream_data(activity_id, stream_dict):\n",
    "    \"\"\"\n",
    "    Inserts or replaces a row in the streams table for a given activity_id.\n",
    "    stream_dict should have keys like 'time', 'distance', etc., with each value a dict containing:\n",
    "    {\n",
    "        'data': [...],\n",
    "        'series_type': '...',\n",
    "        'original_size': ...,\n",
    "        'resolution': '...'\n",
    "    }\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Create the column mappings dynamically\n",
    "    base_columns = []\n",
    "    placeholders = []\n",
    "    values = []\n",
    "\n",
    "    # Always include activity_id\n",
    "    base_columns.append(\"activity_id\")\n",
    "    placeholders.append(\"?\")\n",
    "    values.append(activity_id)\n",
    "\n",
    "    for key, val in stream_dict.items():\n",
    "        if not isinstance(val, dict):\n",
    "            continue  # skip malformed\n",
    "\n",
    "        base_columns.extend([\n",
    "            f\"{key}_data\",\n",
    "            f\"{key}_series_type\",\n",
    "            f\"{key}_original_size\",\n",
    "            f\"{key}_resolution\"\n",
    "        ])\n",
    "        placeholders.extend([\"?\"] * 4)\n",
    "\n",
    "        values.extend([\n",
    "            json.dumps(val.get(\"data\")),\n",
    "            val.get(\"series_type\"),\n",
    "            val.get(\"original_size\"),\n",
    "            val.get(\"resolution\")\n",
    "        ])\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        INSERT INTO streams ({', '.join(base_columns)})\n",
    "        VALUES ({', '.join(placeholders)})\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    try:\n",
    "        c.execute(sql, values)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    except sqlite3.IntegrityError:\n",
    "        print(f\"Activity {activity_id} already exists in the 'streams' table. Skipping insert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2685191d",
   "metadata": {},
   "source": [
    "#### Simple Query to Get all activity IDs from Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5fe5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_activity_ids_streams(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT activity_id\n",
    "        FROM streams \n",
    "              \"\"\")\n",
    "    \n",
    "    count = c.fetchall()\n",
    "    conn.close()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f4a4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Simple Query to Get all Streams for latest activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aee83f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_stream_example(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    # Run query and load into DataFrame (with column headers)\n",
    "    df = pd.read_sql_query(\n",
    "        \"\"\"\n",
    "        SELECT * \n",
    "        FROM streams \n",
    "        ORDER BY activity_id desc\n",
    "        limit 1\n",
    "    \"\"\",\n",
    "        conn\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ae79ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>time_data</th>\n",
       "      <th>time_series_type</th>\n",
       "      <th>time_original_size</th>\n",
       "      <th>time_resolution</th>\n",
       "      <th>distance_data</th>\n",
       "      <th>distance_series_type</th>\n",
       "      <th>distance_original_size</th>\n",
       "      <th>distance_resolution</th>\n",
       "      <th>latlng_data</th>\n",
       "      <th>latlng_series_type</th>\n",
       "      <th>latlng_original_size</th>\n",
       "      <th>latlng_resolution</th>\n",
       "      <th>altitude_data</th>\n",
       "      <th>altitude_series_type</th>\n",
       "      <th>altitude_original_size</th>\n",
       "      <th>altitude_resolution</th>\n",
       "      <th>velocity_smooth_data</th>\n",
       "      <th>velocity_smooth_series_type</th>\n",
       "      <th>velocity_smooth_original_size</th>\n",
       "      <th>velocity_smooth_resolution</th>\n",
       "      <th>heartrate_data</th>\n",
       "      <th>heartrate_series_type</th>\n",
       "      <th>heartrate_original_size</th>\n",
       "      <th>heartrate_resolution</th>\n",
       "      <th>cadence_data</th>\n",
       "      <th>cadence_series_type</th>\n",
       "      <th>cadence_original_size</th>\n",
       "      <th>cadence_resolution</th>\n",
       "      <th>watts_data</th>\n",
       "      <th>watts_series_type</th>\n",
       "      <th>watts_original_size</th>\n",
       "      <th>watts_resolution</th>\n",
       "      <th>moving_data</th>\n",
       "      <th>moving_series_type</th>\n",
       "      <th>moving_original_size</th>\n",
       "      <th>moving_resolution</th>\n",
       "      <th>grade_smooth_data</th>\n",
       "      <th>grade_smooth_series_type</th>\n",
       "      <th>grade_smooth_original_size</th>\n",
       "      <th>grade_smooth_resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14393650080</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>distance</td>\n",
       "      <td>3049</td>\n",
       "      <td>high</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0...</td>\n",
       "      <td>distance</td>\n",
       "      <td>3049</td>\n",
       "      <td>high</td>\n",
       "      <td>[[44.949551, -93.324906], [44.949551, -93.3249...</td>\n",
       "      <td>distance</td>\n",
       "      <td>3049</td>\n",
       "      <td>high</td>\n",
       "      <td>[278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278...</td>\n",
       "      <td>distance</td>\n",
       "      <td>3049</td>\n",
       "      <td>high</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.667, 1.0, 1.2, 1.6, 2.0, 2.0...</td>\n",
       "      <td>distance</td>\n",
       "      <td>3049</td>\n",
       "      <td>high</td>\n",
       "      <td>[61, 61, 61, 61, 61, 61, 62, 63, 63, 63, 63, 6...</td>\n",
       "      <td>distance</td>\n",
       "      <td>3049</td>\n",
       "      <td>high</td>\n",
       "      <td>[86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 8...</td>\n",
       "      <td>distance</td>\n",
       "      <td>3049</td>\n",
       "      <td>high</td>\n",
       "      <td>[null, null, null, null, null, null, null, nul...</td>\n",
       "      <td>distance</td>\n",
       "      <td>3049</td>\n",
       "      <td>high</td>\n",
       "      <td>[false, false, false, true, true, true, true, ...</td>\n",
       "      <td>distance</td>\n",
       "      <td>3049</td>\n",
       "      <td>high</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>distance</td>\n",
       "      <td>3049</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_id                                          time_data  \\\n",
       "0  14393650080  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "  time_series_type  time_original_size time_resolution  \\\n",
       "0         distance                3049            high   \n",
       "\n",
       "                                       distance_data distance_series_type  \\\n",
       "0  [0.0, 0.0, 0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0...             distance   \n",
       "\n",
       "   distance_original_size distance_resolution  \\\n",
       "0                    3049                high   \n",
       "\n",
       "                                         latlng_data latlng_series_type  \\\n",
       "0  [[44.949551, -93.324906], [44.949551, -93.3249...           distance   \n",
       "\n",
       "   latlng_original_size latlng_resolution  \\\n",
       "0                  3049              high   \n",
       "\n",
       "                                       altitude_data altitude_series_type  \\\n",
       "0  [278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278...             distance   \n",
       "\n",
       "   altitude_original_size altitude_resolution  \\\n",
       "0                    3049                high   \n",
       "\n",
       "                                velocity_smooth_data  \\\n",
       "0  [0.0, 0.0, 0.0, 0.667, 1.0, 1.2, 1.6, 2.0, 2.0...   \n",
       "\n",
       "  velocity_smooth_series_type  velocity_smooth_original_size  \\\n",
       "0                    distance                           3049   \n",
       "\n",
       "  velocity_smooth_resolution  \\\n",
       "0                       high   \n",
       "\n",
       "                                      heartrate_data heartrate_series_type  \\\n",
       "0  [61, 61, 61, 61, 61, 61, 62, 63, 63, 63, 63, 6...              distance   \n",
       "\n",
       "   heartrate_original_size heartrate_resolution  \\\n",
       "0                     3049                 high   \n",
       "\n",
       "                                        cadence_data cadence_series_type  \\\n",
       "0  [86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 8...            distance   \n",
       "\n",
       "   cadence_original_size cadence_resolution  \\\n",
       "0                   3049               high   \n",
       "\n",
       "                                          watts_data watts_series_type  \\\n",
       "0  [null, null, null, null, null, null, null, nul...          distance   \n",
       "\n",
       "   watts_original_size watts_resolution  \\\n",
       "0                 3049             high   \n",
       "\n",
       "                                         moving_data moving_series_type  \\\n",
       "0  [false, false, false, true, true, true, true, ...           distance   \n",
       "\n",
       "   moving_original_size moving_resolution  \\\n",
       "0                  3049              high   \n",
       "\n",
       "                                   grade_smooth_data grade_smooth_series_type  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                 distance   \n",
       "\n",
       "   grade_smooth_original_size grade_smooth_resolution  \n",
       "0                        3049                    high  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = single_stream_example(DB_PATH)\n",
    "test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca1d93d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17184"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.time_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e33d9b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15197"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.heartrate_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8c03c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streams_data(activity_id, db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT distance_data, heartrate_data, altitude_data FROM streams WHERE activity_id = ?\", (activity_id,))\n",
    "    row = cur.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if row:\n",
    "        try:\n",
    "            distance = json.loads(row[0]) if row[0] else []\n",
    "            heartrate = json.loads(row[1]) if row[1] else []\n",
    "            altitude = json.loads(row[2]) if row[2] else []\n",
    "            return distance, heartrate, altitude\n",
    "        except Exception as e:\n",
    "            print(\"Failed to load stream data:\", e)\n",
    "    return [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bf8ef13f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such column: id",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m z = \u001b[43mget_streams_data\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m14414666612\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDB_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mget_streams_data\u001b[39m\u001b[34m(activity_id, db_path)\u001b[39m\n\u001b[32m      2\u001b[39m conn = sqlite3.connect(db_path)\n\u001b[32m      3\u001b[39m cur = conn.cursor()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSELECT distance_data, heartrate_data, altitude_data FROM streams WHERE id = ?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivity_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m row = cur.fetchone()\n\u001b[32m      6\u001b[39m conn.close()\n",
      "\u001b[31mOperationalError\u001b[39m: no such column: id"
     ]
    }
   ],
   "source": [
    "z = get_streams_data(14414666612, DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "da0a4625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [], [])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2bad1",
   "metadata": {},
   "source": [
    "## Database Gear Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af5449",
   "metadata": {},
   "source": [
    "#### Initialize Gear Table  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0070c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_gear_db():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS gear (\n",
    "        gear_id TEXT PRIMARY KEY,\n",
    "        is_primary BOOLEAN,\n",
    "        resource_state INTEGER,\n",
    "        distance INTEGER,\n",
    "        brand_name TEXT,\n",
    "        model_name TEXT,      \n",
    "        frame_type INTEGER,\n",
    "        description TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf6ab3",
   "metadata": {},
   "source": [
    "#### Insert Single Gear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "293b0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def insert_single_gear(gear):\n",
    "    \"\"\"Insert activity records, skipping those with duplicate 'id'.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "    try:\n",
    "        c.execute('''\n",
    "        INSERT OR REPLACE INTO gear VALUES (\n",
    "            :gear_id, :is_primary, \n",
    "            :resource_state, :distance,\n",
    "            :brand_name, :model_name, :frame_type, :description\n",
    "                  )\n",
    "        ''', {\n",
    "            \"gear_id\": gear[\"id\"],\n",
    "            \"is_primary\": gear.get(\"primary\"),\n",
    "            \"resource_state\": gear.get(\"resource_state\"),\n",
    "            \"distance\": gear.get(\"distance\"),\n",
    "            \"brand_name\": gear.get(\"brand_name\"),\n",
    "            \"model_name\": gear.get(\"model_name\"),\n",
    "            \"frame_type\": gear.get(\"frame_type\"),\n",
    "            \"description\": gear.get(\"description\"),\n",
    "            \"import_date\": datetime.now().isoformat()\n",
    "        })\n",
    "    except sqlite3.IntegrityError:\n",
    "        print(f\"Skipping duplicate activity with id {gear['id']}\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35414d6c",
   "metadata": {},
   "source": [
    "## Get Latest Activity and Associated Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7d71f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity ID: 14404286770, Name: Morning Run, Type: Run\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    activities = []\n",
    "    streams = []\n",
    "    page = 1\n",
    "    per_page = 1\n",
    "    while True:\n",
    "        activities_page = get_activities(AUTH_TOKEN, page=page, per_page=per_page)\n",
    "        if not activities_page:\n",
    "            break\n",
    "        activities.extend(activities_page)\n",
    "        page += 1\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "        break\n",
    "\n",
    "    # Process the activity data\n",
    "    for activity in activities:\n",
    "        print(f\"Activity ID: {activity['id']}, Name: {activity['name']}, Type: {activity['type']}\")\n",
    "\n",
    "    keys = [\"time\", \"distance\", \"latlng\", \"altitude\", \"heartrate\", \"cadence\", \"watts\"]\n",
    "    keys = \"time, latlng\"\n",
    "    # Process stream data\n",
    "    for a in activities:\n",
    "        stream = get_streams(AUTH_TOKEN, keys, a['id'])\n",
    "        if not stream:\n",
    "            break\n",
    "        streams.extend(stream)\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "        break\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b705f",
   "metadata": {},
   "source": [
    "## Bulk Historical Processing of Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f83cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting point, build unix timestamps in 6 month batches\n",
    "\n",
    "# time_0 = time.mktime(datetime.datetime(2019, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_1 = time.mktime(datetime.datetime(2019, 7, 1, 0, 0, 0).timetuple()) \n",
    "# time_2 = time.mktime(datetime.datetime(2020, 1, 1, 0, 0, 0).timetuple()) \n",
    "# time_3 = time.mktime(datetime.datetime(2020, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_4 = time.mktime(datetime.datetime(2021, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_5 = time.mktime(datetime.datetime(2021, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_6 = time.mktime(datetime.datetime(2022, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_7 = time.mktime(datetime.datetime(2022, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_8 = time.mktime(datetime.datetime(2023, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_9 = time.mktime(datetime.datetime(2023, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_10 = time.mktime(datetime.datetime(2024, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_11 = time.mktime(datetime.datetime(2024, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_12 = time.mktime(datetime.datetime(2025, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_13 = time.mktime(datetime.datetime(2025, 7, 1, 0, 0, 0).timetuple())\n",
    "\n",
    "day_by_day_before = time.mktime(datetime(2025, 5, 10, 0, 0, 0).timetuple())\n",
    "day_by_day_after = time.mktime(datetime(2025, 5, 9, 0, 0, 0).timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3248bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1 activities were imported so far.\n",
      "1 activities were imported so far today\n",
      "2 activities were imported from the API this round.\n"
     ]
    }
   ],
   "source": [
    "# ensure db table exists\n",
    "initialize_database()\n",
    "\n",
    "# Get the data\n",
    "try:\n",
    "    activities = []\n",
    "    page = 1\n",
    "    per_page = 30\n",
    "    while True:\n",
    "        activities_page = get_activities(AUTH_TOKEN, page=page, per_page=per_page, before = day_by_day_before, after = day_by_day_after) # currently done, latest after time was time_12\n",
    "        if not activities_page:\n",
    "            break\n",
    "        print(len(activities_page)) # expect 30 each time unless final page\n",
    "        activities.extend(activities_page)\n",
    "        \n",
    "        insert_activities_batch(activities_page) # attempt to bulk write to db\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "\n",
    "        num_today = count_activities_imported_today(DB_PATH) # count objects in db now\n",
    "        print(f\"{num_today} activities were imported so far.\")\n",
    "\n",
    "        page += 1\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "        if page > 50:\n",
    "            break\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "num_today = count_activities_imported_today(DB_PATH)\n",
    "print(f\"{num_today} activities were imported so far today\")\n",
    "print(f\"{len(activities)} activities were imported from the API this round.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17807bb1",
   "metadata": {},
   "source": [
    "## Bulk Historical Processing of Data Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46f95e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DB\n",
    "initialize_streams_db()\n",
    "\n",
    "# get all stream activity IDs\n",
    "stream_activity_ids = get_all_activity_ids_streams(\"strava_data.db\")\n",
    "stream_activity_ids = set(i[0] for i in stream_activity_ids)\n",
    "\n",
    "# get all activity ID's in db sorted by activity date desc as set\n",
    "sorted_activity_list = get_all_activity_ids_with_HR(\"strava_data.db\")\n",
    "sorted_activity_list = set(i[0] for i in sorted_activity_list)\n",
    "\n",
    "# Take the \n",
    "valid_activity_ids = tuple(sorted_activity_list - stream_activity_ids)\n",
    "\n",
    "keys = \"time,distance,latlng,altitude,velocity_smooth,heartrate,cadence,watts,temp,moving,grade_smooth\"\n",
    "\n",
    "for i, activity_integer in enumerate(valid_activity_ids):\n",
    "    \n",
    "    try:\n",
    "        stream = get_streams(AUTH_TOKEN, keys, activity_integer)\n",
    "        if not stream:\n",
    "            print('no stream')\n",
    "            continue\n",
    "    \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error occurred: {e}\")\n",
    "        if \"429\" in str(e):\n",
    "            print(\"RATE LIMITED!!!\")\n",
    "            break\n",
    "        if \"404\" in str(e):\n",
    "            print(\"Stream data unavailable for activity\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "    insert_stream_data(activity_integer, stream)\n",
    "    time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "    if i > 98:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7b90233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2033 streams in the db.\n",
      "2746 valid activities with potential streams data exist in the db.\n",
      "713 to go!\n"
     ]
    }
   ],
   "source": [
    "num_today = count_activities_imported_today(DB_PATH)\n",
    "print(f\"{len(get_all_activity_ids_streams(\"strava_data.db\"))} streams in the db.\")\n",
    "print(f\"{len(get_all_activity_ids_with_HR(\"strava_data.db\"))} valid activities with potential streams data exist in the db.\")\n",
    "print(f\"{len(get_all_activity_ids_with_HR(\"strava_data.db\")) - len(get_all_activity_ids_streams(\"strava_data.db\"))} to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7738b0",
   "metadata": {},
   "source": [
    "## Gear Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "035385ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('b5036222',)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the DB\n",
    "initialize_gear_db()\n",
    "\n",
    "shoe_id = get_all_gear_ids(DB_PATH)\n",
    "shoe_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "54c9b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe = get_gear(AUTH_TOKEN, \"b6893678\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8fdfa495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'g15302697',\n",
       " 'primary': False,\n",
       " 'name': 'New Balance Vongo v5 ',\n",
       " 'nickname': '',\n",
       " 'resource_state': 3,\n",
       " 'retired': False,\n",
       " 'distance': 1076704,\n",
       " 'converted_distance': 669.0,\n",
       " 'brand_name': 'New Balance',\n",
       " 'model_name': 'Vongo v5',\n",
       " 'description': None,\n",
       " 'notification_distance': 450}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "849d8cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_single_gear(shoe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
