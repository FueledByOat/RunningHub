{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f018bf94",
   "metadata": {},
   "source": [
    "# Strava API Pipeline Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3426fd",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "776f027f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sqlite3\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Developer Docs\n",
    "# https://developers.strava.com/docs/getting-started/#basic\n",
    "\n",
    "# Streams API Details\n",
    "# https://developers.strava.com/docs/reference/#api-Streams-getActivityStreams\n",
    "\n",
    "# Replace with your actual credentials\n",
    "load_dotenv(dotenv_path=\"secrets.env\")\n",
    "CLIENT_ID = os.environ.get(\"CLIENT_ID\")\n",
    "CLIENT_SECRET = os.environ.get(\"CLIENT_SECRET\")\n",
    "REFRESH_TOKEN = os.environ.get(\"REFRESH_TOKEN\")\n",
    "\n",
    "DB_PATH = 'strava_data.db'\n",
    "\n",
    "load_dotenv(dotenv_path=\"secrets.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4380f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = 'strava_data.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed418c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64543\n"
     ]
    }
   ],
   "source": [
    "print(CLIENT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33d6a5",
   "metadata": {},
   "source": [
    "### Error Troubleshooting\n",
    "\n",
    "HTTP error occurred: 401 Client Error: Unauthorized for url: https://www.strava.com/api/v3/athlete/activities?page=1&per_page=1\n",
    "\n",
    "Go to this link, and note the scopes being used at the end of the URL - \n",
    "https://www.strava.com/oauth/authorize?client_id=64543&response_type=code&redirect_uri=http://localhost/exchange_token&approval_prompt=force&scope=profile:read_all,activity:read_all\n",
    "\n",
    "More details on scope here - https://developers.strava.com/docs/authentication/#detailsaboutrequestingaccess\n",
    "\n",
    "Extract the auth code from the reply URL and assign it using the below cell.\n",
    "\n",
    "Then, run the contents of the Code to Exchange Auth Code for Auth Token section to get a valid AUTH_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75cd832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTH_CODE = \"0aef51cf61cce5e491d11a2528b4aaa30f9756ca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb921b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0aef51cf61cce5e491d11a2528b4aaa30f9756ca\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(dotenv_path=\"secrets.env\", override=True)\n",
    "print(os.environ.get(\"AUTH_CODE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b03a59",
   "metadata": {},
   "source": [
    "## How this SHOULD work\n",
    "\n",
    "Go to this link, and note the scopes being used at the end of the URL - \n",
    "https://www.strava.com/oauth/authorize?client_id=64543&response_type=code&redirect_uri=http://localhost/exchange_token&approval_prompt=force&scope=profile:read_all,activity:read_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eddf280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTH_CODE = 'cf2cfc3a2fda1c8b9f2d6ed48623175047d3ea29'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbf44d2",
   "metadata": {},
   "source": [
    "The auth code provides the initial access and scope to the app's athletes but is not used for queries.\n",
    "\n",
    "That AUTH CODE should then be used below to exchange for a short lived (6 hours?) ACCESS TOKEN\n",
    "\n",
    "We will also store the replied REFRESH_TOKEN in the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f53c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5d4dc1fd084e0994631899facefef89478de90d3\n",
      "{'token_type': 'Bearer', 'expires_at': 1747337695, 'expires_in': 21600, 'refresh_token': '5d4dc1fd084e0994631899facefef89478de90d3', 'access_token': '46f0c8973ef94a38944485aa0ff048fe093c84bf', 'athlete': {'id': 24266563, 'username': 'smithcharlie', 'resource_state': 2, 'firstname': 'Charlie', 'lastname': 'Smith ðŸ¦š', 'bio': '', 'city': 'Minneapolis', 'state': 'MN', 'country': 'United States', 'sex': 'M', 'premium': False, 'summit': False, 'created_at': '2017-08-17T15:31:27Z', 'updated_at': '2025-04-19T18:19:00Z', 'badge_type_id': 0, 'weight': 63.5029, 'profile_medium': 'https://dgalywyr863hv.cloudfront.net/pictures/athletes/24266563/11743602/9/medium.jpg', 'profile': 'https://dgalywyr863hv.cloudfront.net/pictures/athletes/24266563/11743602/9/large.jpg', 'friend': None, 'follower': None}}\n",
      "5d4dc1fd084e0994631899facefef89478de90d3\n"
     ]
    }
   ],
   "source": [
    "def get_auth_token(client_id, client_secret, auth_code):\n",
    "    \"\"\"Refreshes the access token using the refresh token.\"\"\"\n",
    "    response = requests.post(\n",
    "        url=\"https://www.strava.com/oauth/token\",\n",
    "        data={\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"grant_type\": \"authorization_code\",\n",
    "            \"code\": auth_code,\n",
    "        },\n",
    "    )\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    return response.json()\n",
    "\n",
    "try:\n",
    "    access_token_request = get_auth_token(CLIENT_ID, CLIENT_SECRET, AUTH_CODE)\n",
    "    ACCESS_TOKEN = access_token_request[\"access_token\"]\n",
    "    os.environ[\"REFRESH_TOKEN\"] = access_token_request[\"refresh_token\"]\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    \n",
    "print(os.environ.get(\"REFRESH_TOKEN\"))\n",
    "print(access_token_request)\n",
    "print(os.environ.get(\"REFRESH_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1174ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ACCESS_TOKEN\"] = ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490e752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASDFASDASDFADFDFA\n"
     ]
    }
   ],
   "source": [
    "print(ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f34ae21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS_TOKEN\n"
     ]
    }
   ],
   "source": [
    "import utils.strava_utils as strava_utils\n",
    "ACCESS_TOKEN = \"c3f5b56134d8a3b061cc58ee0ae47571b61a5f93\"\n",
    "strava_utils.update_env_variable(\"ACCESS_TOKEN\", ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae05a3",
   "metadata": {},
   "source": [
    "THEN once that ACCESS TOKEN expires, we can try to exchange for a new one using the refresh code we were provided and the below code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fdbaa",
   "metadata": {},
   "source": [
    "## Refresh Auth Token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0acd62",
   "metadata": {},
   "source": [
    "The manual cell below is necessary because the key from the prior process is stored in an environment variable. This should work for the airflow approach but will need to be copied manually when running local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e2e4638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5d4dc1fd084e0994631899facefef89478de90d3\n"
     ]
    }
   ],
   "source": [
    "REFRESH_TOKEN = \"5d4dc1fd084e0994631899facefef89478de90d3\"\n",
    "print(REFRESH_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a1564587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old gemini code don't know if useful or not\n",
    "# This SHOULD work \n",
    "def refresh_access_token(client_id, client_secret, refresh_token):\n",
    "    \"\"\"Refreshes the access token using the refresh token.\"\"\"\n",
    "    response = requests.post(\n",
    "        url=\"https://www.strava.com/oauth/token\",\n",
    "        data={\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"grant_type\": \"refresh_token\",\n",
    "            \"refresh_token\": refresh_token,\n",
    "        },\n",
    "    )\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    os.environ[\"REFRESH_TOKEN\"] = response[\"refresh_token\"]\n",
    "    return response.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7cd1c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP error occurred: 401 Client Error: Unauthorized for url: https://www.strava.com/oauth/token\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    refresh_attempt = refresh_access_token(CLIENT_ID, CLIENT_SECRET, REFRESH_TOKEN)\n",
    "    ACCESS_TOKEN = refresh_attempt[\"access_token\"]\n",
    "    os.environ[\"REFRESH_TOKEN\"] = access_token_request[\"refresh_token\"]\n",
    "    \n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "24d21e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_type': 'Bearer',\n",
       " 'access_token': 'd49fc739be1f780349f472f3b88a971ea6eb9843',\n",
       " 'expires_at': 1747020565,\n",
       " 'expires_in': 21600,\n",
       " 'refresh_token': '5d4dc1fd084e0994631899facefef89478de90d3'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refresh_attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a8fed",
   "metadata": {},
   "source": [
    "## Get Auth Token\n",
    "#### The Auth Code input here should be the code extracted from the blank webpage after a user approves a scope request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61610c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth_token(client_id, client_secret, auth_code):\n",
    "    \"\"\"Refreshes the access token using the refresh token.\"\"\"\n",
    "    response = requests.post(\n",
    "        url=\"https://www.strava.com/oauth/token\",\n",
    "        data={\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"grant_type\": \"authorization_code\",\n",
    "            \"code\": auth_code,\n",
    "        },\n",
    "    )\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9cf232",
   "metadata": {},
   "source": [
    "#### Code to Exchange Auth Code for Auth Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ff5a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred: 'access_token'\n",
      "{'message': 'Bad Request', 'errors': [{'resource': 'AuthorizationCode', 'field': 'code', 'code': 'invalid'}]}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    swap_auth_token_attempt = get_auth_token(CLIENT_ID, CLIENT_SECRET, AUTH_CODE)\n",
    "    AUTH_TOKEN = swap_auth_token_attempt[\"access_token\"]\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    \n",
    "print(swap_auth_token_attempt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb74a0",
   "metadata": {},
   "source": [
    "## Base Functions for retreiving activities and timeseries data from Strava API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc673e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activities(access_token, page=1, per_page=30, **optional_parameters):\n",
    "    \"\"\"Retrieves activities from the Strava API.\n",
    "    Optional parameters should be provided at the end of the call like so:\n",
    "    before = epoch_timestamp, after = epoch_timestamp\n",
    "    \"\"\"\n",
    "    url = f\"https://www.strava.com/api/v3/athlete/activities\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    params = {\"page\": page, \"per_page\": per_page}\n",
    "    params.update(optional_parameters)\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_streams(access_token, keys, activity_id):\n",
    "    \"\"\"Retrieves activities from the Strava API.\"\"\"\n",
    "    url = f\"https://www.strava.com/api/v3/activities/\" + str(activity_id) + \"/streams\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    params = {\"keys\" : keys, \"key_by_type\": True}\n",
    "    # valid keys includes [\"time\", \"distance\", \"latlng\", \"altitude\", \"heartrate\", \"cadence\", \"watts\"]\n",
    "    # https://developers.strava.com/docs/reference/#api-models-StreamSet\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_gear(access_token, gear_id):\n",
    "    \"\"\"Retrieves activities from the Strava API.\"\"\"\n",
    "    url = f\"https://www.strava.com/api/v3/gear/\" + str(gear_id)\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    # params = {\"id\" : gear_id}\n",
    "    # valid keys includes [\"time\", \"distance\", \"latlng\", \"altitude\", \"heartrate\", \"cadence\", \"watts\"]\n",
    "    # https://developers.strava.com/docs/reference/#api-models-StreamSet\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c60a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[]', '[]')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     12\u001b[39m     conn.close()\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (lat, lon)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mget_latest_starting_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDB_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mget_latest_starting_coords\u001b[39m\u001b[34m(db_path)\u001b[39m\n\u001b[32m      9\u001b[39m rows = cur.fetchone()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(rows)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m lat, lon = \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, \u001b[43mrows\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m)) \n\u001b[32m     12\u001b[39m conn.close()\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (lat, lon)\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "def get_latest_starting_coords(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"SELECT start_latlng, end_latlng FROM activities \n",
    "                WHERE start_latlng is not NULL or \n",
    "                length(start_latlng) > 100\n",
    "                order by start_date desc\n",
    "                limit 1\"\"\")\n",
    "    rows = cur.fetchone()\n",
    "    print(rows)\n",
    "    lat, lon = map(float, rows.split(\",\")) \n",
    "    conn.close()\n",
    "\n",
    "    return (lat, lon)\n",
    "\n",
    "get_latest_starting_coords(DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d2c4f",
   "metadata": {},
   "source": [
    "## Base functions for storing data in db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd261b9",
   "metadata": {},
   "source": [
    "#### Initialize Activities Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "735ef43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_database():\n",
    "    \"\"\"Create the SQLite database and full 'activities' table.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS activities (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        resource_state INTEGER,\n",
    "        athlete_id INTEGER,\n",
    "        athlete_resource_state INTEGER,\n",
    "        name TEXT,\n",
    "        distance REAL,\n",
    "        moving_time INTEGER,\n",
    "        elapsed_time INTEGER,\n",
    "        total_elevation_gain REAL,\n",
    "        type TEXT,\n",
    "        sport_type TEXT,\n",
    "        workout_type INTEGER,\n",
    "        start_date TEXT,\n",
    "        start_date_local TEXT,\n",
    "        timezone TEXT,\n",
    "        utc_offset REAL,\n",
    "        location_city TEXT,\n",
    "        location_state TEXT,\n",
    "        location_country TEXT,\n",
    "        achievement_count INTEGER,\n",
    "        kudos_count INTEGER,\n",
    "        comment_count INTEGER,\n",
    "        athlete_count INTEGER,\n",
    "        photo_count INTEGER,\n",
    "        map_id TEXT,\n",
    "        map_summary_polyline TEXT,\n",
    "        map_resource_state INTEGER,\n",
    "        trainer BOOLEAN,\n",
    "        commute BOOLEAN,\n",
    "        manual BOOLEAN,\n",
    "        private BOOLEAN,\n",
    "        visibility TEXT,\n",
    "        flagged BOOLEAN,\n",
    "        gear_id TEXT,\n",
    "        start_latlng TEXT,\n",
    "        end_latlng TEXT,\n",
    "        average_speed REAL,\n",
    "        max_speed REAL,\n",
    "        average_cadence REAL,\n",
    "        average_watts REAL,\n",
    "        max_watts INTEGER,\n",
    "        weighted_average_watts INTEGER,\n",
    "        device_watts BOOLEAN,\n",
    "        kilojoules REAL,\n",
    "        has_heartrate BOOLEAN,\n",
    "        average_heartrate REAL,\n",
    "        max_heartrate REAL,\n",
    "        heartrate_opt_out BOOLEAN,\n",
    "        display_hide_heartrate_option BOOLEAN,\n",
    "        elev_high REAL,\n",
    "        elev_low REAL,\n",
    "        upload_id INTEGER,\n",
    "        upload_id_str TEXT,\n",
    "        external_id TEXT,\n",
    "        from_accepted_tag BOOLEAN,\n",
    "        pr_count INTEGER,\n",
    "        total_photo_count INTEGER,\n",
    "        has_kudoed BOOLEAN,\n",
    "        import_date TEXT\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b2ad04",
   "metadata": {},
   "source": [
    "#### Activities Individual DB Entry Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecf442b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def insert_activities(activity_list):\n",
    "    \"\"\"Insert activity records, skipping those with duplicate 'id'.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    for activity in activity_list:\n",
    "        try:\n",
    "            c.execute('''\n",
    "            INSERT INTO activities VALUES (\n",
    "                :id, :resource_state, \n",
    "                :athlete_id, :athlete_resource_state,\n",
    "                :name, :distance, :moving_time, :elapsed_time, :total_elevation_gain,\n",
    "                :type, :sport_type, :workout_type, :start_date, :start_date_local,\n",
    "                :timezone, :utc_offset, :location_city, :location_state, :location_country,\n",
    "                :achievement_count, :kudos_count, :comment_count, :athlete_count, :photo_count,\n",
    "                :map_id, :map_summary_polyline, :map_resource_state,\n",
    "                :trainer, :commute, :manual, :private, :visibility, :flagged, :gear_id,\n",
    "                :start_latlng, :end_latlng,\n",
    "                :average_speed, :max_speed, :average_cadence, :average_watts,\n",
    "                :max_watts, :weighted_average_watts, :device_watts, :kilojoules,\n",
    "                :has_heartrate, :average_heartrate, :max_heartrate,\n",
    "                :heartrate_opt_out, :display_hide_heartrate_option,\n",
    "                :elev_high, :elev_low,\n",
    "                :upload_id, :upload_id_str, :external_id, :from_accepted_tag,\n",
    "                :pr_count, :total_photo_count, :has_kudoed, :import_date\n",
    "            )\n",
    "            ''', {\n",
    "                \"id\": activity[\"id\"],\n",
    "                \"resource_state\": activity.get(\"resource_state\"),\n",
    "                \"athlete_id\": activity.get(\"athlete\", {}).get(\"id\"),\n",
    "                \"athlete_resource_state\": activity.get(\"athlete\", {}).get(\"resource_state\"),\n",
    "                \"name\": activity.get(\"name\"),\n",
    "                \"distance\": activity.get(\"distance\"),\n",
    "                \"moving_time\": activity.get(\"moving_time\"),\n",
    "                \"elapsed_time\": activity.get(\"elapsed_time\"),\n",
    "                \"total_elevation_gain\": activity.get(\"total_elevation_gain\"),\n",
    "                \"type\": activity.get(\"type\"),\n",
    "                \"sport_type\": activity.get(\"sport_type\"),\n",
    "                \"workout_type\": activity.get(\"workout_type\"),\n",
    "                \"start_date\": activity.get(\"start_date\"),\n",
    "                \"start_date_local\": activity.get(\"start_date_local\"),\n",
    "                \"timezone\": activity.get(\"timezone\"),\n",
    "                \"utc_offset\": activity.get(\"utc_offset\"),\n",
    "                \"location_city\": activity.get(\"location_city\"),\n",
    "                \"location_state\": activity.get(\"location_state\"),\n",
    "                \"location_country\": activity.get(\"location_country\"),\n",
    "                \"achievement_count\": activity.get(\"achievement_count\"),\n",
    "                \"kudos_count\": activity.get(\"kudos_count\"),\n",
    "                \"comment_count\": activity.get(\"comment_count\"),\n",
    "                \"athlete_count\": activity.get(\"athlete_count\"),\n",
    "                \"photo_count\": activity.get(\"photo_count\"),\n",
    "                \"map_id\": activity.get(\"map\", {}).get(\"id\"),\n",
    "                \"map_summary_polyline\": activity.get(\"map\", {}).get(\"summary_polyline\"),\n",
    "                \"map_resource_state\": activity.get(\"map\", {}).get(\"resource_state\"),\n",
    "                \"trainer\": activity.get(\"trainer\"),\n",
    "                \"commute\": activity.get(\"commute\"),\n",
    "                \"manual\": activity.get(\"manual\"),\n",
    "                \"private\": activity.get(\"private\"),\n",
    "                \"visibility\": activity.get(\"visibility\"),\n",
    "                \"flagged\": activity.get(\"flagged\"),\n",
    "                \"gear_id\": activity.get(\"gear_id\"),\n",
    "                \"start_latlng\": json.dumps(activity.get(\"start_latlng\")),\n",
    "                \"end_latlng\": json.dumps(activity.get(\"end_latlng\")),\n",
    "                \"average_speed\": activity.get(\"average_speed\"),\n",
    "                \"max_speed\": activity.get(\"max_speed\"),\n",
    "                \"average_cadence\": activity.get(\"average_cadence\"),\n",
    "                \"average_watts\": activity.get(\"average_watts\"),\n",
    "                \"max_watts\": activity.get(\"max_watts\"),\n",
    "                \"weighted_average_watts\": activity.get(\"weighted_average_watts\"),\n",
    "                \"device_watts\": activity.get(\"device_watts\"),\n",
    "                \"kilojoules\": activity.get(\"kilojoules\"),\n",
    "                \"has_heartrate\": activity.get(\"has_heartrate\"),\n",
    "                \"average_heartrate\": activity.get(\"average_heartrate\"),\n",
    "                \"max_heartrate\": activity.get(\"max_heartrate\"),\n",
    "                \"heartrate_opt_out\": activity.get(\"heartrate_opt_out\"),\n",
    "                \"display_hide_heartrate_option\": activity.get(\"display_hide_heartrate_option\"),\n",
    "                \"elev_high\": activity.get(\"elev_high\"),\n",
    "                \"elev_low\": activity.get(\"elev_low\"),\n",
    "                \"upload_id\": activity.get(\"upload_id\"),\n",
    "                \"upload_id_str\": activity.get(\"upload_id_str\"),\n",
    "                \"external_id\": activity.get(\"external_id\"),\n",
    "                \"from_accepted_tag\": activity.get(\"from_accepted_tag\"),\n",
    "                \"pr_count\": activity.get(\"pr_count\"),\n",
    "                \"total_photo_count\": activity.get(\"total_photo_count\"),\n",
    "                \"has_kudoed\": activity.get(\"has_kudoed\"),\n",
    "                \"import_date\": datetime.now().isoformat()\n",
    "            })\n",
    "        except sqlite3.IntegrityError:\n",
    "            print(f\"Skipping duplicate activity with id {activity['id']}\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb127101",
   "metadata": {},
   "source": [
    "#### Activities Batch Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2732bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_activities_batch(activity_list, db_path):\n",
    "    \"\"\"Efficiently insert multiple activity records into the database.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    data = []\n",
    "    for activity in activity_list:\n",
    "        data.append({\n",
    "            \"id\": activity[\"id\"],\n",
    "            \"resource_state\": activity.get(\"resource_state\"),\n",
    "            \"athlete_id\": activity.get(\"athlete\", {}).get(\"id\"),\n",
    "            \"athlete_resource_state\": activity.get(\"athlete\", {}).get(\"resource_state\"),\n",
    "            \"name\": activity.get(\"name\"),\n",
    "            \"distance\": activity.get(\"distance\"),\n",
    "            \"moving_time\": activity.get(\"moving_time\"),\n",
    "            \"elapsed_time\": activity.get(\"elapsed_time\"),\n",
    "            \"total_elevation_gain\": activity.get(\"total_elevation_gain\"),\n",
    "            \"type\": activity.get(\"type\"),\n",
    "            \"sport_type\": activity.get(\"sport_type\"),\n",
    "            \"workout_type\": activity.get(\"workout_type\"),\n",
    "            \"start_date\": activity.get(\"start_date\"),\n",
    "            \"start_date_local\": activity.get(\"start_date_local\"),\n",
    "            \"timezone\": activity.get(\"timezone\"),\n",
    "            \"utc_offset\": activity.get(\"utc_offset\"),\n",
    "            \"location_city\": activity.get(\"location_city\"),\n",
    "            \"location_state\": activity.get(\"location_state\"),\n",
    "            \"location_country\": activity.get(\"location_country\"),\n",
    "            \"achievement_count\": activity.get(\"achievement_count\"),\n",
    "            \"kudos_count\": activity.get(\"kudos_count\"),\n",
    "            \"comment_count\": activity.get(\"comment_count\"),\n",
    "            \"athlete_count\": activity.get(\"athlete_count\"),\n",
    "            \"photo_count\": activity.get(\"photo_count\"),\n",
    "            \"map_id\": activity.get(\"map\", {}).get(\"id\"),\n",
    "            \"map_summary_polyline\": activity.get(\"map\", {}).get(\"summary_polyline\"),\n",
    "            \"map_resource_state\": activity.get(\"map\", {}).get(\"resource_state\"),\n",
    "            \"trainer\": activity.get(\"trainer\"),\n",
    "            \"commute\": activity.get(\"commute\"),\n",
    "            \"manual\": activity.get(\"manual\"),\n",
    "            \"private\": activity.get(\"private\"),\n",
    "            \"visibility\": activity.get(\"visibility\"),\n",
    "            \"flagged\": activity.get(\"flagged\"),\n",
    "            \"gear_id\": activity.get(\"gear_id\"),\n",
    "            \"start_latlng\": json.dumps(activity.get(\"start_latlng\")),\n",
    "            \"end_latlng\": json.dumps(activity.get(\"end_latlng\")),\n",
    "            \"average_speed\": activity.get(\"average_speed\"),\n",
    "            \"max_speed\": activity.get(\"max_speed\"),\n",
    "            \"average_cadence\": activity.get(\"average_cadence\"),\n",
    "            \"average_watts\": activity.get(\"average_watts\"),\n",
    "            \"max_watts\": activity.get(\"max_watts\"),\n",
    "            \"weighted_average_watts\": activity.get(\"weighted_average_watts\"),\n",
    "            \"device_watts\": activity.get(\"device_watts\"),\n",
    "            \"kilojoules\": activity.get(\"kilojoules\"),\n",
    "            \"has_heartrate\": activity.get(\"has_heartrate\"),\n",
    "            \"average_heartrate\": activity.get(\"average_heartrate\"),\n",
    "            \"max_heartrate\": activity.get(\"max_heartrate\"),\n",
    "            \"heartrate_opt_out\": activity.get(\"heartrate_opt_out\"),\n",
    "            \"display_hide_heartrate_option\": activity.get(\"display_hide_heartrate_option\"),\n",
    "            \"elev_high\": activity.get(\"elev_high\"),\n",
    "            \"elev_low\": activity.get(\"elev_low\"),\n",
    "            \"upload_id\": activity.get(\"upload_id\"),\n",
    "            \"upload_id_str\": activity.get(\"upload_id_str\"),\n",
    "            \"external_id\": activity.get(\"external_id\"),\n",
    "            \"from_accepted_tag\": activity.get(\"from_accepted_tag\"),\n",
    "            \"pr_count\": activity.get(\"pr_count\"),\n",
    "            \"total_photo_count\": activity.get(\"total_photo_count\"),\n",
    "            \"has_kudoed\": activity.get(\"has_kudoed\"),\n",
    "            \"import_date\": datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "    try:\n",
    "        c.executemany('''\n",
    "        INSERT OR IGNORE INTO activities VALUES (\n",
    "            :id, :resource_state, :athlete_id, :athlete_resource_state,\n",
    "            :name, :distance, :moving_time, :elapsed_time, :total_elevation_gain,\n",
    "            :type, :sport_type, :workout_type, :start_date, :start_date_local,\n",
    "            :timezone, :utc_offset, :location_city, :location_state, :location_country,\n",
    "            :achievement_count, :kudos_count, :comment_count, :athlete_count, :photo_count,\n",
    "            :map_id, :map_summary_polyline, :map_resource_state,\n",
    "            :trainer, :commute, :manual, :private, :visibility, :flagged, :gear_id,\n",
    "            :start_latlng, :end_latlng,\n",
    "            :average_speed, :max_speed, :average_cadence, :average_watts,\n",
    "            :max_watts, :weighted_average_watts, :device_watts, :kilojoules,\n",
    "            :has_heartrate, :average_heartrate, :max_heartrate,\n",
    "            :heartrate_opt_out, :display_hide_heartrate_option,\n",
    "            :elev_high, :elev_low,\n",
    "            :upload_id, :upload_id_str, :external_id, :from_accepted_tag,\n",
    "            :pr_count, :total_photo_count, :has_kudoed, :import_date\n",
    "        )\n",
    "        ''', data)\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error inserting batch:\", e)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c38a58a",
   "metadata": {},
   "source": [
    "#### Function to Rebuild single activity from flattened version in db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8b79298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_by_id(activity_id):\n",
    "    \"\"\"Retrieve a single activity and reconstruct its nested format.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\"SELECT * FROM activities WHERE id = ?\", (activity_id,))\n",
    "    row = c.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if row is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"id\": row[\"id\"],\n",
    "        \"resource_state\": row[\"resource_state\"],\n",
    "        \"athlete\": {\n",
    "            \"id\": row[\"athlete_id\"],\n",
    "            \"resource_state\": row[\"athlete_resource_state\"]\n",
    "        },\n",
    "        \"name\": row[\"name\"],\n",
    "        \"distance\": row[\"distance\"],\n",
    "        \"moving_time\": row[\"moving_time\"],\n",
    "        \"elapsed_time\": row[\"elapsed_time\"],\n",
    "        \"total_elevation_gain\": row[\"total_elevation_gain\"],\n",
    "        \"type\": row[\"type\"],\n",
    "        \"sport_type\": row[\"sport_type\"],\n",
    "        \"workout_type\": row[\"workout_type\"],\n",
    "        \"start_date\": row[\"start_date\"],\n",
    "        \"start_date_local\": row[\"start_date_local\"],\n",
    "        \"timezone\": row[\"timezone\"],\n",
    "        \"utc_offset\": row[\"utc_offset\"],\n",
    "        \"location_city\": row[\"location_city\"],\n",
    "        \"location_state\": row[\"location_state\"],\n",
    "        \"location_country\": row[\"location_country\"],\n",
    "        \"achievement_count\": row[\"achievement_count\"],\n",
    "        \"kudos_count\": row[\"kudos_count\"],\n",
    "        \"comment_count\": row[\"comment_count\"],\n",
    "        \"athlete_count\": row[\"athlete_count\"],\n",
    "        \"photo_count\": row[\"photo_count\"],\n",
    "        \"map\": {\n",
    "            \"id\": row[\"map_id\"],\n",
    "            \"summary_polyline\": row[\"map_summary_polyline\"],\n",
    "            \"resource_state\": row[\"map_resource_state\"]\n",
    "        },\n",
    "        \"trainer\": bool(row[\"trainer\"]),\n",
    "        \"commute\": bool(row[\"commute\"]),\n",
    "        \"manual\": bool(row[\"manual\"]),\n",
    "        \"private\": bool(row[\"private\"]),\n",
    "        \"visibility\": row[\"visibility\"],\n",
    "        \"flagged\": bool(row[\"flagged\"]),\n",
    "        \"gear_id\": row[\"gear_id\"],\n",
    "        \"start_latlng\": json.loads(row[\"start_latlng\"]),\n",
    "        \"end_latlng\": json.loads(row[\"end_latlng\"]),\n",
    "        \"average_speed\": row[\"average_speed\"],\n",
    "        \"max_speed\": row[\"max_speed\"],\n",
    "        \"average_cadence\": row[\"average_cadence\"],\n",
    "        \"average_watts\": row[\"average_watts\"],\n",
    "        \"max_watts\": row[\"max_watts\"],\n",
    "        \"weighted_average_watts\": row[\"weighted_average_watts\"],\n",
    "        \"device_watts\": bool(row[\"device_watts\"]),\n",
    "        \"kilojoules\": row[\"kilojoules\"],\n",
    "        \"has_heartrate\": bool(row[\"has_heartrate\"]),\n",
    "        \"average_heartrate\": row[\"average_heartrate\"],\n",
    "        \"max_heartrate\": row[\"max_heartrate\"],\n",
    "        \"heartrate_opt_out\": bool(row[\"heartrate_opt_out\"]),\n",
    "        \"display_hide_heartrate_option\": bool(row[\"display_hide_heartrate_option\"]),\n",
    "        \"elev_high\": row[\"elev_high\"],\n",
    "        \"elev_low\": row[\"elev_low\"],\n",
    "        \"upload_id\": row[\"upload_id\"],\n",
    "        \"upload_id_str\": row[\"upload_id_str\"],\n",
    "        \"external_id\": row[\"external_id\"],\n",
    "        \"from_accepted_tag\": bool(row[\"from_accepted_tag\"]),\n",
    "        \"pr_count\": row[\"pr_count\"],\n",
    "        \"total_photo_count\": row[\"total_photo_count\"],\n",
    "        \"has_kudoed\": bool(row[\"has_kudoed\"])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca75d58",
   "metadata": {},
   "source": [
    "#### Simple Query to get records loaded during current day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c64ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_activities_imported_today(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM activities \n",
    "        WHERE substr(import_date, 1, 10) = ?\n",
    "    \"\"\", (today_str,))\n",
    "    \n",
    "    count = c.fetchone()[0]\n",
    "    conn.close()\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9807a38d",
   "metadata": {},
   "source": [
    "#### Simple Query to Latest record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ff92056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14497411369,\n",
       " 2,\n",
       " 24266563,\n",
       " 1,\n",
       " 'Morning Walk',\n",
       " 4647.5,\n",
       " 2861,\n",
       " 2861,\n",
       " 45.0,\n",
       " 'Walk',\n",
       " 'Walk',\n",
       " None,\n",
       " '2025-05-16T10:48:01Z',\n",
       " '2025-05-16T05:48:01Z',\n",
       " '(GMT-06:00) America/Chicago',\n",
       " -18000.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 'a14497411369',\n",
       " 'o}jqG`uqxP?c@IkBOeA]{ABo@EyANuAGIq@g@g@o@m@iASo@A}@?c@LkAJUXc@VUd@g@T[@IGM_BeAQYGWS_DA_EJ_A@a@C]EYGCO@MCs@Ls@Dy@OeANWGy@]k@MYAm@@]?g@GQISOWi@Ka@[mDSi@e@c@KGg@KiABc@As@SIBONUt@GFc@k@k@[WEUF_@`@UhAJnB?nAD`ACrA@b@WhCETIPG\\\\Oh@a@j@QLUZ_AbAAJ@xACjADDL@X?v@FTAn@HLAVFh@C`AF\\\\?jANz@Rv@Zd@D^LL?t@^bBf@RNr@`@PRVh@l@nBp@fB^j@VZRPn@\\\\^LXDx@D|A@d@D`@X^f@n@l@TXTNFRJf@PpA\\\\~@',\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 'everyone',\n",
       " 0,\n",
       " 'g15302697',\n",
       " '[44.949665, -93.324741]',\n",
       " '[44.949581, -93.32488]',\n",
       " 1.624,\n",
       " 2.5,\n",
       " 60.9,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 1,\n",
       " 86.1,\n",
       " 108.0,\n",
       " 0,\n",
       " 1,\n",
       " 287.0,\n",
       " 275.0,\n",
       " 15467510211,\n",
       " '15467510211',\n",
       " '469062869529427971.fit',\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " '2025-05-16T07:45:35.460549')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def latest_activity_imported(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT * \n",
    "        FROM activities \n",
    "        WHERE import_date = \n",
    "        (select max(import_date) from activities)\n",
    "    \"\"\")\n",
    "    \n",
    "    record = c.fetchone()\n",
    "    conn.close()\n",
    "    return record\n",
    "\n",
    "latest_activity_imported(DB_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0143cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14493150635,\n",
       " 2,\n",
       " 24266563,\n",
       " 1,\n",
       " 'Turbulent',\n",
       " 7286.1,\n",
       " 2362,\n",
       " 2376,\n",
       " 34.0,\n",
       " 'Run',\n",
       " 'Run',\n",
       " 0,\n",
       " '2025-05-15T21:44:22Z',\n",
       " '2025-05-15T16:44:22Z',\n",
       " '(GMT-06:00) America/Chicago',\n",
       " -18000.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 0,\n",
       " 13,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 'a14493150635',\n",
       " 'w}jqGluqxPAeAKmAI}@Ki@Sg@]]k@s@m@g@e@Qw@E_BDSEq@WcBeAW]Wk@MOG?EDSr@m@z@k@tAc@d@MZMl@GHIDO?k@W]c@o@m@o@aAOi@[aBA]E[Qs@_@}@_Aq@e@OkA{@I?S@_@PWBs@Sg@COFORc@RILIX@VD\\\\@`@E~@EVE@QW{@aAMW?INNHDF?VO@EISWWOGa@@a@CKESOQGo@CUBe@Km@GIEQQa@{@OW}@_Ak@c@s@s@O?]ZSx@QTOF_@HOBa@AKBSXMZEZGpA@`ADt@CvAWrBMb@ATN`@NPH@`@CVVFJ?^G^MT[Vw@TMNSh@QnACv@O`BC|AInB?xBE~@H~A?l@HlAC\\\\@NL~@JZFJ`@\\\\DJX|BB`BDf@DTTt@Jl@FRLJJBV@hCQTBp@?RDT@`@Cr@I`@?j@HXV^L\\\\XVb@DLl@fD\\\\p@~AfBXn@HDRDd@ZbAjAd@d@TJVFVBt@C|@Nh@@`AEnBSn@Dh@GrCIlA?VCn@Bb@C`@@HERW^?NEf@k@j@c@Za@',\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 'everyone',\n",
       " 0,\n",
       " 'g17224321',\n",
       " '[44.949358, -93.324792]',\n",
       " '[44.949456, -93.324709]',\n",
       " 3.085,\n",
       " 4.6,\n",
       " 88.6,\n",
       " 217.2,\n",
       " 293,\n",
       " 218,\n",
       " 1,\n",
       " 513.1,\n",
       " 1,\n",
       " 126.7,\n",
       " 140.0,\n",
       " 0,\n",
       " 1,\n",
       " 292.0,\n",
       " 273.0,\n",
       " 15462887799,\n",
       " '15462887799',\n",
       " '469050135488266254.fit',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '2025-05-15T19:46:10.108351')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_activity_imported(DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c90103b",
   "metadata": {},
   "source": [
    "### Simple Query to get Gear Id from Latest Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04529122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_gear_ids(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT distinct gear_id \n",
    "        FROM activities \n",
    "        WHERE gear_id IS NOT NULL\n",
    "    \"\"\")\n",
    "    \n",
    "    record = c.fetchall()\n",
    "    conn.close()\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d36ce",
   "metadata": {},
   "source": [
    "#### Simple Query to Get Specific record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fee55d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_data_all(db_path, activity_id):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Run query and load into DataFrame (with column headers)\n",
    "    df = pd.read_sql_query(\n",
    "        \"SELECT * FROM activities WHERE id = ?\",\n",
    "        conn,\n",
    "        params=(activity_id,)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d568f71",
   "metadata": {},
   "source": [
    "#### Simple Query to get all Activity IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13e15b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14487474408,),\n",
       " (14483199626,),\n",
       " (14477593705,),\n",
       " (14472461251,),\n",
       " (14465685256,),\n",
       " (14461585344,),\n",
       " (14448198825,),\n",
       " (14445846595,),\n",
       " (14439139788,),\n",
       " (14436191500,),\n",
       " (14429488624,),\n",
       " (14429488648,),\n",
       " (14420081833,),\n",
       " (14414666612,),\n",
       " (14411191781,),\n",
       " (14411191925,),\n",
       " (14411192865,),\n",
       " (14404286770,),\n",
       " (14399681906,),\n",
       " (14393650080,),\n",
       " (14389805238,),\n",
       " (14383969194,),\n",
       " (14380480511,),\n",
       " (14379281304,),\n",
       " (14376062303,),\n",
       " (14369842769,),\n",
       " (14368997811,),\n",
       " (14365012542,),\n",
       " (14358400377,),\n",
       " (14354639209,),\n",
       " (14353398775,),\n",
       " (14348764058,),\n",
       " (14342981460,),\n",
       " (14338478098,),\n",
       " (14338218423,),\n",
       " (14337526946,),\n",
       " (14331978461,),\n",
       " (14326961057,),\n",
       " (14321075456,),\n",
       " (14317096914,),\n",
       " (14310902427,),\n",
       " (14305742622,),\n",
       " (14302735322,),\n",
       " (14292794382,),\n",
       " (14285619866,),\n",
       " (14280817149,),\n",
       " (14276784576,),\n",
       " (14271402828,),\n",
       " (14267399463,),\n",
       " (14261794985,),\n",
       " (14245504574,),\n",
       " (14237190879,),\n",
       " (14226658058,),\n",
       " (14222270286,),\n",
       " (14217673520,),\n",
       " (14214735620,),\n",
       " (14211839733,),\n",
       " (14207239257,),\n",
       " (14202362392,),\n",
       " (14199011311,),\n",
       " (14198134902,),\n",
       " (14194243688,),\n",
       " (14193413852,),\n",
       " (14188732734,),\n",
       " (14183565736,),\n",
       " (14178732890,),\n",
       " (14173542322,),\n",
       " (14170002752,),\n",
       " (14166911277,),\n",
       " (14157659619,),\n",
       " (14155282984,),\n",
       " (14148911926,),\n",
       " (14145372006,),\n",
       " (14140789788,),\n",
       " (14135715349,),\n",
       " (14131993702,),\n",
       " (14128674023,),\n",
       " (14125526616,),\n",
       " (14122628021,),\n",
       " (14121380988,),\n",
       " (14115691665,),\n",
       " (14111448036,),\n",
       " (14105469037,),\n",
       " (14102398730,),\n",
       " (14102024448,),\n",
       " (14091046205,),\n",
       " (14089458321,),\n",
       " (14081667115,),\n",
       " (14076801010,),\n",
       " (14072663334,),\n",
       " (14067418551,),\n",
       " (14063042383,),\n",
       " (14057204092,),\n",
       " (14053022964,),\n",
       " (14047512233,),\n",
       " (14043049309,),\n",
       " (14032955639,),\n",
       " (14032342040,),\n",
       " (14022619974,),\n",
       " (14020644288,),\n",
       " (14019869964,),\n",
       " (14014693589,),\n",
       " (14007049231,),\n",
       " (13991234665,),\n",
       " (13987278716,),\n",
       " (13977683494,),\n",
       " (13958644336,),\n",
       " (13956223845,),\n",
       " (13954311815,),\n",
       " (13948529073,),\n",
       " (13944241956,),\n",
       " (13940162980,),\n",
       " (13934647421,),\n",
       " (13925444779,),\n",
       " (13920953320,),\n",
       " (13915226936,),\n",
       " (13911584953,),\n",
       " (13903253245,),\n",
       " (13889807753,),\n",
       " (13884089413,),\n",
       " (13875446959,),\n",
       " (13866665819,),\n",
       " (13838622677,),\n",
       " (13828620991,),\n",
       " (13827528622,),\n",
       " (13819603827,),\n",
       " (13817834193,),\n",
       " (13800217085,),\n",
       " (13781696082,),\n",
       " (13774096953,),\n",
       " (13765418030,),\n",
       " (13753615151,),\n",
       " (13738566700,),\n",
       " (13729288971,),\n",
       " (13710639294,),\n",
       " (13699783207,),\n",
       " (13685234465,),\n",
       " (13669742413,),\n",
       " (13664655162,),\n",
       " (13659755341,),\n",
       " (13654533001,),\n",
       " (13650809290,),\n",
       " (13647424015,),\n",
       " (13643115523,),\n",
       " (13635720954,),\n",
       " (13633624758,),\n",
       " (13628462901,),\n",
       " (13624927251,),\n",
       " (13620900860,),\n",
       " (13616536303,),\n",
       " (13612475666,),\n",
       " (13612354751,),\n",
       " (13609996312,),\n",
       " (13608551353,),\n",
       " (13607887569,),\n",
       " (13607887432,),\n",
       " (13604320745,),\n",
       " (13601283525,),\n",
       " (13601283392,),\n",
       " (13594033719,),\n",
       " (13590070214,),\n",
       " (13586284463,),\n",
       " (13577045996,),\n",
       " (13577046606,),\n",
       " (13567924050,),\n",
       " (13555125264,),\n",
       " (13551057784,),\n",
       " (13551057363,),\n",
       " (13551057443,),\n",
       " (13547071064,),\n",
       " (13546728705,),\n",
       " (13546728707,),\n",
       " (13546728698,),\n",
       " (13539402847,),\n",
       " (13536827093,),\n",
       " (13531933726,),\n",
       " (13531933522,),\n",
       " (13531933676,),\n",
       " (13524174518,),\n",
       " (13523539287,),\n",
       " (13511481141,),\n",
       " (13504862934,),\n",
       " (13496538742,),\n",
       " (13488803937,),\n",
       " (13487762350,),\n",
       " (13484345569,),\n",
       " (13483859240,),\n",
       " (13483859236,),\n",
       " (13483859237,),\n",
       " (13478185920,),\n",
       " (13469656186,),\n",
       " (13461946631,),\n",
       " (13458720436,),\n",
       " (13458720307,),\n",
       " (13458720358,),\n",
       " (13451095641,),\n",
       " (13442629754,),\n",
       " (13435422694,),\n",
       " (13427880787,),\n",
       " (13426651758,),\n",
       " (13423792158,),\n",
       " (13423325160,),\n",
       " (13423325162,),\n",
       " (13423325168,),\n",
       " (13413695199,),\n",
       " (13406713891,),\n",
       " (13405504032,),\n",
       " (13399627059,),\n",
       " (13390475803,),\n",
       " (13388726022,),\n",
       " (13382027247,),\n",
       " (13378371756,),\n",
       " (13373870481,),\n",
       " (13370346293,),\n",
       " (13366444792,),\n",
       " (13365421514,),\n",
       " (13361675438,),\n",
       " (13361253506,),\n",
       " (13360870718,),\n",
       " (13356786376,),\n",
       " (13351929381,),\n",
       " (13342754456,),\n",
       " (13337863140,),\n",
       " (13329298869,),\n",
       " (13328072150,),\n",
       " (13317978881,),\n",
       " (13316188794,),\n",
       " (13311228549,),\n",
       " (13303868016,),\n",
       " (13302994146,),\n",
       " (13298952931,),\n",
       " (13294510752,),\n",
       " (13289960470,),\n",
       " (13285114374,),\n",
       " (13280975100,),\n",
       " (13273035676,),\n",
       " (13268040200,),\n",
       " (13268041049,),\n",
       " (13258730399,),\n",
       " (13258234125,),\n",
       " (13256148117,),\n",
       " (13250904785,),\n",
       " (13250225554,),\n",
       " (13240441588,),\n",
       " (13239370224,),\n",
       " (13235009229,),\n",
       " (13233801037,),\n",
       " (13224473326,),\n",
       " (13222716137,),\n",
       " (13218881360,),\n",
       " (13216103841,),\n",
       " (13211168825,),\n",
       " (13209550894,),\n",
       " (13202929984,),\n",
       " (13200614241,),\n",
       " (13196199426,),\n",
       " (13194338095,),\n",
       " (13189099800,),\n",
       " (13187897734,),\n",
       " (13183220480,),\n",
       " (13182284073,),\n",
       " (13174231432,),\n",
       " (13169647032,),\n",
       " (13168856735,),\n",
       " (13164120030,),\n",
       " (13162156059,),\n",
       " (13157718923,),\n",
       " (13151433505,),\n",
       " (13148674592,),\n",
       " (13145140358,),\n",
       " (13141825054,),\n",
       " (13137931096,),\n",
       " (13135207326,),\n",
       " (13130577484,),\n",
       " (13128724341,),\n",
       " (13124029555,),\n",
       " (13122352566,),\n",
       " (13116922437,),\n",
       " (13109591092,),\n",
       " (13107360594,),\n",
       " (13107159872,),\n",
       " (13103495926,),\n",
       " (13100127515,),\n",
       " (13100127557,),\n",
       " (13096241056,),\n",
       " (13093290747,),\n",
       " (13093154682,),\n",
       " (13088548538,),\n",
       " (13088547919,),\n",
       " (13085413128,),\n",
       " (13081363026,),\n",
       " (13079777862,),\n",
       " (13078587580,),\n",
       " (13075271214,),\n",
       " (13074159063,),\n",
       " (13066796969,),\n",
       " (13066300697,),\n",
       " (13061850326,),\n",
       " (13060876299,),\n",
       " (13055041621,),\n",
       " (13054769493,),\n",
       " (13054207771,),\n",
       " (13052326327,),\n",
       " (13047480036,),\n",
       " (13045955706,),\n",
       " (13045953971,),\n",
       " (13041256776,),\n",
       " (13045953326,),\n",
       " (13033827197,),\n",
       " (13033198904,),\n",
       " (13031267705,),\n",
       " (13026764132,),\n",
       " (13019111353,),\n",
       " (13015808474,),\n",
       " (13011406560,),\n",
       " (13008613797,),\n",
       " (13005605535,),\n",
       " (13003852928,),\n",
       " (13003851312,),\n",
       " (13003850344,),\n",
       " (13003849085,),\n",
       " (12996900309,),\n",
       " (12994450340,),\n",
       " (12991964760,),\n",
       " (12987668410,),\n",
       " (12982639147,),\n",
       " (12976253302,),\n",
       " (12973831696,),\n",
       " (12966906246,),\n",
       " (12965218994,),\n",
       " (12960704231,),\n",
       " (12960704155,),\n",
       " (12959393323,),\n",
       " (12954560208,),\n",
       " (12994453869,),\n",
       " (12947768374,),\n",
       " (12944333280,),\n",
       " (12939886054,),\n",
       " (12931985961,),\n",
       " (12924756908,),\n",
       " (12915690924,),\n",
       " (12914089399,),\n",
       " (12909230147,),\n",
       " (12902294041,),\n",
       " (12894953744,),\n",
       " (12891516307,),\n",
       " (12887139843,),\n",
       " (12879191303,),\n",
       " (12878918134,),\n",
       " (12877920367,),\n",
       " (12871415906,),\n",
       " (12861787704,),\n",
       " (12854364774,),\n",
       " (12847982234,),\n",
       " (12840333512,),\n",
       " (12836967226,),\n",
       " (12828891070,),\n",
       " (12828452770,),\n",
       " (12824772855,),\n",
       " (12816153439,),\n",
       " (12815787058,),\n",
       " (12815783490,),\n",
       " (12815778784,),\n",
       " (12808328416,),\n",
       " (12808328383,),\n",
       " (12807187720,),\n",
       " (12800281910,),\n",
       " (12784892700,),\n",
       " (12781099856,),\n",
       " (12777241946,),\n",
       " (12768761195,),\n",
       " (12761662070,),\n",
       " (12761662054,),\n",
       " (12752944966,),\n",
       " (12749819591,),\n",
       " (12744430465,),\n",
       " (12737356090,),\n",
       " (12729513105,),\n",
       " (12725543885,),\n",
       " (12720045570,),\n",
       " (12712635389,),\n",
       " (12701658541,),\n",
       " (12701657073,),\n",
       " (12694840400,),\n",
       " (12684940767,),\n",
       " (12677382151,),\n",
       " (12672951169,),\n",
       " (12669332035,),\n",
       " (12663977952,),\n",
       " (12655596128,),\n",
       " (12649664616,),\n",
       " (12637868611,),\n",
       " (12630109692,),\n",
       " (12625215613,),\n",
       " (12618081417,),\n",
       " (12618081035,),\n",
       " (12618068075,),\n",
       " (12617196572,),\n",
       " (12600698937,),\n",
       " (12592398891,),\n",
       " (12592398812,),\n",
       " (12592398350,),\n",
       " (12581620918,),\n",
       " (12581620488,),\n",
       " (12572739006,),\n",
       " (12567972686,),\n",
       " (12564530664,),\n",
       " (12548091154,),\n",
       " (12533265639,),\n",
       " (12532873115,),\n",
       " (12524541625,),\n",
       " (12524305595,),\n",
       " (12524304961,),\n",
       " (12519456427,),\n",
       " (12515806500,),\n",
       " (12511653839,),\n",
       " (12511409717,),\n",
       " (12505267368,),\n",
       " (12505267244,),\n",
       " (12505266952,),\n",
       " (12500728664,),\n",
       " (12496116830,),\n",
       " (12495789347,),\n",
       " (12487232901,),\n",
       " (12477428678,),\n",
       " (12476693088,),\n",
       " (12467801910,),\n",
       " (12461763180,),\n",
       " (12458428609,),\n",
       " (12453866527,),\n",
       " (12450241899,),\n",
       " (12441283565,),\n",
       " (12435291159,),\n",
       " (12432484878,),\n",
       " (12428407658,),\n",
       " (12427999289,),\n",
       " (12416951563,),\n",
       " (12411648455,),\n",
       " (12411647947,),\n",
       " (12408744886,),\n",
       " (12408743975,),\n",
       " (12408740604,),\n",
       " (12399435508,),\n",
       " (12395534917,),\n",
       " (12395534272,),\n",
       " (12387593485,),\n",
       " (12383205213,),\n",
       " (12375600268,),\n",
       " (12370172223,),\n",
       " (12369759654,),\n",
       " (12361392099,),\n",
       " (12361004464,),\n",
       " (12351256726,),\n",
       " (12351255881,),\n",
       " (12342278522,),\n",
       " (12336817782,),\n",
       " (12328362614,),\n",
       " (12328088766,),\n",
       " (12327818905,),\n",
       " (12323313955,),\n",
       " (12319568126,),\n",
       " (12318999572,),\n",
       " (12314897673,),\n",
       " (12298470211,),\n",
       " (12292095705,),\n",
       " (12290599510,),\n",
       " (12284955085,),\n",
       " (12284642287,),\n",
       " (12276664700,),\n",
       " (12269215121,),\n",
       " (12269215742,),\n",
       " (12269214707,),\n",
       " (12263827388,),\n",
       " (12255257769,),\n",
       " (12250626610,),\n",
       " (12250432686,),\n",
       " (12249926964,),\n",
       " (12246003272,),\n",
       " (12241837618,),\n",
       " (12231253157,),\n",
       " (12226173003,),\n",
       " (12226172891,),\n",
       " (12217407467,),\n",
       " (12209826003,),\n",
       " (12209825919,),\n",
       " (12209825609,),\n",
       " (12204086017,),\n",
       " (12199905056,),\n",
       " (12199466193,),\n",
       " (12195275910,),\n",
       " (12180396681,),\n",
       " (12172481364,),\n",
       " (12172665345,),\n",
       " (12171490370,),\n",
       " (12162128680,),\n",
       " (12158057537,),\n",
       " (12158056873,),\n",
       " (12150067427,),\n",
       " (12150067327,),\n",
       " (12150066609,),\n",
       " (12144882095,),\n",
       " (12136326452,),\n",
       " (12131878958,),\n",
       " (12120706765,),\n",
       " (12120013459,),\n",
       " (12113637181,),\n",
       " (12102973926,),\n",
       " (12098805164,),\n",
       " (12098804938,),\n",
       " (12091370486,),\n",
       " (12091370393,),\n",
       " (12091370084,),\n",
       " (12085495744,),\n",
       " (12081499405,),\n",
       " (12076483404,),\n",
       " (12065090145,),\n",
       " (12060068297,),\n",
       " (12052051307,),\n",
       " (12043467228,),\n",
       " (12039257524,),\n",
       " (12038762078,),\n",
       " (12035354697,),\n",
       " (12031122276,),\n",
       " (12026319050,),\n",
       " (12023276102,),\n",
       " (12022959699,),\n",
       " (12022960804,),\n",
       " (12017933870,),\n",
       " (12011359227,),\n",
       " (12009328207,),\n",
       " (12006011992,),\n",
       " (12005835554,),\n",
       " (12005252835,),\n",
       " (12003622349,),\n",
       " (12002670775,),\n",
       " (11995105355,),\n",
       " (11989119380,),\n",
       " (11989121502,),\n",
       " (11981425540,),\n",
       " (11973535269,),\n",
       " (11968337597,),\n",
       " (11965121257,),\n",
       " (11965120990,),\n",
       " (11965120838,),\n",
       " (11964112610,),\n",
       " (11959760502,),\n",
       " (11955236628,),\n",
       " (11955236238,),\n",
       " (11948076810,),\n",
       " (11947881454,),\n",
       " (11946127479,),\n",
       " (11946123888,),\n",
       " (11945517480,),\n",
       " (11944340290,),\n",
       " (11936330615,),\n",
       " (11935369526,),\n",
       " (11935369944,),\n",
       " (11930858826,),\n",
       " (11927411738,),\n",
       " (11927411305,),\n",
       " (11927410788,),\n",
       " (11923021995,),\n",
       " (11922591742,),\n",
       " (11919643304,),\n",
       " (11915619555,),\n",
       " (11913700705,),\n",
       " (11910404671,),\n",
       " (11906236599,),\n",
       " (11898054249,),\n",
       " (11890380141,),\n",
       " (11890289210,),\n",
       " (11889851012,),\n",
       " (11888351719,),\n",
       " (11888395596,),\n",
       " (11887968214,),\n",
       " (11887595453,),\n",
       " (11887412563,),\n",
       " (11887162252,),\n",
       " (11885533078,),\n",
       " (11885395090,),\n",
       " (11879654162,),\n",
       " (11879326862,),\n",
       " (11878809805,),\n",
       " (11878390549,),\n",
       " (11878189613,),\n",
       " (11878189274,),\n",
       " (11877336394,),\n",
       " (11869913025,),\n",
       " (11869912703,),\n",
       " (11869912437,),\n",
       " (11861953594,),\n",
       " (11861573336,),\n",
       " (11861619416,),\n",
       " (11858875363,),\n",
       " (11858286003,),\n",
       " (11858875176,),\n",
       " (11858875107,),\n",
       " (11853472320,),\n",
       " (11853472412,),\n",
       " (11853285074,),\n",
       " (11853281491,),\n",
       " (11850240218,),\n",
       " (11850057502,),\n",
       " (11849893623,),\n",
       " (11849848086,),\n",
       " (11849840869,),\n",
       " (11849776524,),\n",
       " (11849685160,),\n",
       " (11849776680,),\n",
       " (11845165623,),\n",
       " (11845165472,),\n",
       " (11845166005,),\n",
       " (11844765783,),\n",
       " (11845164658,),\n",
       " (11845164464,),\n",
       " (11845164222,),\n",
       " (11845163996,),\n",
       " (11841537740,),\n",
       " (11841537325,),\n",
       " (11836721483,),\n",
       " (11831249430,),\n",
       " (11824172470,),\n",
       " (11818025287,),\n",
       " (11814283566,),\n",
       " (11807330454,),\n",
       " (11806873715,),\n",
       " (11803115232,),\n",
       " (11803115818,),\n",
       " (11803115127,),\n",
       " (11797292823,),\n",
       " (11792828513,),\n",
       " (11789654877,),\n",
       " (11786138298,),\n",
       " (11781247034,),\n",
       " (11778483325,),\n",
       " (11776339930,),\n",
       " (11774313353,),\n",
       " (11771045991,),\n",
       " (11768145531,),\n",
       " (11762637229,),\n",
       " (11760484614,),\n",
       " (11759241038,),\n",
       " (11755287020,),\n",
       " (11753257550,),\n",
       " (11751270555,),\n",
       " (11748000009,),\n",
       " (11747999898,),\n",
       " (11747999533,),\n",
       " (11744340339,),\n",
       " (11743228221,),\n",
       " (11736707246,),\n",
       " (11734701436,),\n",
       " (11736706922,),\n",
       " (11736706945,),\n",
       " (11736706771,),\n",
       " (11736706635,),\n",
       " (11736706178,),\n",
       " (11736705999,),\n",
       " (11736705909,),\n",
       " (11736705778,),\n",
       " (11736705635,),\n",
       " (11736705545,),\n",
       " (11712875125,),\n",
       " (11736705274,),\n",
       " (11736705305,),\n",
       " (11736705138,),\n",
       " (11704201933,),\n",
       " (11736705084,),\n",
       " (11736704900,),\n",
       " (11693555832,),\n",
       " (11689743090,),\n",
       " (11684699738,),\n",
       " (11736704505,),\n",
       " (11736704434,),\n",
       " (11736704260,),\n",
       " (11736704123,),\n",
       " (11736704027,),\n",
       " (11658273524,),\n",
       " (11651193912,),\n",
       " (11643670805,),\n",
       " (11638881741,),\n",
       " (11634439446,),\n",
       " (11631430963,),\n",
       " (11622700539,),\n",
       " (11736703697,),\n",
       " (11615467443,),\n",
       " (11615467394,),\n",
       " (11613674494,),\n",
       " (11612007582,),\n",
       " (11736703463,),\n",
       " (11603076636,),\n",
       " (11599506417,),\n",
       " (11592186486,),\n",
       " (11587004738,),\n",
       " (11587004440,),\n",
       " (11587004395,),\n",
       " (11587003766,),\n",
       " (11579008416,),\n",
       " (11573047220,),\n",
       " (11570772061,),\n",
       " (11566936414,),\n",
       " (11557652679,),\n",
       " (11551405352,),\n",
       " (11551403230,),\n",
       " (11547208248,),\n",
       " (11539291169,),\n",
       " (11536574792,),\n",
       " (11536574430,),\n",
       " (11529280795,),\n",
       " (11529280624,),\n",
       " (11529280131,),\n",
       " (11524215443,),\n",
       " (11520834186,),\n",
       " (11520836676,),\n",
       " (11513388782,),\n",
       " (11509452588,),\n",
       " (11506027933,),\n",
       " (11495949348,),\n",
       " (11494344672,),\n",
       " (11487593691,),\n",
       " (11483117222,),\n",
       " (11475540888,),\n",
       " (11475540764,),\n",
       " (11475540110,),\n",
       " (11470297194,),\n",
       " (11464884350,),\n",
       " (11459730176,),\n",
       " (11450644334,),\n",
       " (11448368530,),\n",
       " (11443378649,),\n",
       " (11438988429,),\n",
       " (11430758599,),\n",
       " (11428064681,),\n",
       " (11423369317,),\n",
       " (11421073746,),\n",
       " (11421073564,),\n",
       " (11421073042,),\n",
       " (11415816462,),\n",
       " (11413060301,),\n",
       " (11397167243,),\n",
       " (11397167309,),\n",
       " (11386777742,),\n",
       " (11380880902,),\n",
       " (11376318896,),\n",
       " (11376318785,),\n",
       " (11373039106,),\n",
       " (11357381978,),\n",
       " (11357381959,),\n",
       " (11349043414,),\n",
       " (11341736564,),\n",
       " (11333960904,),\n",
       " (11333960726,),\n",
       " (11332444177,),\n",
       " (11331663681,),\n",
       " (11331661482,),\n",
       " (11325984649,),\n",
       " (11321993027,),\n",
       " (11319210251,),\n",
       " (11312142654,),\n",
       " (11312143098,),\n",
       " (11312142744,),\n",
       " (11306953605,),\n",
       " (11302365379,),\n",
       " (11294668760,),\n",
       " (11283511069,),\n",
       " (11283509861,),\n",
       " (11277204136,),\n",
       " (11277203100,),\n",
       " (11277202789,),\n",
       " (11268601463,),\n",
       " (11265361070,),\n",
       " (11257159604,),\n",
       " (11250560995,),\n",
       " (11235374103,),\n",
       " (11233434101,),\n",
       " (11227474036,),\n",
       " (11216571927,),\n",
       " (11213280896,),\n",
       " (11206042243,),\n",
       " (11206042174,),\n",
       " (11202097177,),\n",
       " (11194843170,),\n",
       " (11191665000,),\n",
       " (11184502794,),\n",
       " (11181505377,),\n",
       " (11173344407,),\n",
       " (11168193117,),\n",
       " (11163850500,),\n",
       " (11160716049,),\n",
       " (11153234046,),\n",
       " (11146348069,),\n",
       " (11138134093,),\n",
       " (11138133991,),\n",
       " (11122256725,),\n",
       " (11119996866,),\n",
       " (11114607248,),\n",
       " (11108446527,),\n",
       " (11101401802,),\n",
       " (11094119027,),\n",
       " (11078150339,),\n",
       " (11072797972,),\n",
       " (11065101548,),\n",
       " (11058139815,),\n",
       " (11051943676,),\n",
       " (11051943462,),\n",
       " (11045593100,),\n",
       " (11028860763,),\n",
       " (11028858993,),\n",
       " (11022141990,),\n",
       " (11017123982,),\n",
       " (11011628215,),\n",
       " (11004564101,),\n",
       " (10996053034,),\n",
       " (10974764415,),\n",
       " (10967596115,),\n",
       " (10961390702,),\n",
       " (10956049697,),\n",
       " (10954184610,),\n",
       " (10948837605,),\n",
       " (10940125731,),\n",
       " (10935261227,),\n",
       " (10933350789,),\n",
       " (10926058198,),\n",
       " (10912963300,),\n",
       " (10900195447,),\n",
       " (10878221432,),\n",
       " (10870636381,),\n",
       " (10860131012,),\n",
       " (10843631835,),\n",
       " (10837298783,),\n",
       " (10836986359,),\n",
       " (10830531566,),\n",
       " (10821852204,),\n",
       " (10810941641,),\n",
       " (10807566138,),\n",
       " (10803773496,),\n",
       " (10790383099,),\n",
       " (10789963909,),\n",
       " (10789963809,),\n",
       " (10782934961,),\n",
       " (10782941944,),\n",
       " (10780944994,),\n",
       " (10774929066,),\n",
       " (10770213885,),\n",
       " (10763354733,),\n",
       " (10763354795,),\n",
       " (10760871875,),\n",
       " (10756926206,),\n",
       " (10742049588,),\n",
       " (10735309799,),\n",
       " (10727604029,),\n",
       " (10723716112,),\n",
       " (10717796318,),\n",
       " (10717796460,),\n",
       " (10714882488,),\n",
       " (10712034499,),\n",
       " (10704247182,),\n",
       " (10703848188,),\n",
       " (10696633538,),\n",
       " (10690029020,),\n",
       " (10690027481,),\n",
       " (10687955322,),\n",
       " (10677861106,),\n",
       " (10671127032,),\n",
       " (10667851151,),\n",
       " (10667871110,),\n",
       " (10663914035,),\n",
       " (10648632268,),\n",
       " (10643027806,),\n",
       " (10635191931,),\n",
       " (10630653836,),\n",
       " (10623893255,),\n",
       " (10620505336,),\n",
       " (10617648106,),\n",
       " (10610245261,),\n",
       " (10604445753,),\n",
       " (10602450713,),\n",
       " (10597048353,),\n",
       " (10595951171,),\n",
       " (10588558097,),\n",
       " (10585063490,),\n",
       " (10583226661,),\n",
       " (10579427001,),\n",
       " (10579199481,),\n",
       " (10576234152,),\n",
       " (10571709332,),\n",
       " (10564180633,),\n",
       " (10557990855,),\n",
       " (10551423210,),\n",
       " (10551424656,),\n",
       " (10540840626,),\n",
       " (10540836379,),\n",
       " (10535056764,),\n",
       " (10531416124,),\n",
       " (10527543246,),\n",
       " (10526085682,),\n",
       " (10520861863,),\n",
       " (10513185449,),\n",
       " (10513183862,),\n",
       " (10508586606,),\n",
       " (10501609411,),\n",
       " (10495669660,),\n",
       " (10494016114,),\n",
       " (10489938279,),\n",
       " (11054670097,),\n",
       " (10482586929,),\n",
       " (10470606086,),\n",
       " (10463466389,),\n",
       " (10458820635,),\n",
       " (10453302485,),\n",
       " (10446670000,),\n",
       " (10441377219,),\n",
       " (10441376371,),\n",
       " (10434798081,),\n",
       " (10431643622,),\n",
       " (10430424552,),\n",
       " (10426484166,),\n",
       " (10421527021,),\n",
       " (10419973404,),\n",
       " (10416928200,),\n",
       " (10412047037,),\n",
       " (10407150403,),\n",
       " (10406487963,),\n",
       " (10396346146,),\n",
       " (10391500811,),\n",
       " (10386281563,),\n",
       " (10386278575,),\n",
       " (10381577104,),\n",
       " (10376482892,),\n",
       " (10371143401,),\n",
       " (10354835901,),\n",
       " (10354152467,),\n",
       " (10350136814,),\n",
       " (10345861661,),\n",
       " (10340255699,),\n",
       " (10334887183,),\n",
       " (10324718678,),\n",
       " (10324448435,),\n",
       " (10318819092,),\n",
       " (10312318615,),\n",
       " (10308805764,),\n",
       " (10303617382,),\n",
       " (10303607950,),\n",
       " (10298773027,),\n",
       " (10287564574,),\n",
       " (10280151641,),\n",
       " (10274022718,),\n",
       " (10270769960,),\n",
       " (10270769951,),\n",
       " (10268768931,),\n",
       " (10268774464,),\n",
       " (10268761272,),\n",
       " (10265500779,),\n",
       " (10259690670,),\n",
       " (10248293754,),\n",
       " (10242401412,),\n",
       " (10231871540,),\n",
       " (10231870680,),\n",
       " (10231871405,),\n",
       " (10230810198,),\n",
       " (10226151608,),\n",
       " (10226151955,),\n",
       " (10220381546,),\n",
       " (10207364268,),\n",
       " (10201219639,),\n",
       " (10195753224,),\n",
       " (10193054376,),\n",
       " (10185835465,),\n",
       " (10185839085,),\n",
       " (10179742263,),\n",
       " (10179741912,),\n",
       " (10160196622,),\n",
       " (10154962304,),\n",
       " (10150968958,),\n",
       " (10145081601,),\n",
       " (10136012151,),\n",
       " (10127320649,),\n",
       " (10119736272,),\n",
       " (10104934052,),\n",
       " (10102075916,),\n",
       " (10098798404,),\n",
       " (10095913328,),\n",
       " (10092577146,),\n",
       " (10090007607,),\n",
       " (10085358212,),\n",
       " (10085358039,),\n",
       " (10078348527,),\n",
       " (10074584222,),\n",
       " (10063927946,),\n",
       " (10058051471,),\n",
       " (10044511638,),\n",
       " (10043933112,),\n",
       " (10037950016,),\n",
       " (10037207760,),\n",
       " (10027965949,),\n",
       " (10028085397,),\n",
       " (10028086602,),\n",
       " (10015713698,),\n",
       " (10002190649,),\n",
       " (9994458704,),\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_activity_ids(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT id\n",
    "        FROM activities \n",
    "        order by start_date desc\n",
    "              \"\"\")\n",
    "    \n",
    "    count = c.fetchall()\n",
    "    conn.close()\n",
    "    return count\n",
    "\n",
    "get_all_activity_ids(DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa82278",
   "metadata": {},
   "source": [
    "#### Simple Query to get all Activity IDs with HR and presumably Streams data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "633dd597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_activity_ids_with_HR(db_path):\n",
    "    \"\"\"Get all activity ids that have HR data, which hopefully will help us avoid a 404 call on the streams data.\n",
    "    My thinking is that if no HR data, we probably have no streams data at all.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT id\n",
    "        FROM activities \n",
    "        WHERE has_heartrate = 1\n",
    "        order by start_date desc\n",
    "              \"\"\")\n",
    "    \n",
    "    count = c.fetchall()\n",
    "    conn.close()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec04d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_activity_import_date(db_path):\n",
    "    \"\"\"Query for latest activity import_date as a unix timestamp\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT max(import_date)\n",
    "        FROM activities \n",
    "    \"\"\")\n",
    "    \n",
    "    record = c.fetchone()[0]\n",
    "    conn.close()\n",
    "    dt = datetime.strptime(record, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    return int(dt.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "724af76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1747316241"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_activity_import_date(DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b6bcb",
   "metadata": {},
   "source": [
    "## Database Streams Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830ece9",
   "metadata": {},
   "source": [
    "#### Initialize DB  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b271fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_streams_db():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS streams (\n",
    "        activity_id INTEGER PRIMARY KEY,\n",
    "        \n",
    "        time_data TEXT,\n",
    "        time_series_type TEXT,\n",
    "        time_original_size INTEGER,\n",
    "        time_resolution TEXT,\n",
    "\n",
    "        distance_data TEXT,\n",
    "        distance_series_type TEXT,\n",
    "        distance_original_size INTEGER,\n",
    "        distance_resolution TEXT,\n",
    "\n",
    "        latlng_data TEXT,\n",
    "        latlng_series_type TEXT,\n",
    "        latlng_original_size INTEGER,\n",
    "        latlng_resolution TEXT,\n",
    "\n",
    "        altitude_data TEXT,\n",
    "        altitude_series_type TEXT,\n",
    "        altitude_original_size INTEGER,\n",
    "        altitude_resolution TEXT,\n",
    "\n",
    "        velocity_smooth_data TEXT,\n",
    "        velocity_smooth_series_type TEXT,\n",
    "        velocity_smooth_original_size INTEGER,\n",
    "        velocity_smooth_resolution TEXT,\n",
    "\n",
    "        heartrate_data TEXT,\n",
    "        heartrate_series_type TEXT,\n",
    "        heartrate_original_size INTEGER,\n",
    "        heartrate_resolution TEXT,\n",
    "\n",
    "        cadence_data TEXT,\n",
    "        cadence_series_type TEXT,\n",
    "        cadence_original_size INTEGER,\n",
    "        cadence_resolution TEXT,\n",
    "\n",
    "        watts_data TEXT,\n",
    "        watts_series_type TEXT,\n",
    "        watts_original_size INTEGER,\n",
    "        watts_resolution TEXT,\n",
    "\n",
    "        moving_data TEXT,\n",
    "        moving_series_type TEXT,\n",
    "        moving_original_size INTEGER,\n",
    "        moving_resolution TEXT,\n",
    "\n",
    "        grade_smooth_data TEXT,\n",
    "        grade_smooth_series_type TEXT,\n",
    "        grade_smooth_original_size INTEGER,\n",
    "        grade_smooth_resolution TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3edeb1",
   "metadata": {},
   "source": [
    "#### Insert Stream Data for Single Activity ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dc06439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_stream_data(activity_id, stream_dict, db_path):\n",
    "    \"\"\"\n",
    "    Inserts or replaces a row in the streams table for a given activity_id.\n",
    "    stream_dict should have keys like 'time', 'distance', etc., with each value a dict containing:\n",
    "    {\n",
    "        'data': [...],\n",
    "        'series_type': '...',\n",
    "        'original_size': ...,\n",
    "        'resolution': '...'\n",
    "    }\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Create the column mappings dynamically\n",
    "    base_columns = []\n",
    "    placeholders = []\n",
    "    values = []\n",
    "\n",
    "    # Always include activity_id\n",
    "    base_columns.append(\"activity_id\")\n",
    "    placeholders.append(\"?\")\n",
    "    values.append(activity_id)\n",
    "\n",
    "    for key, val in stream_dict.items():\n",
    "        if not isinstance(val, dict):\n",
    "            continue  # skip malformed\n",
    "\n",
    "        base_columns.extend([\n",
    "            f\"{key}_data\",\n",
    "            f\"{key}_series_type\",\n",
    "            f\"{key}_original_size\",\n",
    "            f\"{key}_resolution\"\n",
    "        ])\n",
    "        placeholders.extend([\"?\"] * 4)\n",
    "\n",
    "        values.extend([\n",
    "            json.dumps(val.get(\"data\")),\n",
    "            val.get(\"series_type\"),\n",
    "            val.get(\"original_size\"),\n",
    "            val.get(\"resolution\")\n",
    "        ])\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        INSERT INTO streams ({', '.join(base_columns)})\n",
    "        VALUES ({', '.join(placeholders)})\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    try:\n",
    "        c.execute(sql, values)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    except sqlite3.IntegrityError:\n",
    "        print(f\"Activity {activity_id} already exists in the 'streams' table. Skipping insert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2685191d",
   "metadata": {},
   "source": [
    "#### Simple Query to Get all activity IDs from Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5fe5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_activity_ids_streams(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT activity_id\n",
    "        FROM streams \n",
    "              \"\"\")\n",
    "    \n",
    "    count = c.fetchall()\n",
    "    conn.close()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f4a4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Simple Query to Get all Streams for latest activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aee83f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_stream_example(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    # Run query and load into DataFrame (with column headers)\n",
    "    df = pd.read_sql_query(\n",
    "        \"\"\"\n",
    "WITH daily_load AS (\n",
    "                SELECT \n",
    "                    date(datetime(start_date)) as date,\n",
    "                    -- Using distance * speed as load proxy (training impulse)\n",
    "                    SUM(average_speed * moving_time / 1000.0) as daily_load\n",
    "                FROM activities\n",
    "                WHERE type = 'Run'\n",
    "                GROUP BY date\n",
    "            )\n",
    "                -- Create a continuous date series to handle missing days\n",
    "                SELECT date(date('now', '-90 days') + (n-1) || ' days') as date\n",
    "                FROM (\n",
    "                    SELECT row_number() OVER () as n \n",
    "                    FROM activities LIMIT 91\n",
    "                )\n",
    "                WHERE date <= date('now')\n",
    "\n",
    "    \"\"\",\n",
    "        conn\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ae79ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4707-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4707-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4707-06-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4707-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4707-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-4707-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-4707-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>-4707-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-4707-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-4707-09-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date\n",
       "0   -4707-06-10\n",
       "1   -4707-06-11\n",
       "2   -4707-06-12\n",
       "3   -4707-06-13\n",
       "4   -4707-06-14\n",
       "..          ...\n",
       "86  -4707-09-04\n",
       "87  -4707-09-05\n",
       "88  -4707-09-06\n",
       "89  -4707-09-07\n",
       "90  -4707-09-08\n",
       "\n",
       "[91 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = single_stream_example(DB_PATH)\n",
    "test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca1d93d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42870"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.time_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e33d9b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36550"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.heartrate_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8272de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tester(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    # Run query and load into DataFrame (with column headers)\n",
    "    df = pd.read_sql_query(\n",
    "        \"\"\"\n",
    "SELECT\n",
    "            activity_id,\n",
    "            MIN(CAST(time_data AS INTEGER)) AS min_time,\n",
    "            MAX(CAST(time_data AS INTEGER)) AS max_time,\n",
    "            (MAX(CAST(time_data AS INTEGER)) - MIN(CAST(time_data AS INTEGER))) AS total_duration\n",
    "        FROM streams\n",
    "        GROUP BY activity_id\n",
    "    \"\"\",\n",
    "        conn\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a348da87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>total_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2056073959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2058321970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2063976670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2070854538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2070854539</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>14465685256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>14472461251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>14477593705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>14483199626</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>14487474408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2760 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      activity_id  min_time  max_time  total_duration\n",
       "0      2056073959         0         0               0\n",
       "1      2058321970         0         0               0\n",
       "2      2063976670         0         0               0\n",
       "3      2070854538         0         0               0\n",
       "4      2070854539         0         0               0\n",
       "...           ...       ...       ...             ...\n",
       "2755  14465685256         0         0               0\n",
       "2756  14472461251         0         0               0\n",
       "2757  14477593705         0         0               0\n",
       "2758  14483199626         0         0               0\n",
       "2759  14487474408         0         0               0\n",
       "\n",
       "[2760 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tester(DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8c03c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streams_data(activity_id, db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT distance_data, heartrate_data, altitude_data FROM streams WHERE activity_id = ?\", (activity_id,))\n",
    "    row = cur.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if row:\n",
    "        try:\n",
    "            distance = json.loads(row[0]) if row[0] else []\n",
    "            heartrate = json.loads(row[1]) if row[1] else []\n",
    "            altitude = json.loads(row[2]) if row[2] else []\n",
    "            return distance, heartrate, altitude\n",
    "        except Exception as e:\n",
    "            print(\"Failed to load stream data:\", e)\n",
    "    return [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf8ef13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = get_streams_data(14477593705, DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da0a4625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.5,\n",
       "  5.0,\n",
       "  6.0,\n",
       "  7.0,\n",
       "  8.5,\n",
       "  10.0,\n",
       "  12.0,\n",
       "  14.0,\n",
       "  16.5,\n",
       "  19.0,\n",
       "  21.5,\n",
       "  24.0,\n",
       "  27.0,\n",
       "  30.0,\n",
       "  33.0,\n",
       "  36.0,\n",
       "  38.5,\n",
       "  41.0,\n",
       "  43.5,\n",
       "  46.0,\n",
       "  49.0,\n",
       "  52.0,\n",
       "  54.5,\n",
       "  57.0,\n",
       "  59.5,\n",
       "  62.0,\n",
       "  64.5,\n",
       "  67.0,\n",
       "  69.5,\n",
       "  72.0,\n",
       "  75.0,\n",
       "  78.0,\n",
       "  81.5,\n",
       "  85.0,\n",
       "  87.5,\n",
       "  90.0,\n",
       "  93.0,\n",
       "  96.0,\n",
       "  100.0,\n",
       "  104.0,\n",
       "  106.0,\n",
       "  108.0,\n",
       "  110.5,\n",
       "  113.0,\n",
       "  115.5,\n",
       "  118.0,\n",
       "  120.5,\n",
       "  123.0,\n",
       "  125.5,\n",
       "  128.0,\n",
       "  130.5,\n",
       "  133.0,\n",
       "  135.5,\n",
       "  138.0,\n",
       "  142.0,\n",
       "  146.0,\n",
       "  148.5,\n",
       "  151.0,\n",
       "  154.0,\n",
       "  157.0,\n",
       "  160.0,\n",
       "  163.0,\n",
       "  165.5,\n",
       "  168.0,\n",
       "  170.5,\n",
       "  173.0,\n",
       "  175.5,\n",
       "  178.0,\n",
       "  181.0,\n",
       "  184.0,\n",
       "  186.0,\n",
       "  188.0,\n",
       "  188.0,\n",
       "  188.0,\n",
       "  190.0,\n",
       "  192.0,\n",
       "  195.0,\n",
       "  198.0,\n",
       "  201.5,\n",
       "  205.0,\n",
       "  208.5,\n",
       "  212.0,\n",
       "  214.5,\n",
       "  217.0,\n",
       "  220.0,\n",
       "  223.0,\n",
       "  225.5,\n",
       "  228.0,\n",
       "  230.0,\n",
       "  232.0,\n",
       "  234.5,\n",
       "  237.0,\n",
       "  239.5,\n",
       "  242.0,\n",
       "  244.5,\n",
       "  247.0,\n",
       "  249.5,\n",
       "  252.0,\n",
       "  254.5,\n",
       "  257.0,\n",
       "  259.5,\n",
       "  262.0,\n",
       "  264.5,\n",
       "  267.0,\n",
       "  270.5,\n",
       "  274.0,\n",
       "  277.0,\n",
       "  280.0,\n",
       "  283.0,\n",
       "  286.0,\n",
       "  288.5,\n",
       "  291.0,\n",
       "  293.5,\n",
       "  296.0,\n",
       "  299.0,\n",
       "  302.0,\n",
       "  304.0,\n",
       "  306.0,\n",
       "  309.0,\n",
       "  312.0,\n",
       "  314.5,\n",
       "  317.0,\n",
       "  319.5,\n",
       "  322.0,\n",
       "  324.5,\n",
       "  327.0,\n",
       "  330.0,\n",
       "  333.0,\n",
       "  335.5,\n",
       "  338.0,\n",
       "  340.5,\n",
       "  343.0,\n",
       "  345.5,\n",
       "  348.0,\n",
       "  350.5,\n",
       "  353.0,\n",
       "  355.0,\n",
       "  357.0,\n",
       "  359.5,\n",
       "  362.0,\n",
       "  364.0,\n",
       "  366.0,\n",
       "  366.0,\n",
       "  366.0,\n",
       "  367.5,\n",
       "  369.0,\n",
       "  369.5,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  370.0,\n",
       "  371.5,\n",
       "  373.0,\n",
       "  373.5,\n",
       "  374.0,\n",
       "  374.0,\n",
       "  374.0,\n",
       "  374.0,\n",
       "  374.0,\n",
       "  377.0,\n",
       "  380.0,\n",
       "  380.0,\n",
       "  380.0,\n",
       "  380.0,\n",
       "  380.0,\n",
       "  380.0,\n",
       "  380.0,\n",
       "  380.0,\n",
       "  380.0,\n",
       "  380.0,\n",
       "  380.0,\n",
       "  381.5,\n",
       "  383.0,\n",
       "  384.0,\n",
       "  385.0,\n",
       "  385.5,\n",
       "  386.0,\n",
       "  388.0,\n",
       "  390.0,\n",
       "  391.5,\n",
       "  393.0,\n",
       "  395.5,\n",
       "  398.0,\n",
       "  401.0,\n",
       "  404.0,\n",
       "  406.5,\n",
       "  409.0,\n",
       "  411.5,\n",
       "  414.0,\n",
       "  416.5,\n",
       "  419.0,\n",
       "  422.0,\n",
       "  425.0,\n",
       "  428.0,\n",
       "  431.0,\n",
       "  434.5,\n",
       "  438.0,\n",
       "  441.5,\n",
       "  445.0,\n",
       "  448.5,\n",
       "  452.0,\n",
       "  454.5,\n",
       "  457.0,\n",
       "  459.5,\n",
       "  462.0,\n",
       "  464.5,\n",
       "  467.0,\n",
       "  470.0,\n",
       "  473.0,\n",
       "  476.0,\n",
       "  479.0,\n",
       "  482.0,\n",
       "  485.0,\n",
       "  487.5,\n",
       "  490.0,\n",
       "  492.0,\n",
       "  494.0,\n",
       "  497.0,\n",
       "  500.0,\n",
       "  502.0,\n",
       "  504.0,\n",
       "  506.5,\n",
       "  509.0,\n",
       "  512.0,\n",
       "  515.0,\n",
       "  518.0,\n",
       "  521.0,\n",
       "  524.5,\n",
       "  528.0,\n",
       "  531.0,\n",
       "  534.0,\n",
       "  536.5,\n",
       "  539.0,\n",
       "  542.0,\n",
       "  545.0,\n",
       "  548.5,\n",
       "  552.0,\n",
       "  555.0,\n",
       "  558.0,\n",
       "  561.0,\n",
       "  564.0,\n",
       "  566.5,\n",
       "  569.0,\n",
       "  571.5,\n",
       "  574.0,\n",
       "  576.5,\n",
       "  579.0,\n",
       "  582.0,\n",
       "  585.0,\n",
       "  587.5,\n",
       "  590.0,\n",
       "  593.0,\n",
       "  596.0,\n",
       "  598.5,\n",
       "  601.0,\n",
       "  604.0,\n",
       "  607.0,\n",
       "  610.0,\n",
       "  613.0,\n",
       "  615.5,\n",
       "  618.0,\n",
       "  621.0,\n",
       "  624.0,\n",
       "  626.5,\n",
       "  629.0,\n",
       "  632.0,\n",
       "  635.0,\n",
       "  637.5,\n",
       "  640.0,\n",
       "  642.5,\n",
       "  645.0,\n",
       "  648.0,\n",
       "  651.0,\n",
       "  654.0,\n",
       "  657.0,\n",
       "  659.5,\n",
       "  662.0,\n",
       "  664.5,\n",
       "  667.0,\n",
       "  669.5,\n",
       "  672.0,\n",
       "  674.5,\n",
       "  677.0,\n",
       "  680.0,\n",
       "  683.0,\n",
       "  686.0,\n",
       "  689.0,\n",
       "  692.0,\n",
       "  695.0,\n",
       "  697.5,\n",
       "  700.0,\n",
       "  703.0,\n",
       "  706.0,\n",
       "  709.0,\n",
       "  712.0,\n",
       "  714.5,\n",
       "  717.0,\n",
       "  720.0,\n",
       "  723.0,\n",
       "  726.0,\n",
       "  729.0,\n",
       "  732.0,\n",
       "  735.0,\n",
       "  738.5,\n",
       "  742.0,\n",
       "  745.0,\n",
       "  748.0,\n",
       "  751.5,\n",
       "  755.0,\n",
       "  757.5,\n",
       "  760.0,\n",
       "  763.0,\n",
       "  766.0,\n",
       "  768.5,\n",
       "  771.0,\n",
       "  774.0,\n",
       "  777.0,\n",
       "  780.0,\n",
       "  783.0,\n",
       "  786.0,\n",
       "  789.0,\n",
       "  791.5,\n",
       "  794.0,\n",
       "  797.0,\n",
       "  800.0,\n",
       "  802.5,\n",
       "  805.0,\n",
       "  808.0,\n",
       "  811.0,\n",
       "  813.5,\n",
       "  816.0,\n",
       "  818.5,\n",
       "  821.0,\n",
       "  823.5,\n",
       "  826.0,\n",
       "  829.0,\n",
       "  832.0,\n",
       "  835.0,\n",
       "  838.0,\n",
       "  841.5,\n",
       "  845.0,\n",
       "  847.5,\n",
       "  850.0,\n",
       "  852.5,\n",
       "  855.0,\n",
       "  857.5,\n",
       "  860.0,\n",
       "  863.5,\n",
       "  867.0,\n",
       "  870.0,\n",
       "  873.0,\n",
       "  875.5,\n",
       "  878.0,\n",
       "  881.0,\n",
       "  884.0,\n",
       "  887.0,\n",
       "  890.0,\n",
       "  893.0,\n",
       "  896.0,\n",
       "  898.5,\n",
       "  901.0,\n",
       "  904.5,\n",
       "  908.0,\n",
       "  910.5,\n",
       "  913.0,\n",
       "  916.0,\n",
       "  919.0,\n",
       "  921.0,\n",
       "  923.0,\n",
       "  926.5,\n",
       "  930.0,\n",
       "  933.0,\n",
       "  936.0,\n",
       "  939.5,\n",
       "  943.0,\n",
       "  946.5,\n",
       "  950.0,\n",
       "  953.0,\n",
       "  956.0,\n",
       "  959.0,\n",
       "  962.0,\n",
       "  965.0,\n",
       "  968.0,\n",
       "  971.0,\n",
       "  974.0,\n",
       "  976.5,\n",
       "  979.0,\n",
       "  982.5,\n",
       "  986.0,\n",
       "  989.0,\n",
       "  992.0,\n",
       "  995.0,\n",
       "  998.0,\n",
       "  1001.0,\n",
       "  1004.0,\n",
       "  1006.5,\n",
       "  1009.0,\n",
       "  1012.0,\n",
       "  1015.0,\n",
       "  1017.5,\n",
       "  1020.0,\n",
       "  1023.0,\n",
       "  1026.0,\n",
       "  1028.0,\n",
       "  1030.0,\n",
       "  1033.0,\n",
       "  1036.0,\n",
       "  1038.5,\n",
       "  1041.0,\n",
       "  1044.0,\n",
       "  1047.0,\n",
       "  1049.5,\n",
       "  1052.0,\n",
       "  1054.5,\n",
       "  1057.0,\n",
       "  1060.0,\n",
       "  1063.0,\n",
       "  1065.5,\n",
       "  1068.0,\n",
       "  1071.0,\n",
       "  1074.0,\n",
       "  1077.0,\n",
       "  1080.0,\n",
       "  1082.0,\n",
       "  1084.0,\n",
       "  1087.0,\n",
       "  1090.0,\n",
       "  1092.5,\n",
       "  1095.0,\n",
       "  1098.0,\n",
       "  1101.0,\n",
       "  1103.5,\n",
       "  1106.0,\n",
       "  1109.5,\n",
       "  1113.0,\n",
       "  1116.0,\n",
       "  1119.0,\n",
       "  1121.5,\n",
       "  1124.0,\n",
       "  1126.5,\n",
       "  1129.0,\n",
       "  1132.0,\n",
       "  1135.0,\n",
       "  1137.5,\n",
       "  1140.0,\n",
       "  1142.5,\n",
       "  1145.0,\n",
       "  1147.5,\n",
       "  1150.0,\n",
       "  1153.0,\n",
       "  1156.0,\n",
       "  1159.0,\n",
       "  1162.0,\n",
       "  1165.0,\n",
       "  1168.0,\n",
       "  1170.5,\n",
       "  1173.0,\n",
       "  1176.0,\n",
       "  1179.0,\n",
       "  1181.5,\n",
       "  1184.0,\n",
       "  1187.5,\n",
       "  1191.0,\n",
       "  1194.0,\n",
       "  1197.0,\n",
       "  1200.0,\n",
       "  1203.0,\n",
       "  1206.0,\n",
       "  1209.0,\n",
       "  1212.5,\n",
       "  1216.0,\n",
       "  1218.5,\n",
       "  1221.0,\n",
       "  1223.5,\n",
       "  1226.0,\n",
       "  1229.0,\n",
       "  1232.0,\n",
       "  1234.5,\n",
       "  1237.0,\n",
       "  1240.0,\n",
       "  1243.0,\n",
       "  1245.5,\n",
       "  1248.0,\n",
       "  1251.5,\n",
       "  1255.0,\n",
       "  1257.5,\n",
       "  1260.0,\n",
       "  1263.0,\n",
       "  1266.0,\n",
       "  1268.5,\n",
       "  1271.0,\n",
       "  1273.5,\n",
       "  1276.0,\n",
       "  1279.5,\n",
       "  1283.0,\n",
       "  1285.5,\n",
       "  1288.0,\n",
       "  1291.0,\n",
       "  1294.0,\n",
       "  1296.5,\n",
       "  1299.0,\n",
       "  1301.5,\n",
       "  1304.0,\n",
       "  1307.0,\n",
       "  1310.0,\n",
       "  1312.0,\n",
       "  1314.0,\n",
       "  1317.0,\n",
       "  1320.0,\n",
       "  1323.0,\n",
       "  1326.0,\n",
       "  1329.0,\n",
       "  1332.0,\n",
       "  1334.5,\n",
       "  1337.0,\n",
       "  1339.5,\n",
       "  1342.0,\n",
       "  1345.0,\n",
       "  1348.0,\n",
       "  1350.5,\n",
       "  1353.0,\n",
       "  1356.0,\n",
       "  1359.0,\n",
       "  1361.5,\n",
       "  1364.0,\n",
       "  1367.5,\n",
       "  1371.0,\n",
       "  1374.0,\n",
       "  1377.0,\n",
       "  1380.0,\n",
       "  1383.0,\n",
       "  1385.5,\n",
       "  1388.0,\n",
       "  1391.0,\n",
       "  1394.0,\n",
       "  1397.0,\n",
       "  1400.0,\n",
       "  1402.5,\n",
       "  1405.0,\n",
       "  1408.5,\n",
       "  1412.0,\n",
       "  1415.0,\n",
       "  1418.0,\n",
       "  1421.0,\n",
       "  1424.0,\n",
       "  1427.0,\n",
       "  1430.0,\n",
       "  1433.0,\n",
       "  1436.0,\n",
       "  1439.5,\n",
       "  1443.0,\n",
       "  1446.5,\n",
       "  1450.0,\n",
       "  1454.0,\n",
       "  1458.0,\n",
       "  1461.5,\n",
       "  1465.0,\n",
       "  1469.0,\n",
       "  1473.0,\n",
       "  1476.0,\n",
       "  1479.0,\n",
       "  1482.5,\n",
       "  1486.0,\n",
       "  1489.0,\n",
       "  1492.0,\n",
       "  1495.5,\n",
       "  1499.0,\n",
       "  1501.5,\n",
       "  1504.0,\n",
       "  1507.5,\n",
       "  1511.0,\n",
       "  1514.0,\n",
       "  1517.0,\n",
       "  1519.5,\n",
       "  1522.0,\n",
       "  1525.0,\n",
       "  1528.0,\n",
       "  1531.5,\n",
       "  1535.0,\n",
       "  1537.5,\n",
       "  1540.0,\n",
       "  1543.0,\n",
       "  1546.0,\n",
       "  1549.0,\n",
       "  1552.0,\n",
       "  1555.0,\n",
       "  1558.0,\n",
       "  1561.0,\n",
       "  1564.0,\n",
       "  1567.0,\n",
       "  1570.0,\n",
       "  1573.0,\n",
       "  1576.0,\n",
       "  1578.5,\n",
       "  1581.0,\n",
       "  1584.0,\n",
       "  1587.0,\n",
       "  1589.0,\n",
       "  1591.0,\n",
       "  1593.5,\n",
       "  1596.0,\n",
       "  1598.5,\n",
       "  1601.0,\n",
       "  1603.5,\n",
       "  1606.0,\n",
       "  1609.0,\n",
       "  1612.0,\n",
       "  1614.0,\n",
       "  1616.0,\n",
       "  1618.5,\n",
       "  1621.0,\n",
       "  1624.0,\n",
       "  1627.0,\n",
       "  1630.0,\n",
       "  1633.0,\n",
       "  1635.5,\n",
       "  1638.0,\n",
       "  1641.0,\n",
       "  1644.0,\n",
       "  1646.0,\n",
       "  1648.0,\n",
       "  1650.5,\n",
       "  1653.0,\n",
       "  1655.5,\n",
       "  1658.0,\n",
       "  1661.0,\n",
       "  1664.0,\n",
       "  1666.5,\n",
       "  1669.0,\n",
       "  1671.5,\n",
       "  1674.0,\n",
       "  1677.0,\n",
       "  1680.0,\n",
       "  1682.5,\n",
       "  1685.0,\n",
       "  1688.5,\n",
       "  1692.0,\n",
       "  1695.5,\n",
       "  1699.0,\n",
       "  1701.0,\n",
       "  1703.0,\n",
       "  1706.0,\n",
       "  1709.0,\n",
       "  1712.0,\n",
       "  1715.0,\n",
       "  1717.5,\n",
       "  1720.0,\n",
       "  1723.0,\n",
       "  1726.0,\n",
       "  1729.0,\n",
       "  1732.0,\n",
       "  1734.5,\n",
       "  1737.0,\n",
       "  1739.0,\n",
       "  1741.0,\n",
       "  1743.0,\n",
       "  1745.0,\n",
       "  1746.5,\n",
       "  1748.0,\n",
       "  1751.0,\n",
       "  1754.0,\n",
       "  1756.1,\n",
       "  1757.2,\n",
       "  1758.3,\n",
       "  1759.4,\n",
       "  1760.5,\n",
       "  1765.0,\n",
       "  1767.5,\n",
       "  1770.0,\n",
       "  1772.0,\n",
       "  1774.0,\n",
       "  1775.0,\n",
       "  1776.0,\n",
       "  1777.5,\n",
       "  1779.0,\n",
       "  1781.5,\n",
       "  1784.0,\n",
       "  1786.0,\n",
       "  1788.0,\n",
       "  1790.5,\n",
       "  1793.0,\n",
       "  1796.0,\n",
       "  1799.0,\n",
       "  1801.5,\n",
       "  1804.0,\n",
       "  1807.0,\n",
       "  1810.0,\n",
       "  1813.0,\n",
       "  1816.0,\n",
       "  1819.0,\n",
       "  1822.0,\n",
       "  1825.5,\n",
       "  1829.0,\n",
       "  1832.5,\n",
       "  1836.0,\n",
       "  1839.0,\n",
       "  1842.0,\n",
       "  1844.0,\n",
       "  1846.0,\n",
       "  1849.0,\n",
       "  1852.0,\n",
       "  1854.5,\n",
       "  1857.0,\n",
       "  1859.5,\n",
       "  1862.0,\n",
       "  1865.5,\n",
       "  1869.0,\n",
       "  1871.5,\n",
       "  1874.0,\n",
       "  1877.5,\n",
       "  1881.0,\n",
       "  1884.0,\n",
       "  1887.0,\n",
       "  1889.5,\n",
       "  1892.0,\n",
       "  1895.0,\n",
       "  1898.0,\n",
       "  1901.0,\n",
       "  1904.0,\n",
       "  1907.0,\n",
       "  1910.0,\n",
       "  1913.0,\n",
       "  1916.0,\n",
       "  1918.5,\n",
       "  1921.0,\n",
       "  1924.0,\n",
       "  1927.0,\n",
       "  1929.0,\n",
       "  1931.0,\n",
       "  1933.5,\n",
       "  1936.0,\n",
       "  1939.0,\n",
       "  1942.0,\n",
       "  1945.5,\n",
       "  1949.0,\n",
       "  1952.0,\n",
       "  1955.0,\n",
       "  1958.0,\n",
       "  1961.0,\n",
       "  1962.5,\n",
       "  1964.0,\n",
       "  1965.5,\n",
       "  1967.0,\n",
       "  1969.5,\n",
       "  1972.0,\n",
       "  1974.5,\n",
       "  1977.0,\n",
       "  1979.5,\n",
       "  1982.0,\n",
       "  1985.5,\n",
       "  1989.0,\n",
       "  1992.5,\n",
       "  1996.0,\n",
       "  1999.0,\n",
       "  2002.0,\n",
       "  2004.0,\n",
       "  2006.0,\n",
       "  2008.5,\n",
       "  2011.0,\n",
       "  2013.5,\n",
       "  2016.0,\n",
       "  2019.5,\n",
       "  2023.0,\n",
       "  2026.0,\n",
       "  2029.0,\n",
       "  2033.0,\n",
       "  2037.0,\n",
       "  2039.5,\n",
       "  2042.0,\n",
       "  2045.0,\n",
       "  2048.0,\n",
       "  2050.5,\n",
       "  2053.0,\n",
       "  2055.0,\n",
       "  2057.0,\n",
       "  2060.0,\n",
       "  2063.0,\n",
       "  2066.0,\n",
       "  2069.0,\n",
       "  2071.5,\n",
       "  2074.0,\n",
       "  2077.0,\n",
       "  2080.0,\n",
       "  2082.5,\n",
       "  2085.0,\n",
       "  2087.0,\n",
       "  2089.0,\n",
       "  2091.0,\n",
       "  2093.0,\n",
       "  2096.5,\n",
       "  2100.0,\n",
       "  2102.5,\n",
       "  2105.0,\n",
       "  2108.0,\n",
       "  2111.0,\n",
       "  2113.0,\n",
       "  2115.0,\n",
       "  2117.0,\n",
       "  2119.0,\n",
       "  2121.5,\n",
       "  2124.0,\n",
       "  2127.0,\n",
       "  2130.0,\n",
       "  2132.5,\n",
       "  2135.0,\n",
       "  2138.0,\n",
       "  2141.0,\n",
       "  2144.5,\n",
       "  2148.0,\n",
       "  2150.5,\n",
       "  2153.0,\n",
       "  2156.5,\n",
       "  2160.0,\n",
       "  2162.5,\n",
       "  2165.0,\n",
       "  2167.5,\n",
       "  2170.0,\n",
       "  2172.0,\n",
       "  2174.0,\n",
       "  2176.5,\n",
       "  2179.0,\n",
       "  2182.0,\n",
       "  2185.0,\n",
       "  2187.5,\n",
       "  2190.0,\n",
       "  2193.0,\n",
       "  2196.0,\n",
       "  2199.0,\n",
       "  2202.0,\n",
       "  2204.5,\n",
       "  2207.0,\n",
       "  2210.0,\n",
       "  2213.0,\n",
       "  2216.0,\n",
       "  2219.0,\n",
       "  2221.5,\n",
       "  2224.0,\n",
       "  2227.0,\n",
       "  2230.0,\n",
       "  2232.5,\n",
       "  2235.0,\n",
       "  2238.0,\n",
       "  2241.0,\n",
       "  2243.0,\n",
       "  2245.0,\n",
       "  2248.0,\n",
       "  2251.0,\n",
       "  2254.0,\n",
       "  2257.0,\n",
       "  2259.5,\n",
       "  2262.0,\n",
       "  2264.5,\n",
       "  2267.0,\n",
       "  2272.0,\n",
       "  2277.0,\n",
       "  2280.5,\n",
       "  2284.0,\n",
       "  2286.0,\n",
       "  2288.0,\n",
       "  2291.0,\n",
       "  2294.0,\n",
       "  2296.5,\n",
       "  2299.0,\n",
       "  2301.5,\n",
       "  2304.0,\n",
       "  2307.0,\n",
       "  2310.0,\n",
       "  2312.5,\n",
       "  2315.0,\n",
       "  2317.5,\n",
       "  2320.0,\n",
       "  2323.0,\n",
       "  2326.0,\n",
       "  2328.0,\n",
       "  2330.0,\n",
       "  2333.0,\n",
       "  2336.0,\n",
       "  2339.0,\n",
       "  2342.0,\n",
       "  2345.0,\n",
       "  2348.0,\n",
       "  2351.5,\n",
       "  2355.0,\n",
       "  2359.0,\n",
       "  2363.0,\n",
       "  2366.0,\n",
       "  2369.0,\n",
       "  2372.0,\n",
       "  2375.0,\n",
       "  2378.0,\n",
       "  2381.0,\n",
       "  2384.0,\n",
       "  2387.0,\n",
       "  2390.0,\n",
       "  2393.0,\n",
       "  2396.5,\n",
       "  2400.0,\n",
       "  2402.5,\n",
       "  2405.0,\n",
       "  2408.0,\n",
       "  2411.0,\n",
       "  2413.5,\n",
       "  2416.0,\n",
       "  2418.5,\n",
       "  2421.0,\n",
       "  2423.0,\n",
       "  2425.0,\n",
       "  2427.5,\n",
       "  2430.0,\n",
       "  2433.0,\n",
       "  2436.0,\n",
       "  2439.0,\n",
       "  2442.0,\n",
       "  2444.0,\n",
       "  2446.0,\n",
       "  2448.5,\n",
       "  2451.0,\n",
       "  2454.5,\n",
       "  2458.0,\n",
       "  2460.5,\n",
       "  2463.0,\n",
       "  2466.5,\n",
       "  2470.0,\n",
       "  2472.5,\n",
       "  2475.0,\n",
       "  2478.0,\n",
       "  2481.0,\n",
       "  2484.0,\n",
       "  2487.0,\n",
       "  2491.0,\n",
       "  2495.0,\n",
       "  2498.5,\n",
       "  2502.0,\n",
       "  2504.5,\n",
       "  2507.0,\n",
       "  2510.0,\n",
       "  2513.0,\n",
       "  2515.5,\n",
       "  2518.0,\n",
       "  2520.5,\n",
       "  2523.0,\n",
       "  2525.0,\n",
       "  2527.0,\n",
       "  2529.5,\n",
       "  2532.0,\n",
       "  2534.5,\n",
       "  2537.0,\n",
       "  2539.5,\n",
       "  2542.0,\n",
       "  2545.5,\n",
       "  2549.0,\n",
       "  2552.0,\n",
       "  2555.0,\n",
       "  2558.0,\n",
       "  2561.0,\n",
       "  2563.5,\n",
       "  2566.0,\n",
       "  2569.5,\n",
       "  2573.0,\n",
       "  2576.0,\n",
       "  2579.0,\n",
       "  2582.0,\n",
       "  2585.0,\n",
       "  2587.5,\n",
       "  2590.0,\n",
       "  2592.5,\n",
       "  2595.0,\n",
       "  2598.0,\n",
       "  2601.0,\n",
       "  2603.5,\n",
       "  2606.0,\n",
       "  2609.0,\n",
       "  2612.0,\n",
       "  2615.0,\n",
       "  2618.0,\n",
       "  2620.5,\n",
       "  2623.0,\n",
       "  2626.0,\n",
       "  2629.0,\n",
       "  2631.5,\n",
       "  2634.0,\n",
       "  2638.0,\n",
       "  2642.0,\n",
       "  2646.0,\n",
       "  2650.0,\n",
       "  2653.0,\n",
       "  2656.0,\n",
       "  2658.5,\n",
       "  ...],\n",
       " [75,\n",
       "  75,\n",
       "  74,\n",
       "  74,\n",
       "  74,\n",
       "  74,\n",
       "  74,\n",
       "  74,\n",
       "  74,\n",
       "  73,\n",
       "  73,\n",
       "  74,\n",
       "  74,\n",
       "  77,\n",
       "  77,\n",
       "  77,\n",
       "  79,\n",
       "  80,\n",
       "  82,\n",
       "  83,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  93,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  99,\n",
       "  100,\n",
       "  103,\n",
       "  105,\n",
       "  108,\n",
       "  109,\n",
       "  111,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  113,\n",
       "  113,\n",
       "  113,\n",
       "  113,\n",
       "  113,\n",
       "  113,\n",
       "  113,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  113,\n",
       "  114,\n",
       "  114,\n",
       "  114,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  116,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  119,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  119,\n",
       "  118,\n",
       "  119,\n",
       "  118,\n",
       "  117,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  116,\n",
       "  116,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  114,\n",
       "  113,\n",
       "  111,\n",
       "  110,\n",
       "  109,\n",
       "  108,\n",
       "  107,\n",
       "  107,\n",
       "  106,\n",
       "  106,\n",
       "  106,\n",
       "  105,\n",
       "  105,\n",
       "  105,\n",
       "  105,\n",
       "  105,\n",
       "  105,\n",
       "  105,\n",
       "  105,\n",
       "  104,\n",
       "  103,\n",
       "  103,\n",
       "  101,\n",
       "  100,\n",
       "  99,\n",
       "  96,\n",
       "  95,\n",
       "  93,\n",
       "  92,\n",
       "  91,\n",
       "  90,\n",
       "  89,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  93,\n",
       "  93,\n",
       "  93,\n",
       "  93,\n",
       "  93,\n",
       "  94,\n",
       "  96,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  102,\n",
       "  103,\n",
       "  103,\n",
       "  104,\n",
       "  104,\n",
       "  105,\n",
       "  104,\n",
       "  104,\n",
       "  104,\n",
       "  104,\n",
       "  105,\n",
       "  105,\n",
       "  106,\n",
       "  106,\n",
       "  105,\n",
       "  105,\n",
       "  105,\n",
       "  105,\n",
       "  105,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  109,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  110,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  116,\n",
       "  116,\n",
       "  117,\n",
       "  117,\n",
       "  118,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  121,\n",
       "  121,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  122,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  124,\n",
       "  124,\n",
       "  123,\n",
       "  123,\n",
       "  122,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  122,\n",
       "  120,\n",
       "  120,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  120,\n",
       "  120,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  120,\n",
       "  119,\n",
       "  118,\n",
       "  116,\n",
       "  115,\n",
       "  115,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  116,\n",
       "  116,\n",
       "  115,\n",
       "  115,\n",
       "  114,\n",
       "  114,\n",
       "  115,\n",
       "  115,\n",
       "  116,\n",
       "  116,\n",
       "  117,\n",
       "  117,\n",
       "  118,\n",
       "  118,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  119,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  117,\n",
       "  117,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  116,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  120,\n",
       "  120,\n",
       "  121,\n",
       "  122,\n",
       "  122,\n",
       "  121,\n",
       "  120,\n",
       "  120,\n",
       "  119,\n",
       "  120,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  122,\n",
       "  122,\n",
       "  121,\n",
       "  121,\n",
       "  120,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  119,\n",
       "  119,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  122,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  121,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  123,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  129,\n",
       "  129,\n",
       "  129,\n",
       "  129,\n",
       "  129,\n",
       "  129,\n",
       "  128,\n",
       "  129,\n",
       "  129,\n",
       "  129,\n",
       "  130,\n",
       "  129,\n",
       "  129,\n",
       "  129,\n",
       "  129,\n",
       "  129,\n",
       "  130,\n",
       "  130,\n",
       "  129,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  124,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  121,\n",
       "  121,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  120,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  120,\n",
       "  120,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  120,\n",
       "  120,\n",
       "  121,\n",
       "  122,\n",
       "  125,\n",
       "  125,\n",
       "  126,\n",
       "  126,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  133,\n",
       "  132,\n",
       "  132,\n",
       "  132,\n",
       "  133,\n",
       "  133,\n",
       "  134,\n",
       "  134,\n",
       "  133,\n",
       "  133,\n",
       "  132,\n",
       "  132,\n",
       "  132,\n",
       "  133,\n",
       "  133,\n",
       "  134,\n",
       "  134,\n",
       "  134,\n",
       "  134,\n",
       "  134,\n",
       "  133,\n",
       "  133,\n",
       "  133,\n",
       "  133,\n",
       "  133,\n",
       "  133,\n",
       "  133,\n",
       "  132,\n",
       "  131,\n",
       "  131,\n",
       "  130,\n",
       "  129,\n",
       "  129,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  127,\n",
       "  126,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  120,\n",
       "  120,\n",
       "  119,\n",
       "  119,\n",
       "  118,\n",
       "  117,\n",
       "  117,\n",
       "  116,\n",
       "  114,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  116,\n",
       "  116,\n",
       "  115,\n",
       "  115,\n",
       "  115,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  118,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  117,\n",
       "  116,\n",
       "  115,\n",
       "  114,\n",
       "  114,\n",
       "  115,\n",
       "  114,\n",
       "  115,\n",
       "  115,\n",
       "  114,\n",
       "  114,\n",
       "  113,\n",
       "  113,\n",
       "  113,\n",
       "  113,\n",
       "  113,\n",
       "  113,\n",
       "  113,\n",
       "  113,\n",
       "  114,\n",
       "  113,\n",
       "  112,\n",
       "  111,\n",
       "  109,\n",
       "  109,\n",
       "  109,\n",
       "  109,\n",
       "  110,\n",
       "  113,\n",
       "  113,\n",
       "  112,\n",
       "  112,\n",
       "  112,\n",
       "  113,\n",
       "  113,\n",
       "  114,\n",
       "  114,\n",
       "  114,\n",
       "  114,\n",
       "  114,\n",
       "  114,\n",
       "  114,\n",
       "  114,\n",
       "  114,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  119,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  121,\n",
       "  121,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  118,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  124,\n",
       "  124,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  128,\n",
       "  128,\n",
       "  129,\n",
       "  129,\n",
       "  129,\n",
       "  129,\n",
       "  129,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  126,\n",
       "  126,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  127,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  126,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  122,\n",
       "  122,\n",
       "  121,\n",
       "  121,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  119,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  120,\n",
       "  119,\n",
       "  119,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  119,\n",
       "  120,\n",
       "  121,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  119,\n",
       "  118,\n",
       "  118,\n",
       "  119,\n",
       "  122,\n",
       "  123,\n",
       "  122,\n",
       "  122,\n",
       "  121,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  119,\n",
       "  119,\n",
       "  120,\n",
       "  120,\n",
       "  121,\n",
       "  121,\n",
       "  120,\n",
       "  119,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  124,\n",
       "  123,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  123,\n",
       "  123,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  124,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  125,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  123,\n",
       "  124,\n",
       "  ...],\n",
       " [279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  280.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  281.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  281.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  280.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  276.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  276.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  279.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  274.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  278.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  277.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  276.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  275.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  274.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  273.0,\n",
       "  ...])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2bad1",
   "metadata": {},
   "source": [
    "## Database Gear Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af5449",
   "metadata": {},
   "source": [
    "#### Initialize Gear Table  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "03eca499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_gear_table():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\"\"\"\n",
    "DROP TABLE gear\"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "drop_gear_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0070c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_gear_db():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS gear (\n",
    "        gear_id TEXT PRIMARY KEY,\n",
    "        is_primary BOOLEAN,\n",
    "        nickname TEXT,\n",
    "        resource_state INTEGER,\n",
    "        retired BOOLEAN,\n",
    "        distance INTEGER,\n",
    "        brand_name TEXT,\n",
    "        model_name TEXT,      \n",
    "        frame_type INTEGER,\n",
    "        description TEXT,\n",
    "        weight REAL\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf6ab3",
   "metadata": {},
   "source": [
    "#### Insert Single Gear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "293b0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def insert_single_gear(gear, db_path):\n",
    "    \"\"\"Insert activity records, skipping those with duplicate 'id'.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    try:\n",
    "        c.execute('''\n",
    "        INSERT OR REPLACE INTO gear VALUES (\n",
    "            :gear_id, :is_primary, :nickname, \n",
    "            :resource_state, :retired, :distance,\n",
    "            :brand_name, :model_name,\n",
    "            :frame_type, :description, :weight\n",
    "                  )\n",
    "        ''', {\n",
    "            \"gear_id\": gear.get(\"id\"),\n",
    "            \"is_primary\": gear.get(\"primary\"),\n",
    "            \"nickname\" : gear.get(\"nickname\"),\n",
    "            \"resource_state\": gear.get(\"resource_state\"),\n",
    "            \"retired\" : gear.get(\"retired\"),\n",
    "            \"distance\": gear.get(\"distance\"),\n",
    "            \"brand_name\": gear.get(\"brand_name\"),\n",
    "            \"model_name\": gear.get(\"model_name\"),\n",
    "            \"frame_type\": gear.get(\"frame_type\"),\n",
    "            \"description\": gear.get(\"description\"),\n",
    "            \"weight\" : gear.get(\"weight\"),\n",
    "            \"import_date\": datetime.now().isoformat()\n",
    "        })\n",
    "    except sqlite3.IntegrityError:\n",
    "        print(f\"Skipping duplicate activity with id {gear['id']}\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4a790",
   "metadata": {},
   "source": [
    "#### Get All Gear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15eec03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_gear(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql_query(\n",
    "        \"\"\"\n",
    "        SELECT *\n",
    "        FROM gear \n",
    "        limit 5\n",
    "    \"\"\",\n",
    "        conn\n",
    "    )\n",
    "    return df\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3db00bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gear_id</th>\n",
       "      <th>is_primary</th>\n",
       "      <th>nickname</th>\n",
       "      <th>resource_state</th>\n",
       "      <th>retired</th>\n",
       "      <th>distance</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>frame_type</th>\n",
       "      <th>description</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b5036222</td>\n",
       "      <td>0</td>\n",
       "      <td>CTS Road</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4390192</td>\n",
       "      <td>Tommaso</td>\n",
       "      <td>Imola</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stolen</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g4006462</td>\n",
       "      <td>0</td>\n",
       "      <td>CTS M860 x1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>687401</td>\n",
       "      <td>New Balance</td>\n",
       "      <td>M860 v9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mens 10.5 M860 BK9 Black/Grey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g4556561</td>\n",
       "      <td>0</td>\n",
       "      <td>CTS M860 x2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>676902</td>\n",
       "      <td>New Balance</td>\n",
       "      <td>M860 v9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mens 10.5 M860 BK9 Black/Grey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g4872382</td>\n",
       "      <td>0</td>\n",
       "      <td>CTS M860 x3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>694916</td>\n",
       "      <td>New Balance</td>\n",
       "      <td>M860 v9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mens 10.5 M860 BK9 Green/Grey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b6893678</td>\n",
       "      <td>0</td>\n",
       "      <td>CTS Road v2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6487523</td>\n",
       "      <td>Bianchi</td>\n",
       "      <td>\"C2C\" VIA NIRONE Alu Sora 9sp mix Compact</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Acquired 4.1.2020</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gear_id  is_primary     nickname  resource_state  retired  distance  \\\n",
       "0  b5036222           0     CTS Road               3        1   4390192   \n",
       "1  g4006462           0  CTS M860 x1               3        1    687401   \n",
       "2  g4556561           0  CTS M860 x2               3        1    676902   \n",
       "3  g4872382           0  CTS M860 x3               3        1    694916   \n",
       "4  b6893678           0  CTS Road v2               3        0   6487523   \n",
       "\n",
       "    brand_name                                  model_name  frame_type  \\\n",
       "0      Tommaso                                       Imola         3.0   \n",
       "1  New Balance                                     M860 v9         NaN   \n",
       "2  New Balance                                     M860 v9         NaN   \n",
       "3  New Balance                                     M860 v9         NaN   \n",
       "4      Bianchi   \"C2C\" VIA NIRONE Alu Sora 9sp mix Compact         3.0   \n",
       "\n",
       "                     description  weight  \n",
       "0                         Stolen    23.0  \n",
       "1  Mens 10.5 M860 BK9 Black/Grey     NaN  \n",
       "2  Mens 10.5 M860 BK9 Black/Grey     NaN  \n",
       "3  Mens 10.5 M860 BK9 Green/Grey     NaN  \n",
       "4              Acquired 4.1.2020    21.7  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_gear(DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0e9972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gearid_for_specific_activity(db_path, activity_id):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\n",
    "        \"\"\"\n",
    "        SELECT gear_id\n",
    "        FROM activities \n",
    "        where id = ?\n",
    "    \"\"\", (activity_id,)\n",
    "    )\n",
    "    count = c.fetchone()[0]\n",
    "    conn.close()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57923498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g15852452'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gearid_for_specific_activity(DB_PATH, 14436191500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35414d6c",
   "metadata": {},
   "source": [
    "## Get Latest Activity and Associated Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7d71f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity ID: 14404286770, Name: Morning Run, Type: Run\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    activities = []\n",
    "    streams = []\n",
    "    page = 1\n",
    "    per_page = 1\n",
    "    while True:\n",
    "        activities_page = get_activities(AUTH_TOKEN, page=page, per_page=per_page)\n",
    "        if not activities_page:\n",
    "            break\n",
    "        activities.extend(activities_page)\n",
    "        page += 1\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "        break\n",
    "\n",
    "    # Process the activity data\n",
    "    for activity in activities:\n",
    "        print(f\"Activity ID: {activity['id']}, Name: {activity['name']}, Type: {activity['type']}\")\n",
    "\n",
    "    keys = [\"time\", \"distance\", \"latlng\", \"altitude\", \"heartrate\", \"cadence\", \"watts\"]\n",
    "    keys = \"time, latlng\"\n",
    "    # Process stream data\n",
    "    for a in activities:\n",
    "        stream = get_streams(AUTH_TOKEN, keys, a['id'])\n",
    "        if not stream:\n",
    "            break\n",
    "        streams.extend(stream)\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "        break\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b705f",
   "metadata": {},
   "source": [
    "## Bulk Historical Processing of Activities\n",
    "#### Run this up to 1000 API calls per day during historical data loading\n",
    "#### Quit IMMEDIATELY if rate limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1f83cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting point, build unix timestamps in 6 month batches\n",
    "\n",
    "# time_0 = time.mktime(datetime.datetime(2019, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_1 = time.mktime(datetime.datetime(2019, 7, 1, 0, 0, 0).timetuple()) \n",
    "# time_2 = time.mktime(datetime.datetime(2020, 1, 1, 0, 0, 0).timetuple()) \n",
    "# time_3 = time.mktime(datetime.datetime(2020, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_4 = time.mktime(datetime.datetime(2021, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_5 = time.mktime(datetime.datetime(2021, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_6 = time.mktime(datetime.datetime(2022, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_7 = time.mktime(datetime.datetime(2022, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_8 = time.mktime(datetime.datetime(2023, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_9 = time.mktime(datetime.datetime(2023, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_10 = time.mktime(datetime.datetime(2024, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_11 = time.mktime(datetime.datetime(2024, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_12 = time.mktime(datetime.datetime(2025, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_13 = time.mktime(datetime.datetime(2025, 7, 1, 0, 0, 0).timetuple())\n",
    "\n",
    "day_by_day_before = time.mktime(datetime(2025, 5, 16, 0, 0, 0).timetuple())\n",
    "day_by_day_after = time.mktime(datetime(2025, 5, 14, 0, 0, 0).timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "01203a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1746853200.0\n"
     ]
    }
   ],
   "source": [
    "print(day_by_day_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3248bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2 activities were imported so far.\n",
      "2 activities were imported so far today\n",
      "3 activities were imported from the API this round.\n"
     ]
    }
   ],
   "source": [
    "# ensure db table exists\n",
    "initialize_database()\n",
    "\n",
    "# Get the data\n",
    "try:\n",
    "    activities = []\n",
    "    page = 1\n",
    "    per_page = 30\n",
    "    while True:\n",
    "        activities_page = get_activities(ACCESS_TOKEN, page=page, per_page=per_page, before = day_by_day_before, after = day_by_day_after) # currently done, latest after time was time_12\n",
    "        if not activities_page:\n",
    "            break\n",
    "        print(len(activities_page)) # expect 30 each time unless final page\n",
    "        activities.extend(activities_page)\n",
    "        \n",
    "        insert_activities_batch(activities_page, DB_PATH) # attempt to bulk write to db\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "\n",
    "        num_today = count_activities_imported_today(DB_PATH) # count objects in db now\n",
    "        print(f\"{num_today} activities were imported so far.\")\n",
    "\n",
    "        page += 1\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "        if page > 10:\n",
    "            break\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "num_today = count_activities_imported_today(DB_PATH)\n",
    "print(f\"{num_today} activities were imported so far today\")\n",
    "print(f\"{len(activities)} activities were imported from the API this round.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17807bb1",
   "metadata": {},
   "source": [
    "## Bulk Historical Processing of Data Streams and Gear\n",
    "#### Run this every 15 minutes up to 10 times a day during historical data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46f95e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DB\n",
    "initialize_streams_db()\n",
    "\n",
    "# get all stream activity IDs\n",
    "stream_activity_ids = get_all_activity_ids_streams(\"strava_data.db\")\n",
    "stream_activity_ids = set(i[0] for i in stream_activity_ids)\n",
    "\n",
    "# get all activity ID's in db sorted by activity date desc as set\n",
    "sorted_activity_list = get_all_activity_ids_with_HR(\"strava_data.db\")\n",
    "sorted_activity_list = set(i[0] for i in sorted_activity_list)\n",
    "\n",
    "# Take the \n",
    "valid_activity_ids = tuple(sorted_activity_list - stream_activity_ids)\n",
    "\n",
    "keys = \"time,distance,latlng,altitude,velocity_smooth,heartrate,cadence,watts,temp,moving,grade_smooth\"\n",
    "\n",
    "for i, activity_integer in enumerate(valid_activity_ids):\n",
    "    \n",
    "    # attempt to pull stream data\n",
    "    try:\n",
    "        stream = get_streams(ACCESS_TOKEN, keys, activity_integer)\n",
    "        if not stream:\n",
    "            print('no stream')\n",
    "            continue\n",
    "    \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error occurred: {e}\")\n",
    "        if \"429\" in str(e):\n",
    "            print(\"RATE LIMITED!!!\")\n",
    "            break\n",
    "        if \"404\" in str(e):\n",
    "            print(\"Stream data unavailable for activity\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "    insert_stream_data(activity_integer, stream, db_path=DB_PATH)\n",
    "    time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "\n",
    "    # attempt to pull gear data\n",
    "\n",
    "    try:\n",
    "        print(activity_integer)\n",
    "        shoe = get_gearid_for_specific_activity(DB_PATH, activity_integer)\n",
    "        print(shoe)\n",
    "        shoe_data = get_gear(ACCESS_TOKEN, shoe)\n",
    "        if not stream:\n",
    "            print('no shoe_data')\n",
    "            continue\n",
    "    \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error occurred: {e}\")\n",
    "        if \"429\" in str(e):\n",
    "            print(\"RATE LIMITED!!!\")\n",
    "            break\n",
    "        if \"404\" in str(e):\n",
    "            print(\"Stream data unavailable for activity\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "    insert_single_gear(shoe_data, db_path=DB_PATH)\n",
    "    time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "\n",
    "    if i > 10:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f7b90233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2753 streams in the db.\n",
      "2751 valid activities with potential streams data exist in the db.\n",
      "-2 to go!\n"
     ]
    }
   ],
   "source": [
    "num_today = count_activities_imported_today(DB_PATH)\n",
    "print(f\"{len(get_all_activity_ids_streams(\"strava_data.db\"))} streams in the db.\")\n",
    "print(f\"{len(get_all_activity_ids_with_HR(\"strava_data.db\"))} valid activities with potential streams data exist in the db.\")\n",
    "print(f\"{len(get_all_activity_ids_with_HR(\"strava_data.db\")) - len(get_all_activity_ids_streams(\"strava_data.db\"))} to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7738b0",
   "metadata": {},
   "source": [
    "## Gear Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10391f5",
   "metadata": {},
   "source": [
    "#### The below fully rebuilds the gear table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "035385ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DB\n",
    "initialize_gear_db()\n",
    "\n",
    "shoe_id = get_all_gear_ids(DB_PATH)\n",
    "\n",
    "for id in shoe_id:\n",
    "    shoe = get_gear(ACCESS_TOKEN, id[0])\n",
    "    insert_single_gear(shoe, db_path=DB_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73263c06",
   "metadata": {},
   "source": [
    "## Airflow Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34548c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.utils.dates import days_ago\n",
    "from datetime import timedelta\n",
    "import requests\n",
    "import json\n",
    "\n",
    "CLIENT_ID = os.environ.get(\"CLIENT_ID\")\n",
    "CLIENT_SECRET = os.environ.get(\"CLIENT_SECRET\")\n",
    "REFRESH_TOKEN = os.environ.get(\"REFRESH_TOKEN\")\n",
    "DB_PATH = os.environ.get(\"DATABASE\")\n",
    "\n",
    "def latest_activity_import_date(db_path):\n",
    "    \"\"\"Query for latest activity import_date as a unix timestamp\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT max(import_date)\n",
    "        FROM activities \n",
    "    \"\"\")\n",
    "    \n",
    "    record = c.fetchone()[0]\n",
    "    conn.close()\n",
    "    dt = datetime.strptime(record, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    return int(dt.timestamp())\n",
    "\n",
    "def get_activities(access_token, page=1, per_page=30, **optional_parameters):\n",
    "    \"\"\"Retrieves activities from the Strava API.\n",
    "    Optional parameters should be provided at the end of the call like so:\n",
    "    before = epoch_timestamp, after = epoch_timestamp\n",
    "    \"\"\"\n",
    "    url = f\"https://www.strava.com/api/v3/athlete/activities\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    params = {\"page\": page, \"per_page\": per_page}\n",
    "    params.update(optional_parameters)\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_streams(access_token, keys = \"time,distance,latlng,altitude,velocity_smooth,heartrate,cadence,watts,temp,moving,grade_smooth\", activity_id):\n",
    "    \"\"\"Retrieves activities from the Strava API.\"\"\"\n",
    "    url = f\"https://www.strava.com/api/v3/activities/\" + str(activity_id) + \"/streams\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    params = {\"keys\" : keys, \"key_by_type\": True}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_gear(access_token, gear_id):\n",
    "    \"\"\"Retrieves activities from the Strava API.\"\"\"\n",
    "    url = f\"https://www.strava.com/api/v3/gear/\" + str(gear_id)\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def insert_activities_batch(activity_list, db_path = DB_PATH):\n",
    "    \"\"\"Efficiently insert multiple activity records into the database.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    data = []\n",
    "    for activity in activity_list:\n",
    "        data.append({\n",
    "            \"id\": activity[\"id\"],\n",
    "            \"resource_state\": activity.get(\"resource_state\"),\n",
    "            \"athlete_id\": activity.get(\"athlete\", {}).get(\"id\"),\n",
    "            \"athlete_resource_state\": activity.get(\"athlete\", {}).get(\"resource_state\"),\n",
    "            \"name\": activity.get(\"name\"),\n",
    "            \"distance\": activity.get(\"distance\"),\n",
    "            \"moving_time\": activity.get(\"moving_time\"),\n",
    "            \"elapsed_time\": activity.get(\"elapsed_time\"),\n",
    "            \"total_elevation_gain\": activity.get(\"total_elevation_gain\"),\n",
    "            \"type\": activity.get(\"type\"),\n",
    "            \"sport_type\": activity.get(\"sport_type\"),\n",
    "            \"workout_type\": activity.get(\"workout_type\"),\n",
    "            \"start_date\": activity.get(\"start_date\"),\n",
    "            \"start_date_local\": activity.get(\"start_date_local\"),\n",
    "            \"timezone\": activity.get(\"timezone\"),\n",
    "            \"utc_offset\": activity.get(\"utc_offset\"),\n",
    "            \"location_city\": activity.get(\"location_city\"),\n",
    "            \"location_state\": activity.get(\"location_state\"),\n",
    "            \"location_country\": activity.get(\"location_country\"),\n",
    "            \"achievement_count\": activity.get(\"achievement_count\"),\n",
    "            \"kudos_count\": activity.get(\"kudos_count\"),\n",
    "            \"comment_count\": activity.get(\"comment_count\"),\n",
    "            \"athlete_count\": activity.get(\"athlete_count\"),\n",
    "            \"photo_count\": activity.get(\"photo_count\"),\n",
    "            \"map_id\": activity.get(\"map\", {}).get(\"id\"),\n",
    "            \"map_summary_polyline\": activity.get(\"map\", {}).get(\"summary_polyline\"),\n",
    "            \"map_resource_state\": activity.get(\"map\", {}).get(\"resource_state\"),\n",
    "            \"trainer\": activity.get(\"trainer\"),\n",
    "            \"commute\": activity.get(\"commute\"),\n",
    "            \"manual\": activity.get(\"manual\"),\n",
    "            \"private\": activity.get(\"private\"),\n",
    "            \"visibility\": activity.get(\"visibility\"),\n",
    "            \"flagged\": activity.get(\"flagged\"),\n",
    "            \"gear_id\": activity.get(\"gear_id\"),\n",
    "            \"start_latlng\": json.dumps(activity.get(\"start_latlng\")),\n",
    "            \"end_latlng\": json.dumps(activity.get(\"end_latlng\")),\n",
    "            \"average_speed\": activity.get(\"average_speed\"),\n",
    "            \"max_speed\": activity.get(\"max_speed\"),\n",
    "            \"average_cadence\": activity.get(\"average_cadence\"),\n",
    "            \"average_watts\": activity.get(\"average_watts\"),\n",
    "            \"max_watts\": activity.get(\"max_watts\"),\n",
    "            \"weighted_average_watts\": activity.get(\"weighted_average_watts\"),\n",
    "            \"device_watts\": activity.get(\"device_watts\"),\n",
    "            \"kilojoules\": activity.get(\"kilojoules\"),\n",
    "            \"has_heartrate\": activity.get(\"has_heartrate\"),\n",
    "            \"average_heartrate\": activity.get(\"average_heartrate\"),\n",
    "            \"max_heartrate\": activity.get(\"max_heartrate\"),\n",
    "            \"heartrate_opt_out\": activity.get(\"heartrate_opt_out\"),\n",
    "            \"display_hide_heartrate_option\": activity.get(\"display_hide_heartrate_option\"),\n",
    "            \"elev_high\": activity.get(\"elev_high\"),\n",
    "            \"elev_low\": activity.get(\"elev_low\"),\n",
    "            \"upload_id\": activity.get(\"upload_id\"),\n",
    "            \"upload_id_str\": activity.get(\"upload_id_str\"),\n",
    "            \"external_id\": activity.get(\"external_id\"),\n",
    "            \"from_accepted_tag\": activity.get(\"from_accepted_tag\"),\n",
    "            \"pr_count\": activity.get(\"pr_count\"),\n",
    "            \"total_photo_count\": activity.get(\"total_photo_count\"),\n",
    "            \"has_kudoed\": activity.get(\"has_kudoed\"),\n",
    "            \"import_date\": datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "    try:\n",
    "        c.executemany('''\n",
    "        INSERT OR IGNORE INTO activities VALUES (\n",
    "            :id, :resource_state, :athlete_id, :athlete_resource_state,\n",
    "            :name, :distance, :moving_time, :elapsed_time, :total_elevation_gain,\n",
    "            :type, :sport_type, :workout_type, :start_date, :start_date_local,\n",
    "            :timezone, :utc_offset, :location_city, :location_state, :location_country,\n",
    "            :achievement_count, :kudos_count, :comment_count, :athlete_count, :photo_count,\n",
    "            :map_id, :map_summary_polyline, :map_resource_state,\n",
    "            :trainer, :commute, :manual, :private, :visibility, :flagged, :gear_id,\n",
    "            :start_latlng, :end_latlng,\n",
    "            :average_speed, :max_speed, :average_cadence, :average_watts,\n",
    "            :max_watts, :weighted_average_watts, :device_watts, :kilojoules,\n",
    "            :has_heartrate, :average_heartrate, :max_heartrate,\n",
    "            :heartrate_opt_out, :display_hide_heartrate_option,\n",
    "            :elev_high, :elev_low,\n",
    "            :upload_id, :upload_id_str, :external_id, :from_accepted_tag,\n",
    "            :pr_count, :total_photo_count, :has_kudoed, :import_date\n",
    "        )\n",
    "        ''', data)\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error inserting batch:\", e)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def insert_stream_data(activity_id, stream_dict, db_path = DB_PATH):\n",
    "    \"\"\"\n",
    "    Inserts or replaces a row in the streams table for a given activity_id.\n",
    "    stream_dict should have keys like 'time', 'distance', etc., with each value a dict containing:\n",
    "    {\n",
    "        'data': [...],\n",
    "        'series_type': '...',\n",
    "        'original_size': ...,\n",
    "        'resolution': '...'\n",
    "    }\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Create the column mappings dynamically\n",
    "    base_columns = []\n",
    "    placeholders = []\n",
    "    values = []\n",
    "\n",
    "    # Always include activity_id\n",
    "    base_columns.append(\"activity_id\")\n",
    "    placeholders.append(\"?\")\n",
    "    values.append(activity_id)\n",
    "\n",
    "    for key, val in stream_dict.items():\n",
    "        if not isinstance(val, dict):\n",
    "            continue  # skip malformed\n",
    "\n",
    "        base_columns.extend([\n",
    "            f\"{key}_data\",\n",
    "            f\"{key}_series_type\",\n",
    "            f\"{key}_original_size\",\n",
    "            f\"{key}_resolution\"\n",
    "        ])\n",
    "        placeholders.extend([\"?\"] * 4)\n",
    "\n",
    "        values.extend([\n",
    "            json.dumps(val.get(\"data\")),\n",
    "            val.get(\"series_type\"),\n",
    "            val.get(\"original_size\"),\n",
    "            val.get(\"resolution\")\n",
    "        ])\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        INSERT INTO streams ({', '.join(base_columns)})\n",
    "        VALUES ({', '.join(placeholders)})\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    try:\n",
    "        c.execute(sql, values)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    except sqlite3.IntegrityError:\n",
    "        print(f\"Activity {activity_id} already exists in the 'streams' table. Skipping insert.\")\n",
    "\n",
    "def insert_single_gear(gear, db_path=DB_PATH):\n",
    "    \"\"\"Insert activity records, skipping those with duplicate 'id'.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "    try:\n",
    "        c.execute('''\n",
    "        INSERT OR REPLACE INTO gear VALUES (\n",
    "            :gear_id, :is_primary, :nickname, \n",
    "            :resource_state, :retired, :distance,\n",
    "            :brand_name, :model_name,\n",
    "            :frame_type, :description, :weight\n",
    "                  )\n",
    "        ''', {\n",
    "            \"gear_id\": gear.get(\"id\"),\n",
    "            \"is_primary\": gear.get(\"primary\"),\n",
    "            \"nickname\" : gear.get(\"nickname\"),\n",
    "            \"resource_state\": gear.get(\"resource_state\"),\n",
    "            \"retired\" : gear.get(\"retired\"),\n",
    "            \"distance\": gear.get(\"distance\"),\n",
    "            \"brand_name\": gear.get(\"brand_name\"),\n",
    "            \"model_name\": gear.get(\"model_name\"),\n",
    "            \"frame_type\": gear.get(\"frame_type\"),\n",
    "            \"description\": gear.get(\"description\"),\n",
    "            \"weight\" : gear.get(\"weight\"),\n",
    "            \"import_date\": datetime.now().isoformat()\n",
    "        })\n",
    "    except sqlite3.IntegrityError:\n",
    "        print(f\"Skipping duplicate activity with id {gear['id']}\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# This needs to happen first and everything else will fail if this fails\n",
    "def refresh_access_token(client_id, client_secret, refresh_token):\n",
    "    \"\"\"API call using local refresh token to get new access token.\n",
    "    Needs to pull client_id, client_secret, and refresh_token from environment variables.\n",
    "    Needs to write new refresh token to environment variables and pass on the received access\n",
    "    token to the following api functions\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        url=\"https://www.strava.com/oauth/token\",\n",
    "        data={\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"grant_type\": \"refresh_token\",\n",
    "            \"refresh_token\": refresh_token,\n",
    "        },\n",
    "    )\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    os.environ[\"REFRESH_TOKEN\"] = response[\"refresh_token\"]\n",
    "    kwargs['ti'].xcom_push(key='access_token', value=response.json()[\"access_token\"])\n",
    "    \n",
    "def fetch_activity_data_and_write_to_db(**kwargs):\n",
    "    \"\"\"Function to call the strava api for latest activity data since that last import_date.\n",
    "    Needs to accept an before and after unix timestamp as a parameter as well as db path\n",
    "    to query for the latest import_date.\n",
    "    \"\"\"\n",
    "    after = latest_activity_import_date(db_path)\n",
    "    before = after + 86400\n",
    "    page = 1\n",
    "    per_page = 30\n",
    "    try:\n",
    "        activities_page = get_activities(ACCESS_TOKEN, page=page, per_page=per_page, before = before, after = after)     \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error occurred: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decode error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    insert_activities_batch(activities_page)\n",
    "    kwargs['ti'].xcom_push(key='activity_dict', value=activities_page)\n",
    "\n",
    "\n",
    "def fetch_streams_data_and_write_to_db(**kwargs):\n",
    "    \"\"\"Function to call the strava api for stream data related to activity id's pulled in from \n",
    "    fetch activity_data then write single stream datasets to the db.\n",
    "    \"\"\"\n",
    "    for activity in activities_page:\n",
    "        try:\n",
    "            stream = get_streams(ACCESS_TOKEN, keys, int(activity[id]))\n",
    "            if not stream:\n",
    "                print('no stream')\n",
    "                continue\n",
    "        \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"HTTP error occurred: {e}\")\n",
    "            if \"429\" in str(e):\n",
    "                print(\"RATE LIMITED!!!\")\n",
    "                break\n",
    "            if \"404\" in str(e):\n",
    "                print(\"Stream data unavailable for activity\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "        insert_stream_data(activity[id], stream)\n",
    "\n",
    "def fetch_gear_data_and_write_to_db(**kwargs):\n",
    "    \"\"\"Function to call the strava api for single gear data related to gear_id pulled in from \n",
    "    fetch activity_data then write single gear update to the db.\n",
    "    \"\"\"\n",
    "    for activity in activities_page:\n",
    "        try:\n",
    "            shoe = activity['gear_id']\n",
    "            if not shoe:\n",
    "                print('no shoe')\n",
    "                continue\n",
    "        \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"HTTP error occurred: {e}\")\n",
    "            if \"429\" in str(e):\n",
    "                print(\"RATE LIMITED!!!\")\n",
    "                break\n",
    "            if \"404\" in str(e):\n",
    "                print(\"Stream data unavailable for activity\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "        insert_single_gear(shoe)\n",
    "\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'you',\n",
    "    'depends_on_past': False,\n",
    "    'email_on_failure': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "with DAG(\n",
    "    'api_to_db_pipeline',\n",
    "    default_args=default_args,\n",
    "    description='Fetch Strava API Activity data and update 3 db tables',\n",
    "    schedule_interval='30 7,17,19 * * *',\n",
    "    start_date=days_ago(1),\n",
    "    catchup=False,\n",
    "    tags=['example'],\n",
    ") as dag:\n",
    "\n",
    "    refresh_tokens = PythonOperator(\n",
    "        task_id='refresh_access_token',\n",
    "        python_callable=refresh_access_token,\n",
    "        provide_context=True,\n",
    "    )\n",
    "\n",
    "    update_activities = PythonOperator(\n",
    "        task_id='fetch_and_write_activities',\n",
    "        python_callable=fetch_activity_data_and_write_to_db,\n",
    "        provide_context=True,\n",
    "    )\n",
    "\n",
    "    update_streams = PythonOperator(\n",
    "        task_id='fetch_and_write_streams',\n",
    "        python_callable=fetch_streams_data_and_write_to_db,\n",
    "        provide_context=True,\n",
    "    )\n",
    "\n",
    "    update_gear = PythonOperator(\n",
    "    task_id='fetch_and_write_gear',\n",
    "    python_callable=fetch_gear_data_and_write_to_db,\n",
    "    provide_context=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    refresh_tokens >> [update_activities, update_streams, update_gear]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64bb434",
   "metadata": {},
   "source": [
    "## GEMMA TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284ad072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.16it/s]\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from accelerate import disk_offload # trying to manage memory\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# load_dotenv('secrets.env') # it's magically working now? \n",
    "hf_secret = os.getenv(\"HF_TOKEN\") # access a token registered on huggingface to allow use of gated model\n",
    "login(token = hf_secret, add_to_git_credential = False) # performs cli login using token above\n",
    "\n",
    "# Defines the model and pipeline to be used for text generation\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"google/gemma-2-2b-it\",\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16,},\n",
    "    device_map=\"cpu\", # other options exist here but cpu seems to work and avoids GPU per our goals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0015348",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ask = \"\"\"Given the following SQL Database schema of a user's running and biking data:\n",
    "        activities table:\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        distance REAL, -- in meters\n",
    "        moving_time INTEGER, -- in seconds\n",
    "        elapsed_time INTEGER, -- in seconds\n",
    "        total_elevation_gain REAL, -- in meters\n",
    "        type TEXT, -- can be Run or Ride\n",
    "        workout_type INTEGER,\n",
    "        start_date_local TEXT,\n",
    "        kudos_count INTEGER,\n",
    "        gear_id TEXT, -- foreign key to gear table\n",
    "        average_speed REAL,\n",
    "        max_speed REAL,\n",
    "        average_cadence REAL,\n",
    "        average_watts REAL,\n",
    "        max_watts INTEGER,\n",
    "        weighted_average_watts INTEGER,\n",
    "        device_watts BOOLEAN,\n",
    "        kilojoules REAL,\n",
    "        average_heartrate REAL,\n",
    "        max_heartrate REAL,\n",
    "        elev_high REAL,\n",
    "        elev_low REAL,\n",
    "        import_date TEXT\n",
    "\n",
    "        gear table (contains shoe and bike data):\n",
    "        gear_id TEXT PRIMARY KEY,\n",
    "        nickname TEXT,\n",
    "        resource_state INTEGER,\n",
    "        retired BOOLEAN,\n",
    "        distance INTEGER,\n",
    "        brand_name TEXT,\n",
    "        model_name TEXT,      \n",
    "        description TEXT,\n",
    "        \n",
    "        Write a SQL query to return the id of all run activities where I wore Brooks brand shoes\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89410b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "{\"role\": \"user\", \"content\": \"You are business proposal writing professional. \"\n",
    "\"Please respond to the following query with a single paragraph. \" + user_ask},\n",
    "]   \n",
    "outputs = pipe(messages, max_new_tokens=256)\n",
    "assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "897967e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT activities.id\n",
      "FROM activities\n",
      "JOIN gear ON activities.gear_id = gear.gear_id\n",
      "WHERE gear.brand_name = 'Brooks';\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9ff014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "match = re.search(r\"```sql\\s+(.*?;)\", assistant_response, re.DOTALL)\n",
    "query = match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad1a3daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT activities.id\n",
      "FROM activities\n",
      "JOIN gear ON activities.gear_id = gear.gear_id\n",
      "WHERE gear.brand_name = 'Brooks';\n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7726d15",
   "metadata": {},
   "source": [
    "## RUnstrong DB Populate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ba8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises_data = [\n",
    "    \n",
    "    {\n",
    "        'name': 'Box Jump',\n",
    "        'description': 'Explosive plyometric exercise involving jumping onto an elevated platform to develop lower body power and coordination.',\n",
    "        'instructions': '1. Stand arm\\'s length from box\\n2. Swing arms back and bend into quarter squat\\n3. Explode up swinging arms forward\\n4. Land softly on box with both feet\\n5. Step down carefully, don\\'t jump down',\n",
    "        'exercise_type': 'Bodyweight',\n",
    "        'movement_pattern': 'Jump',\n",
    "        'primary_muscles': ['Quadriceps', 'Glutes'],\n",
    "        'secondary_muscles': ['Hamstrings', 'Calves', 'Core'],\n",
    "        'muscle_groups': 'Lower body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 6,\n",
    "        'prerequisites': 'Basic jumping ability, good landing mechanics',\n",
    "        'progressions': ['Jump squats', 'Step-ups'],\n",
    "        'regressions': ['Higher box jumps', 'Weighted box jumps'],\n",
    "        'equipment_required': ['Plyometric box'],\n",
    "        'equipment_optional': None,\n",
    "        'setup_time': 1,\n",
    "        'space_required': 'Moderate',\n",
    "        'rep_range_min': 3,\n",
    "        'rep_range_max': 10,\n",
    "        'tempo': 'Explosive',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Compound',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Knee injuries, ankle problems, poor landing mechanics',\n",
    "        'common_mistakes': ['Box too high', 'Jumping down instead of stepping', 'Poor landing position'],\n",
    "        'safety_notes': 'Start with lower box, focus on soft landings, step down',\n",
    "        'category': 'Power',\n",
    "        'training_style': ['Functional', 'Sport-specific'],\n",
    "        'experience_level': ['Intermediate', 'Advanced'],\n",
    "        'goals': ['Power', 'Explosiveness'],\n",
    "        'duration_minutes': 2,\n",
    "        'popularity_score': 8,\n",
    "        'alternatives': ['Jump Squats', 'Broad Jumps', 'Step-ups'],\n",
    "        'supersets_well_with': ['Pull-ups', 'Plank variations']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Kettlebell Romanian Deadlift with Dumbbells',\n",
    "        'description': 'Hip hinge movement using dumbbells in place of kettlebell to target posterior chain muscles with emphasis on hamstrings and glutes.',\n",
    "        'instructions': '1. Hold dumbbells in front of thighs with feet hip-width apart\\n2. Initiate movement by pushing hips back\\n3. Lower weights while keeping them close to legs\\n4. Feel stretch in hamstrings\\n5. Drive hips forward to return to standing',\n",
    "        'exercise_type': 'Free weights',\n",
    "        'movement_pattern': 'Hinge',\n",
    "        'primary_muscles': ['Hamstrings', 'Glutes'],\n",
    "        'secondary_muscles': ['Lower back', 'Core', 'Forearms'],\n",
    "        'muscle_groups': 'Lower body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 5,\n",
    "        'prerequisites': 'Hip hinge pattern, hamstring flexibility',\n",
    "        'progressions': ['Good mornings', 'Glute bridges'],\n",
    "        'regressions': ['Conventional deadlift', 'Single-leg RDL'],\n",
    "        'equipment_required': ['Dumbbells'],\n",
    "        'equipment_optional': None,\n",
    "        'setup_time': 1,\n",
    "        'space_required': 'Moderate',\n",
    "        'rep_range_min': 8,\n",
    "        'rep_range_max': 15,\n",
    "        'tempo': '3-1-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Compound',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Lower back injuries, severe hamstring tightness',\n",
    "        'common_mistakes': ['Rounding back', 'Bending knees too much', 'Not feeling hamstring stretch'],\n",
    "        'safety_notes': 'Maintain neutral spine, initiate with hip hinge',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Functional', 'Bodybuilding'],\n",
    "        'experience_level': ['Beginner', 'Intermediate', 'Advanced'],\n",
    "        'goals': ['Strength', 'Hypertrophy'],\n",
    "        'duration_minutes': 3,\n",
    "        'popularity_score': 8,\n",
    "        'alternatives': ['Romanian Deadlift', 'Good Mornings', 'Glute Ham Raise'],\n",
    "        'supersets_well_with': ['Chest Press', 'Plank variations']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Deadlift',\n",
    "        'description': 'Fundamental compound movement lifting weight from the ground, targeting the entire posterior chain and core.',\n",
    "        'instructions': '1. Stand with feet hip-width apart, bar over mid-foot\\n2. Bend at hips and knees to grip bar\\n3. Keep chest up and back neutral\\n4. Drive through heels and extend hips and knees\\n5. Stand tall with shoulders back',\n",
    "        'exercise_type': 'Free weights',\n",
    "        'movement_pattern': 'Hinge',\n",
    "        'primary_muscles': ['Hamstrings', 'Glutes', 'Lower back'],\n",
    "        'secondary_muscles': ['Quadriceps', 'Core', 'Upper back', 'Forearms'],\n",
    "        'muscle_groups': 'Full body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 8,\n",
    "        'prerequisites': 'Hip hinge pattern, adequate mobility, proper form instruction',\n",
    "        'progressions': ['Romanian Deadlift', 'Rack pulls'],\n",
    "        'regressions': ['Sumo deadlift', 'Trap bar deadlift'],\n",
    "        'equipment_required': ['Barbell', 'Weight plates'],\n",
    "        'equipment_optional': 'Lifting straps, chalk',\n",
    "        'setup_time': 3,\n",
    "        'space_required': 'Large',\n",
    "        'rep_range_min': 1,\n",
    "        'rep_range_max': 10,\n",
    "        'tempo': '1-1-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Compound',\n",
    "        'injury_risk_level': 'High',\n",
    "        'contraindications': 'Lower back injuries, severe mobility restrictions',\n",
    "        'common_mistakes': ['Rounding back', 'Bar drifting away', 'Hyperextending at top'],\n",
    "        'safety_notes': 'Master form with light weight first, use proper progression',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Powerlifting', 'Functional'],\n",
    "        'experience_level': ['Intermediate', 'Advanced'],\n",
    "        'goals': ['Strength', 'Power'],\n",
    "        'duration_minutes': 4,\n",
    "        'popularity_score': 10,\n",
    "        'alternatives': ['Romanian Deadlift', 'Trap Bar Deadlift', 'Rack Pulls'],\n",
    "        'supersets_well_with': ['Pull-ups', 'Plank variations']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Pull-up',\n",
    "        'description': 'Upper body pulling exercise performed by hanging from a bar and pulling the body up until chin clears the bar.',\n",
    "        'instructions': '1. Hang from pull-up bar with arms fully extended\\n2. Use overhand grip slightly wider than shoulders\\n3. Pull body up until chin clears bar\\n4. Lower with control to full hang\\n5. Avoid swinging or kipping',\n",
    "        'exercise_type': 'Bodyweight',\n",
    "        'movement_pattern': 'Pull',\n",
    "        'primary_muscles': ['Latissimus dorsi', 'Rhomboids'],\n",
    "        'secondary_muscles': ['Biceps', 'Rear deltoids', 'Core'],\n",
    "        'muscle_groups': 'Upper body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 7,\n",
    "        'prerequisites': 'Adequate upper body strength, dead hang ability',\n",
    "        'progressions': ['Assisted pull-ups', 'Negative pull-ups'],\n",
    "        'regressions': ['Weighted pull-ups', 'One-arm pull-ups'],\n",
    "        'equipment_required': ['Pull-up bar'],\n",
    "        'equipment_optional': 'Assistance bands',\n",
    "        'setup_time': 1,\n",
    "        'space_required': 'Minimal',\n",
    "        'rep_range_min': 3,\n",
    "        'rep_range_max': 15,\n",
    "        'tempo': '2-1-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Compound',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Shoulder impingement, elbow issues',\n",
    "        'common_mistakes': ['Partial range of motion', 'Swinging', 'Neck craning'],\n",
    "        'safety_notes': 'Full range of motion, control descent, proper grip',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Functional', 'Bodyweight'],\n",
    "        'experience_level': ['Intermediate', 'Advanced'],\n",
    "        'goals': ['Strength', 'Hypertrophy'],\n",
    "        'duration_minutes': 2,\n",
    "        'popularity_score': 9,\n",
    "        'alternatives': ['Lat Pulldown', 'Assisted Pull-ups', 'Chin-ups'],\n",
    "        'supersets_well_with': ['Push-ups', 'Squats', 'Deadlifts']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Plank',\n",
    "        'description': 'Isometric core exercise maintaining a straight body position supported by forearms and toes.',\n",
    "        'instructions': '1. Start in push-up position then lower to forearms\\n2. Keep body in straight line from head to heels\\n3. Engage core and glutes\\n4. Hold position while breathing normally\\n5. Avoid sagging hips or raising butt',\n",
    "        'exercise_type': 'Bodyweight',\n",
    "        'movement_pattern': 'Anti-extension',\n",
    "        'primary_muscles': ['Core', 'Deep abdominals'],\n",
    "        'secondary_muscles': ['Shoulders', 'Glutes', 'Back'],\n",
    "        'muscle_groups': 'Core',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 4,\n",
    "        'prerequisites': 'Basic core strength',\n",
    "        'progressions': ['Wall plank', 'Knee plank'],\n",
    "        'regressions': ['Plank with leg lifts', 'Single-arm plank'],\n",
    "        'equipment_required': None,\n",
    "        'equipment_optional': 'Exercise mat',\n",
    "        'setup_time': 0,\n",
    "        'space_required': 'Minimal',\n",
    "        'rep_range_min': 1,\n",
    "        'rep_range_max': 1,\n",
    "        'tempo': 'Hold 15-120 seconds',\n",
    "        'range_of_motion': 'Static',\n",
    "        'compound_vs_isolation': 'Compound',\n",
    "        'injury_risk_level': 'Low',\n",
    "        'contraindications': 'Lower back pain, shoulder injuries',\n",
    "        'common_mistakes': ['Sagging hips', 'Raising butt', 'Holding breath'],\n",
    "        'safety_notes': 'Maintain neutral spine, breathe normally',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Functional', 'Bodyweight'],\n",
    "        'experience_level': ['Beginner', 'Intermediate', 'Advanced'],\n",
    "        'goals': ['Core strength', 'Stability'],\n",
    "        'duration_minutes': 2,\n",
    "        'popularity_score': 9,\n",
    "        'alternatives': ['Dead Bug', 'Bird Dog', 'Side Plank'],\n",
    "        'supersets_well_with': ['Any exercise', 'Glute bridges']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Banded Clams',\n",
    "        'description': 'Hip strengthening exercise using resistance band to target glute medius and improve hip stability.',\n",
    "        'instructions': '1. Lie on side with knees bent and band around thighs\\n2. Keep feet together\\n3. Lift top knee up against band resistance\\n4. Feel activation in side of glute\\n5. Lower with control and repeat',\n",
    "        'exercise_type': 'Resistance band',\n",
    "        'movement_pattern': 'Hip abduction',\n",
    "        'primary_muscles': ['Glute medius'],\n",
    "        'secondary_muscles': ['Glute minimus', 'Hip stabilizers'],\n",
    "        'muscle_groups': 'Lower body',\n",
    "        'unilateral': True,\n",
    "        'difficulty_rating': 3,\n",
    "        'prerequisites': 'Basic hip mobility',\n",
    "        'progressions': ['Clamshells without band'],\n",
    "        'regressions': ['Standing clamshells', 'Clamshells with heavier band'],\n",
    "        'equipment_required': ['Resistance band'],\n",
    "        'equipment_optional': 'Exercise mat',\n",
    "        'setup_time': 1,\n",
    "        'space_required': 'Minimal',\n",
    "        'rep_range_min': 12,\n",
    "        'rep_range_max': 25,\n",
    "        'tempo': '2-2-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Isolation',\n",
    "        'injury_risk_level': 'Low',\n",
    "        'contraindications': 'Hip impingement, IT band syndrome',\n",
    "        'common_mistakes': ['Rolling back', 'Using hip flexors', 'Too fast tempo'],\n",
    "        'safety_notes': 'Focus on glute activation, maintain side-lying position',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Rehabilitation', 'Functional'],\n",
    "        'experience_level': ['Beginner', 'Intermediate'],\n",
    "        'goals': ['Hip stability', 'Injury prevention'],\n",
    "        'duration_minutes': 2,\n",
    "        'popularity_score': 7,\n",
    "        'alternatives': ['Side-lying hip abduction', 'Monster walks', 'Fire hydrants'],\n",
    "        'supersets_well_with': ['Glute bridges', 'Leg raises']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Leg Raise',\n",
    "        'description': 'Core strengthening exercise performed by lifting legs while lying down to target lower abdominals and hip flexors.',\n",
    "        'instructions': '1. Lie on back with legs straight\\n2. Place hands under lower back for support\\n3. Keep legs straight and lift toward ceiling\\n4. Lower legs slowly without touching ground\\n5. Maintain lower back contact with floor',\n",
    "        'exercise_type': 'Bodyweight',\n",
    "        'movement_pattern': 'Hip flexion',\n",
    "        'primary_muscles': ['Lower abdominals', 'Hip flexors'],\n",
    "        'secondary_muscles': ['Core', 'Quadriceps'],\n",
    "        'muscle_groups': 'Core',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 5,\n",
    "        'prerequisites': 'Basic core strength, hip flexor flexibility',\n",
    "        'progressions': ['Bent knee raises', 'Assisted leg raises'],\n",
    "        'regressions': ['Hanging leg raises', 'Weighted leg raises'],\n",
    "        'equipment_required': None,\n",
    "        'equipment_optional': 'Exercise mat',\n",
    "        'setup_time': 0,\n",
    "        'space_required': 'Minimal',\n",
    "        'rep_range_min': 8,\n",
    "        'rep_range_max': 20,\n",
    "        'tempo': '2-1-3-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Isolation',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Lower back pain, hip flexor tightness',\n",
    "        'common_mistakes': ['Arching back', 'Using momentum', 'Not controlling descent'],\n",
    "        'safety_notes': 'Keep lower back pressed to floor, control the movement',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Bodyweight', 'Bodybuilding'],\n",
    "        'experience_level': ['Intermediate', 'Advanced'],\n",
    "        'goals': ['Core strength', 'Hypertrophy'],\n",
    "        'duration_minutes': 2,\n",
    "        'popularity_score': 7,\n",
    "        'alternatives': ['Hanging Leg Raises', 'Reverse Crunches', 'Dead Bug'],\n",
    "        'supersets_well_with': ['Plank variations', 'Calf raises']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lateral Pull Down',\n",
    "        'description': 'Upper body pulling exercise using a lat pulldown machine to target the latissimus dorsi and other back muscles.',\n",
    "        'instructions': '1. Sit at lat pulldown machine with thighs secured\\n2. Grip bar with wide overhand grip\\n3. Pull bar down to upper chest\\n4. Squeeze shoulder blades together\\n5. Control the weight back to starting position',\n",
    "        'exercise_type': 'Machine',\n",
    "        'movement_pattern': 'Pull',\n",
    "        'primary_muscles': ['Latissimus dorsi'],\n",
    "        'secondary_muscles': ['Rhomboids', 'Middle trapezius', 'Biceps'],\n",
    "        'muscle_groups': 'Upper body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 4,\n",
    "        'prerequisites': 'Basic pulling strength',\n",
    "        'progressions': ['Assisted pull-ups'],\n",
    "        'regressions': ['Pull-ups', 'Single-arm lat pulldown'],\n",
    "        'equipment_required': ['Lat pulldown machine'],\n",
    "        'equipment_optional': 'Different grip attachments',\n",
    "        'setup_time': 2,\n",
    "        'space_required': 'Large',\n",
    "        'rep_range_min': 6,\n",
    "        'rep_range_max': 15,\n",
    "        'tempo': '2-1-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Compound',\n",
    "        'injury_risk_level': 'Low',\n",
    "        'contraindications': 'Shoulder impingement, lat tightness',\n",
    "        'common_mistakes': ['Pulling behind neck', 'Leaning too far back', 'Using momentum'],\n",
    "        'safety_notes': 'Pull to front of body, maintain upright posture',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Bodybuilding', 'Functional'],\n",
    "        'experience_level': ['Beginner', 'Intermediate', 'Advanced'],\n",
    "        'goals': ['Strength', 'Hypertrophy'],\n",
    "        'duration_minutes': 3,\n",
    "        'popularity_score': 8,\n",
    "        'alternatives': ['Pull-ups', 'Seated Cable Row', 'T-Bar Row'],\n",
    "        'supersets_well_with': ['Chest Press', 'Shoulder exercises']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Weighted Bar Squat',\n",
    "        'description': 'Fundamental compound movement using a barbell to load the squat pattern, targeting the entire lower body.',\n",
    "        'instructions': '1. Position barbell on your upper back (high or low bar)\\n2. Stand with feet shoulder-width apart\\n3. Initiate movement by pushing hips back\\n4. Lower until thighs are parallel to ground\\n5. Drive through heels to return to standing',\n",
    "        'exercise_type': 'Free weights',\n",
    "        'movement_pattern': 'Squat',\n",
    "        'primary_muscles': ['Quadriceps', 'Glutes'],\n",
    "        'secondary_muscles': ['Hamstrings', 'Calves', 'Core', 'Upper back'],\n",
    "        'muscle_groups': 'Lower body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 7,\n",
    "        'prerequisites': 'Bodyweight squat mastery, proper mobility',\n",
    "        'progressions': ['Bodyweight Squat', 'Goblet Squat'],\n",
    "        'regressions': ['Front Squat', 'Overhead Squat'],\n",
    "        'equipment_required': ['Barbell', 'Squat Rack'],\n",
    "        'equipment_optional': 'Lifting shoes',\n",
    "        'setup_time': 3,\n",
    "        'space_required': 'Large',\n",
    "        'rep_range_min': 3,\n",
    "        'rep_range_max': 20,\n",
    "        'tempo': '3-1-X-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Compound',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Knee injuries, lower back issues',\n",
    "        'common_mistakes': ['Knee valgus', 'Forward lean', 'Partial range of motion'],\n",
    "        'safety_notes': 'Use safety bars, warm up thoroughly, maintain neutral spine',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Powerlifting', 'Bodybuilding', 'Functional'],\n",
    "        'experience_level': ['Intermediate', 'Advanced'],\n",
    "        'goals': ['Strength', 'Hypertrophy', 'Power'],\n",
    "        'duration_minutes': 4,\n",
    "        'popularity_score': 10,\n",
    "        'alternatives': ['Goblet Squat', 'Leg Press', 'Bulgarian Split Squat'],\n",
    "        'supersets_well_with': ['Pull-up', 'Plank']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Eccentric Heel Drop',\n",
    "        'description': 'Rehabilitation exercise focusing on the eccentric (lowering) phase to strengthen the Achilles tendon and calf muscles.',\n",
    "        'instructions': '1. Stand on a step with balls of feet on edge\\n2. Rise up onto toes with both feet\\n3. Lift one foot off the step\\n4. Slowly lower the heel of working leg below step level\\n5. Use both feet to return to starting position',\n",
    "        'exercise_type': 'Bodyweight',\n",
    "        'movement_pattern': 'Calf raise',\n",
    "        'primary_muscles': ['Calves'],\n",
    "        'secondary_muscles': ['Achilles tendon'],\n",
    "        'muscle_groups': 'Lower body',\n",
    "        'unilateral': True,\n",
    "        'difficulty_rating': 4,\n",
    "        'prerequisites': 'Basic calf raise',\n",
    "        'progressions': ['Calf Raise'],\n",
    "        'regressions': ['Weighted Eccentric Heel Drop'],\n",
    "        'equipment_required': ['Step/Box'],\n",
    "        'equipment_optional': None,\n",
    "        'setup_time': 1,\n",
    "        'space_required': 'Minimal',\n",
    "        'rep_range_min': 10,\n",
    "        'rep_range_max': 20,\n",
    "        'tempo': '1-1-5-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Isolation',\n",
    "        'injury_risk_level': 'Low',\n",
    "        'contraindications': 'Acute Achilles injury',\n",
    "        'common_mistakes': ['Too fast eccentric', 'Using both legs to lower'],\n",
    "        'safety_notes': 'Progress slowly, stop if pain increases',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Rehabilitation', 'Functional'],\n",
    "        'experience_level': ['Beginner', 'Intermediate'],\n",
    "        'goals': ['Strength', 'Rehabilitation'],\n",
    "        'duration_minutes': 2,\n",
    "        'popularity_score': 5,\n",
    "        'alternatives': ['Calf Raise', 'Seated Calf Raise'],\n",
    "        'supersets_well_with': ['Leg Raise', 'Plank']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Bulgarian Split Squat',\n",
    "        'description': 'Unilateral lower body exercise performed with rear foot elevated, emphasizing single-leg strength and stability.',\n",
    "        'instructions': '1. Stand 2-3 feet in front of a bench\\n2. Place top of rear foot on bench behind you\\n3. Lower into lunge position until front thigh is parallel\\n4. Drive through front heel to return to start\\n5. Complete all reps before switching legs',\n",
    "        'exercise_type': 'Bodyweight',\n",
    "        'movement_pattern': 'Lunge',\n",
    "        'primary_muscles': ['Quadriceps', 'Glutes'],\n",
    "        'secondary_muscles': ['Hamstrings', 'Calves', 'Core'],\n",
    "        'muscle_groups': 'Lower body',\n",
    "        'unilateral': True,\n",
    "        'difficulty_rating': 6,\n",
    "        'prerequisites': 'Basic lunge, single-leg balance',\n",
    "        'progressions': ['Reverse Lunge', 'Split Squat'],\n",
    "        'regressions': ['Weighted Bulgarian Split Squat', 'Jump Bulgarian Split Squat'],\n",
    "        'equipment_required': ['Bench/Box'],\n",
    "        'equipment_optional': 'Dumbbells',\n",
    "        'setup_time': 2,\n",
    "        'space_required': 'Moderate',\n",
    "        'rep_range_min': 8,\n",
    "        'rep_range_max': 20,\n",
    "        'tempo': '2-1-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Compound',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Knee injuries, ankle mobility issues',\n",
    "        'common_mistakes': ['Too much weight on rear foot', 'Knee valgus', 'Forward lean'],\n",
    "        'safety_notes': 'Focus on front leg doing the work, maintain balance',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Functional', 'Bodybuilding'],\n",
    "        'experience_level': ['Intermediate', 'Advanced'],\n",
    "        'goals': ['Strength', 'Hypertrophy', 'Functional'],\n",
    "        'duration_minutes': 3,\n",
    "        'popularity_score': 8,\n",
    "        'alternatives': ['Lunges', 'Single Leg Squat', 'Step Up'],\n",
    "        'supersets_well_with': ['Push-up variations', 'Plank']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Single-Arm Press With Balance',\n",
    "        'description': 'Unilateral overhead press performed while balancing on one leg to challenge stability and core strength.',\n",
    "        'instructions': '1. Stand on one leg holding dumbbell at shoulder height\\n2. Engage core and maintain balance\\n3. Press weight overhead while staying balanced\\n4. Lower with control\\n5. Complete set before switching sides',\n",
    "        'exercise_type': 'Free weights',\n",
    "        'movement_pattern': 'Push',\n",
    "        'primary_muscles': ['Shoulders', 'Core'],\n",
    "        'secondary_muscles': ['Triceps', 'Upper back', 'Glutes', 'Hip stabilizers'],\n",
    "        'muscle_groups': 'Full body',\n",
    "        'unilateral': True,\n",
    "        'difficulty_rating': 7,\n",
    "        'prerequisites': 'Single-leg balance, overhead press',\n",
    "        'progressions': ['Overhead Press', 'Single-leg stands'],\n",
    "        'regressions': ['Single-arm press with eyes closed', 'Single-arm press on unstable surface'],\n",
    "        'equipment_required': ['Dumbbell'],\n",
    "        'equipment_optional': None,\n",
    "        'setup_time': 1,\n",
    "        'space_required': 'Moderate',\n",
    "        'rep_range_min': 6,\n",
    "        'rep_range_max': 12,\n",
    "        'tempo': '2-1-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Compound',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Shoulder impingement, balance disorders',\n",
    "        'common_mistakes': ['Using too heavy weight', 'Losing balance', 'Compensatory movements'],\n",
    "        'safety_notes': 'Start light, have something to grab for balance if needed',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Functional', 'Bodybuilding'],\n",
    "        'experience_level': ['Intermediate', 'Advanced'],\n",
    "        'goals': ['Strength', 'Functional', 'Balance'],\n",
    "        'duration_minutes': 3,\n",
    "        'popularity_score': 6,\n",
    "        'alternatives': ['Overhead Press', 'Single-arm Press', 'Pike Push-up'],\n",
    "        'supersets_well_with': ['Single Leg Squat', 'Plank variations']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Weighted Offset Dead Bug',\n",
    "        'description': 'Anti-extension core exercise performed with uneven loading to challenge stability and coordination.',\n",
    "        'instructions': '1. Lie on back with arms extended toward ceiling\\n2. Hold different weights in each hand\\n3. Bring knees to 90 degrees\\n4. Extend opposite arm and leg while maintaining lower back contact\\n5. Return to start and alternate sides',\n",
    "        'exercise_type': 'Free weights',\n",
    "        'movement_pattern': 'Anti-extension',\n",
    "        'primary_muscles': ['Core', 'Deep abdominals'],\n",
    "        'secondary_muscles': ['Hip flexors', 'Shoulders'],\n",
    "        'muscle_groups': 'Core',\n",
    "        'unilateral': True,\n",
    "        'difficulty_rating': 6,\n",
    "        'prerequisites': 'Regular dead bug, core stability',\n",
    "        'progressions': ['Dead Bug', 'Bird Dog'],\n",
    "        'regressions': ['Weighted Dead Bug (even weight)', 'Dead Bug with band'],\n",
    "        'equipment_required': ['Dumbbells (different weights)'],\n",
    "        'equipment_optional': None,\n",
    "        'setup_time': 2,\n",
    "        'space_required': 'Minimal',\n",
    "        'rep_range_min': 6,\n",
    "        'rep_range_max': 12,\n",
    "        'tempo': '2-2-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Isolation',\n",
    "        'injury_risk_level': 'Low',\n",
    "        'contraindications': 'Lower back pain, shoulder injuries',\n",
    "        'common_mistakes': ['Losing lower back contact', 'Moving too fast', 'Holding breath'],\n",
    "        'safety_notes': 'Maintain neutral spine throughout, breathe normally',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Functional', 'Rehabilitation'],\n",
    "        'experience_level': ['Intermediate', 'Advanced'],\n",
    "        'goals': ['Stability', 'Core strength'],\n",
    "        'duration_minutes': 3,\n",
    "        'popularity_score': 5,\n",
    "        'alternatives': ['Dead Bug', 'Pallof Press', 'Plank variations'],\n",
    "        'supersets_well_with': ['Glute bridges', 'Calf raises']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Shrug',\n",
    "        'description': 'Isolation exercise targeting the upper trapezius muscles by elevating the shoulders against resistance.',\n",
    "        'instructions': '1. Stand holding weights at your sides or in front\\n2. Keep arms straight and shoulders relaxed\\n3. Shrug shoulders up toward ears\\n4. Squeeze at the top\\n5. Lower shoulders slowly',\n",
    "        'exercise_type': 'Free weights',\n",
    "        'movement_pattern': 'Shrug',\n",
    "        'primary_muscles': ['Upper trapezius'],\n",
    "        'secondary_muscles': ['Levator scapulae', 'Rhomboids'],\n",
    "        'muscle_groups': 'Upper body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 3,\n",
    "        'prerequisites': 'Basic grip strength',\n",
    "        'progressions': ['Bodyweight shrugs'],\n",
    "        'regressions': ['Barbell shrugs', 'Behind-the-back shrugs'],\n",
    "        'equipment_required': ['Dumbbells or Barbell'],\n",
    "        'equipment_optional': 'Straps',\n",
    "        'setup_time': 1,\n",
    "        'space_required': 'Minimal',\n",
    "        'rep_range_min': 10,\n",
    "        'rep_range_max': 20,\n",
    "        'tempo': '1-2-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Isolation',\n",
    "        'injury_risk_level': 'Low',\n",
    "        'contraindications': 'Neck injuries, shoulder impingement',\n",
    "        'common_mistakes': ['Rolling shoulders', 'Using too much weight', 'Partial range of motion'],\n",
    "        'safety_notes': 'Avoid rolling shoulders, straight up and down motion only',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Bodybuilding', 'Powerlifting'],\n",
    "        'experience_level': ['Beginner', 'Intermediate', 'Advanced'],\n",
    "        'goals': ['Hypertrophy', 'Strength'],\n",
    "        'duration_minutes': 2,\n",
    "        'popularity_score': 7,\n",
    "        'alternatives': ['Upright Row', 'Face Pulls', 'Trap Raise'],\n",
    "        'supersets_well_with': ['Calf Raise', 'Lateral raises']\n",
    "    },\n",
    "    {\n",
    "        'name': '45 lb Calf Raise',\n",
    "        'description': 'Calf strengthening exercise performed with a 45-pound weight to target the gastrocnemius and soleus muscles.',\n",
    "        'instructions': '1. Stand holding 45lb weight (plate or dumbbell)\\n2. Position balls of feet on slightly elevated surface\\n3. Rise up onto toes as high as possible\\n4. Squeeze calves at the top\\n5. Lower heels below starting position for stretch',\n",
    "        'exercise_type': 'Free weights',\n",
    "        'movement_pattern': 'Calf raise',\n",
    "        'primary_muscles': ['Calves'],\n",
    "        'secondary_muscles': ['Forearms'],\n",
    "        'muscle_groups': 'Lower body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 4,\n",
    "        'prerequisites': 'Basic calf raise',\n",
    "        'progressions': ['Bodyweight calf raise'],\n",
    "        'regressions': ['Heavier weighted calf raise', 'Single-leg calf raise'],\n",
    "        'equipment_required': ['45lb weight', 'Step/Platform'],\n",
    "        'equipment_optional': None,\n",
    "        'setup_time': 2,\n",
    "        'space_required': 'Minimal',\n",
    "        'rep_range_min': 12,\n",
    "        'rep_range_max': 25,\n",
    "        'tempo': '1-2-2-2',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Isolation',\n",
    "        'injury_risk_level': 'Low',\n",
    "        'contraindications': 'Achilles tendon injuries, calf strains',\n",
    "        'common_mistakes': ['Bouncing at bottom', 'Partial range of motion', 'Using momentum'],\n",
    "        'safety_notes': 'Control the weight, don\\'t bounce, maintain balance',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Bodybuilding', 'Functional'],\n",
    "        'experience_level': ['Beginner', 'Intermediate'],\n",
    "        'goals': ['Hypertrophy', 'Strength'],\n",
    "        'duration_minutes': 2,\n",
    "        'popularity_score': 8,\n",
    "        'alternatives': ['Seated Calf Raise', 'Single-leg Calf Raise', 'Eccentric Heel Drop'],\n",
    "        'supersets_well_with': ['Shrug', 'Leg Raise']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Chest Press',\n",
    "        'description': 'Fundamental pushing exercise targeting the chest, shoulders, and triceps using dumbbells or machine.',\n",
    "        'instructions': '1. Lie on bench with weights at chest level\\n2. Plant feet firmly on ground\\n3. Press weights up and slightly together\\n4. Lower with control to chest level\\n5. Maintain shoulder blade stability',\n",
    "        'exercise_type': 'Free weights',\n",
    "        'movement_pattern': 'Push',\n",
    "        'primary_muscles': ['Chest'],\n",
    "        'secondary_muscles': ['Shoulders', 'Triceps'],\n",
    "        'muscle_groups': 'Upper body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 4,\n",
    "        'prerequisites': 'Basic pushing movement',\n",
    "        'progressions': ['Push-up', 'Incline press'],\n",
    "        'regressions': ['Barbell bench press', 'Single-arm press'],\n",
    "        'equipment_required': ['Dumbbells', 'Bench'],\n",
    "        'equipment_optional': None,\n",
    "        'setup_time': 2,\n",
    "        'space_required': 'Moderate',\n",
    "        'rep_range_min': 6,\n",
    "        'rep_range_max': 15,\n",
    "        'tempo': '2-1-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Compound',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Shoulder impingement, recent chest surgery',\n",
    "        'common_mistakes': ['Bouncing off chest', 'Flaring elbows too wide', 'Arching back excessively'],\n",
    "        'safety_notes': 'Use spotter for heavy weights, maintain control throughout',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Bodybuilding', 'Powerlifting'],\n",
    "        'experience_level': ['Beginner', 'Intermediate', 'Advanced'],\n",
    "        'goals': ['Strength', 'Hypertrophy'],\n",
    "        'duration_minutes': 3,\n",
    "        'popularity_score': 9,\n",
    "        'alternatives': ['Push-up', 'Bench Press', 'Chest Flies'],\n",
    "        'supersets_well_with': ['Pull-up', 'Lat Pulldown', 'Shrug']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Chest Flies',\n",
    "        'description': 'Isolation exercise for the chest performed with a fly motion to target pectoral muscles with minimal tricep involvement.',\n",
    "        'instructions': '1. Lie on bench holding dumbbells above chest\\n2. Lower weights in wide arc with slight elbow bend\\n3. Feel stretch in chest at bottom\\n4. Bring weights together above chest in hugging motion\\n5. Squeeze chest muscles at top',\n",
    "        'exercise_type': 'Free weights',\n",
    "        'movement_pattern': 'Fly',\n",
    "        'primary_muscles': ['Chest'],\n",
    "        'secondary_muscles': ['Shoulders'],\n",
    "        'muscle_groups': 'Upper body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 5,\n",
    "        'prerequisites': 'Chest press, shoulder stability',\n",
    "        'progressions': ['Chest press'],\n",
    "        'regressions': ['Cable flies', 'Incline flies'],\n",
    "        'equipment_required': ['Dumbbells', 'Bench'],\n",
    "        'equipment_optional': None,\n",
    "        'setup_time': 2,\n",
    "        'space_required': 'Moderate',\n",
    "        'rep_range_min': 8,\n",
    "        'rep_range_max': 15,\n",
    "        'tempo': '2-2-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Isolation',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Shoulder impingement, chest strains',\n",
    "        'common_mistakes': ['Using too much weight', 'Dropping elbows too low', 'Turning into press'],\n",
    "        'safety_notes': 'Keep slight bend in elbows, control the stretch',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Bodybuilding'],\n",
    "        'experience_level': ['Intermediate', 'Advanced'],\n",
    "        'goals': ['Hypertrophy'],\n",
    "        'duration_minutes': 3,\n",
    "        'popularity_score': 7,\n",
    "        'alternatives': ['Cable Flies', 'Pec Deck', 'Push-up variations'],\n",
    "        'supersets_well_with': ['Tricep exercises', 'Rear delt flies']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Single Leg Squat',\n",
    "        'description': 'Advanced unilateral exercise requiring significant strength, balance, and mobility to perform a full squat on one leg.',\n",
    "        'instructions': '1. Stand on one leg with other leg extended forward\\n2. Keep extended leg straight and off ground\\n3. Lower into squat position on standing leg\\n4. Go as deep as possible while maintaining form\\n5. Drive through heel to return to standing',\n",
    "        'exercise_type': 'Bodyweight',\n",
    "        'movement_pattern': 'Squat',\n",
    "        'primary_muscles': ['Quadriceps', 'Glutes'],\n",
    "        'secondary_muscles': ['Hamstrings', 'Calves', 'Core', 'Hip stabilizers'],\n",
    "        'muscle_groups': 'Lower body',\n",
    "        'unilateral': True,\n",
    "        'difficulty_rating': 9,\n",
    "        'prerequisites': 'Excellent single-leg balance, strong squat, ankle mobility',\n",
    "        'progressions': ['Assisted single-leg squat', 'Box pistol squat'],\n",
    "        'regressions': ['Jump single-leg squat', 'Weighted single-leg squat'],\n",
    "        'equipment_required': None,\n",
    "        'equipment_optional': 'TRX or assistance',\n",
    "        'setup_time': 1,\n",
    "        'space_required': 'Minimal',\n",
    "        'rep_range_min': 3,\n",
    "        'rep_range_max': 10,\n",
    "        'tempo': '3-1-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Compound',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Knee injuries, poor balance, limited ankle mobility',\n",
    "        'common_mistakes': ['Knee valgus', 'Using momentum', 'Partial range of motion'],\n",
    "        'safety_notes': 'Progress slowly, ensure adequate strength and mobility first',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Functional', 'Bodyweight'],\n",
    "        'experience_level': ['Advanced'],\n",
    "        'goals': ['Strength', 'Functional', 'Balance'],\n",
    "        'duration_minutes': 2,\n",
    "        'popularity_score': 6,\n",
    "        'alternatives': ['Bulgarian Split Squat', 'Lunges', 'Step-ups'],\n",
    "        'supersets_well_with': ['Push-up variations', 'Plank']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Pogo Hops',\n",
    "        'description': 'Plyometric exercise focusing on quick, repetitive jumping to develop calf strength, ankle stiffness, and reactive ability.',\n",
    "        'instructions': '1. Stand with feet hip-width apart\\n2. Keep legs relatively straight\\n3. Hop up and down quickly using only ankles and calves\\n4. Minimize ground contact time\\n5. Land on balls of feet and immediately bounce up',\n",
    "        'exercise_type': 'Bodyweight',\n",
    "        'movement_pattern': 'Jump',\n",
    "        'primary_muscles': ['Calves', 'Ankles'],\n",
    "        'secondary_muscles': ['Core', 'Hip stabilizers'],\n",
    "        'muscle_groups': 'Lower body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 5,\n",
    "        'prerequisites': 'Basic jumping ability, healthy ankles',\n",
    "        'progressions': ['Calf raises', 'Small hops'],\n",
    "        'regressions': ['Single-leg pogo hops', 'Weighted pogo hops'],\n",
    "        'equipment_required': None,\n",
    "        'equipment_optional': None,\n",
    "        'setup_time': 0,\n",
    "        'space_required': 'Minimal',\n",
    "        'rep_range_min': 15,\n",
    "        'rep_range_max': 50,\n",
    "        'tempo': 'Fast',\n",
    "        'range_of_motion': 'Partial',\n",
    "        'compound_vs_isolation': 'Isolation',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Ankle injuries, Achilles problems, shin splints',\n",
    "        'common_mistakes': ['Bending knees too much', 'Slow rhythm', 'Landing on heels'],\n",
    "        'safety_notes': 'Start with shorter sets, progress volume gradually',\n",
    "        'category': 'Power',\n",
    "        'training_style': ['Functional', 'Sport-specific'],\n",
    "        'experience_level': ['Intermediate', 'Advanced'],\n",
    "        'goals': ['Power', 'Reactive strength'],\n",
    "        'duration_minutes': 1,\n",
    "        'popularity_score': 6,\n",
    "        'alternatives': ['Jump rope', 'Calf raises', 'Box jumps'],\n",
    "        'supersets_well_with': ['Static stretches', 'Mobility work']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Trap Raise',\n",
    "        'description': 'Isolation exercise targeting the middle and lower trapezius muscles through shoulder blade retraction and elevation.',\n",
    "        'instructions': '1. Lie face down on incline bench or stand bent over\\n2. Hold light weights with arms extended\\n3. Raise arms up and back in Y-formation\\n4. Squeeze shoulder blades together\\n5. Lower with control',\n",
    "        'exercise_type': 'Free weights',\n",
    "        'movement_pattern': 'Pull',\n",
    "        'primary_muscles': ['Middle trapezius', 'Lower trapezius'],\n",
    "        'secondary_muscles': ['Rhomboids', 'Rear deltoids'],\n",
    "        'muscle_groups': 'Upper body',\n",
    "        'unilateral': False,\n",
    "        'difficulty_rating': 4,\n",
    "        'prerequisites': 'Basic shoulder mobility',\n",
    "        'progressions': ['Prone Y-raises without weight'],\n",
    "        'regressions': ['Face pulls', 'Band pull-aparts'],\n",
    "        'equipment_required': ['Light dumbbells'],\n",
    "        'equipment_optional': 'Incline bench',\n",
    "        'setup_time': 2,\n",
    "        'space_required': 'Moderate',\n",
    "        'rep_range_min': 10,\n",
    "        'rep_range_max': 20,\n",
    "        'tempo': '2-2-2-1',\n",
    "        'range_of_motion': 'Full',\n",
    "        'compound_vs_isolation': 'Isolation',\n",
    "        'injury_risk_level': 'Moderate',\n",
    "        'contraindications': 'Knee injuries, balance issues',\n",
    "        'common_mistakes': ['Using too heavy weight', 'Not controlling the descent', 'Poor balance'],\n",
    "        'safety_notes': 'Ensure box is stable, start with lighter weights',\n",
    "        'category': 'Strength',\n",
    "        'training_style': ['Functional', 'Bodybuilding'],\n",
    "        'experience_level': ['Intermediate', 'Advanced'],\n",
    "        'goals': ['Strength', 'Hypertrophy', 'Functional'],\n",
    "        'duration_minutes': 3,\n",
    "        'popularity_score': 6,\n",
    "        'alternatives': ['Step Up', 'Hammer Curl', 'Lunge with Curl'],\n",
    "        'supersets_well_with': ['Chest Press', 'Plank']\n",
    "    },\n",
    "    {\n",
    "    'name': 'Weighted Step Up',\n",
    "    'description': 'Unilateral lower body exercise targeting quadriceps and glutes while holding additional weight.',\n",
    "    'instructions': '1. Stand facing a box or bench holding dumbbells\\n2. Step up with one foot, driving through heel\\n3. Bring other foot up to standing position\\n4. Step down with control, same foot first\\n5. Complete all reps on one side before switching',\n",
    "    'exercise_type': 'Free weights',\n",
    "    'movement_pattern': 'Push',\n",
    "    'primary_muscles': ['Quadriceps', 'Glutes'],\n",
    "    'secondary_muscles': ['Hamstrings', 'Calves', 'Core'],\n",
    "    'muscle_groups': 'Lower body',\n",
    "    'unilateral': True,\n",
    "    'difficulty_rating': 6,\n",
    "    'prerequisites': 'Basic balance and coordination',\n",
    "    'progressions': ['Bodyweight step up'],\n",
    "    'regressions': ['Higher box height', 'Heavier weights', 'Explosive step ups'],\n",
    "    'equipment_required': ['Box or bench', 'Dumbbells'],\n",
    "    'equipment_optional': 'Barbell',\n",
    "    'setup_time': 2,\n",
    "    'space_required': 'Moderate',\n",
    "    'rep_range_min': 8,\n",
    "    'rep_range_max': 15,\n",
    "    'tempo': '2-1-2-1',\n",
    "    'range_of_motion': 'Full',\n",
    "    'compound_vs_isolation': 'Compound',\n",
    "    'injury_risk_level': 'Moderate',\n",
    "    'contraindications': 'Knee injuries, ankle instability',\n",
    "    'common_mistakes': ['Pushing off back foot', 'Leaning forward excessively', 'Not controlling descent'],\n",
    "    'safety_notes': 'Ensure box is stable, start with bodyweight only',\n",
    "    'category': 'Strength',\n",
    "    'training_style': ['Functional', 'Athletic'],\n",
    "    'experience_level': ['Beginner', 'Intermediate', 'Advanced'],\n",
    "    'goals': ['Strength', 'Power', 'Functional'],\n",
    "    'duration_minutes': 4,\n",
    "    'popularity_score': 7,\n",
    "    'alternatives': ['Lunges', 'Bulgarian split squats', 'Single leg squats'],\n",
    "    'supersets_well_with': ['Push ups', 'Plank', 'Upper body exercises']\n",
    "},\n",
    "{\n",
    "    'name': 'Hammer Curl',\n",
    "    'description': 'Bicep isolation exercise using neutral grip to target biceps and forearms.',\n",
    "    'instructions': '1. Stand with dumbbells at sides, palms facing body\\n2. Keep elbows close to torso\\n3. Curl weights up without rotating wrists\\n4. Squeeze at top, maintain neutral grip\\n5. Lower with control',\n",
    "    'exercise_type': 'Free weights',\n",
    "    'movement_pattern': 'Pull',\n",
    "    'primary_muscles': ['Biceps', 'Brachialis'],\n",
    "    'secondary_muscles': ['Brachioradialis', 'Forearms'],\n",
    "    'muscle_groups': 'Upper body',\n",
    "    'unilateral': False,\n",
    "    'difficulty_rating': 3,\n",
    "    'prerequisites': 'Basic arm strength',\n",
    "    'progressions': ['Assisted curls with resistance bands'],\n",
    "    'regressions': ['Cable hammer curls', 'Alternating hammer curls'],\n",
    "    'equipment_required': ['Dumbbells'],\n",
    "    'equipment_optional': 'Cable machine',\n",
    "    'setup_time': 1,\n",
    "    'space_required': 'Minimal',\n",
    "    'rep_range_min': 8,\n",
    "    'rep_range_max': 15,\n",
    "    'tempo': '2-1-2-1',\n",
    "    'range_of_motion': 'Full',\n",
    "    'compound_vs_isolation': 'Isolation',\n",
    "    'injury_risk_level': 'Low',\n",
    "    'contraindications': 'Elbow injuries, wrist pain',\n",
    "    'common_mistakes': ['Swinging body', 'Using momentum', 'Partial range of motion'],\n",
    "    'safety_notes': 'Keep core engaged, avoid ego lifting',\n",
    "    'category': 'Strength',\n",
    "    'training_style': ['Bodybuilding', 'General fitness'],\n",
    "    'experience_level': ['Beginner', 'Intermediate', 'Advanced'],\n",
    "    'goals': ['Hypertrophy', 'Strength'],\n",
    "    'duration_minutes': 3,\n",
    "    'popularity_score': 8,\n",
    "    'alternatives': ['Regular bicep curls', 'Cable curls', 'Chin ups'],\n",
    "    'supersets_well_with': ['Tricep exercises', 'Shoulder exercises']\n",
    "},\n",
    "{\n",
    "    'name': 'Back Bridge',\n",
    "    'description': 'Bodyweight exercise targeting posterior chain through spinal extension and hip flexor stretching.',\n",
    "    'instructions': '1. Lie on back, knees bent, feet flat\\n2. Place hands by ears, fingers toward shoulders\\n3. Press through hands and feet to lift body\\n4. Form arch from hands to feet\\n5. Hold position, breathe steadily',\n",
    "    'exercise_type': 'Bodyweight',\n",
    "    'movement_pattern': 'Extension',\n",
    "    'primary_muscles': ['Erector spinae', 'Glutes'],\n",
    "    'secondary_muscles': ['Shoulders', 'Triceps', 'Hip flexors'],\n",
    "    'muscle_groups': 'Full body',\n",
    "    'unilateral': False,\n",
    "    'difficulty_rating': 8,\n",
    "    'prerequisites': 'Good shoulder and spinal mobility',\n",
    "    'progressions': ['Wall bridge', 'Bridge from knees'],\n",
    "    'regressions': ['Bridge walks', 'Single arm/leg variations'],\n",
    "    'equipment_required': [],\n",
    "    'equipment_optional': 'Yoga mat',\n",
    "    'setup_time': 1,\n",
    "    'space_required': 'Moderate',\n",
    "    'rep_range_min': 3,\n",
    "    'rep_range_max': 10,\n",
    "    'tempo': 'Hold 10-30 seconds',\n",
    "    'range_of_motion': 'Full',\n",
    "    'compound_vs_isolation': 'Compound',\n",
    "    'injury_risk_level': 'High',\n",
    "    'contraindications': 'Neck injuries, shoulder impingement, lower back problems',\n",
    "    'common_mistakes': ['Insufficient warm-up', 'Forcing the position', 'Poor hand placement'],\n",
    "    'safety_notes': 'Requires extensive mobility work, progress gradually',\n",
    "    'category': 'Flexibility',\n",
    "    'training_style': ['Gymnastics', 'Yoga', 'Mobility'],\n",
    "    'experience_level': ['Advanced'],\n",
    "    'goals': ['Flexibility', 'Functional'],\n",
    "    'duration_minutes': 5,\n",
    "    'popularity_score': 4,\n",
    "    'alternatives': ['Camel pose', 'Cobra stretch', 'Hip flexor stretches'],\n",
    "    'supersets_well_with': ['Forward folds', 'Core exercises']\n",
    "},\n",
    "{\n",
    "    'name': 'Tricep Pulldown',\n",
    "    'description': 'Cable isolation exercise targeting triceps through elbow extension.',\n",
    "    'instructions': '1. Stand at cable machine with rope or bar attachment\\n2. Keep elbows close to sides\\n3. Pull attachment down by extending forearms\\n4. Squeeze triceps at bottom\\n5. Return with control',\n",
    "    'exercise_type': 'Cable',\n",
    "    'movement_pattern': 'Push',\n",
    "    'primary_muscles': ['Triceps'],\n",
    "    'secondary_muscles': ['Anterior deltoids', 'Core'],\n",
    "    'muscle_groups': 'Upper body',\n",
    "    'unilateral': False,\n",
    "    'difficulty_rating': 4,\n",
    "    'prerequisites': 'Basic upper body strength',\n",
    "    'progressions': ['Assisted dips'],\n",
    "    'regressions': ['Single arm pulldowns', 'Overhead extensions'],\n",
    "    'equipment_required': ['Cable machine', 'Rope or bar attachment'],\n",
    "    'equipment_optional': 'Different attachments',\n",
    "    'setup_time': 2,\n",
    "    'space_required': 'Minimal',\n",
    "    'rep_range_min': 10,\n",
    "    'rep_range_max': 20,\n",
    "    'tempo': '2-1-2-1',\n",
    "    'range_of_motion': 'Full',\n",
    "    'compound_vs_isolation': 'Isolation',\n",
    "    'injury_risk_level': 'Low',\n",
    "    'contraindications': 'Elbow pain, shoulder injuries',\n",
    "    'common_mistakes': ['Moving elbows', 'Using shoulders', 'Partial range of motion'],\n",
    "    'safety_notes': 'Start light, focus on form over weight',\n",
    "    'category': 'Strength',\n",
    "    'training_style': ['Bodybuilding', 'General fitness'],\n",
    "    'experience_level': ['Beginner', 'Intermediate', 'Advanced'],\n",
    "    'goals': ['Hypertrophy', 'Strength'],\n",
    "    'duration_minutes': 3,\n",
    "    'popularity_score': 8,\n",
    "    'alternatives': ['Tricep dips', 'Close grip push ups', 'Overhead tricep extension'],\n",
    "    'supersets_well_with': ['Bicep exercises', 'Chest exercises']\n",
    "},\n",
    "{\n",
    "    'name': 'Single Leg Jump Plyometric',\n",
    "    'description': 'Explosive unilateral plyometric exercise developing power and stability in single leg stance.',\n",
    "    'instructions': '1. Stand on one leg with slight knee bend\\n2. Jump vertically as high as possible\\n3. Land softly on same leg with control\\n4. Absorb impact through entire leg\\n5. Reset and repeat',\n",
    "    'exercise_type': 'Plyometric',\n",
    "    'movement_pattern': 'Jump',\n",
    "    'primary_muscles': ['Quadriceps', 'Glutes', 'Calves'],\n",
    "    'secondary_muscles': ['Hamstrings', 'Core', 'Stabilizers'],\n",
    "    'muscle_groups': 'Lower body',\n",
    "    'unilateral': True,\n",
    "    'difficulty_rating': 7,\n",
    "    'prerequisites': 'Good single leg balance and strength',\n",
    "    'progressions': ['Two leg jumps', 'Assisted single leg jumps'],\n",
    "    'regressions': ['Multi-directional jumps', 'Weighted jumps'],\n",
    "    'equipment_required': [],\n",
    "    'equipment_optional': 'Soft landing surface',\n",
    "    'setup_time': 1,\n",
    "    'space_required': 'Moderate',\n",
    "    'rep_range_min': 5,\n",
    "    'rep_range_max': 10,\n",
    "    'tempo': 'Explosive up, controlled landing',\n",
    "    'range_of_motion': 'Full',\n",
    "    'compound_vs_isolation': 'Compound',\n",
    "    'injury_risk_level': 'High',\n",
    "    'contraindications': 'Knee injuries, ankle instability, balance issues',\n",
    "    'common_mistakes': ['Hard landings', 'Poor balance', 'Insufficient knee bend'],\n",
    "    'safety_notes': 'Master two-leg jumps first, ensure proper landing mechanics',\n",
    "    'category': 'Power',\n",
    "    'training_style': ['Athletic', 'Sports specific'],\n",
    "    'experience_level': ['Intermediate', 'Advanced'],\n",
    "    'goals': ['Power', 'Athletic performance'],\n",
    "    'duration_minutes': 3,\n",
    "    'popularity_score': 6,\n",
    "    'alternatives': ['Two leg jumps', 'Single leg squats', 'Hop variations'],\n",
    "    'supersets_well_with': ['Upper body exercises', 'Core work']\n",
    "},\n",
    "{\n",
    "    'name': 'Single Leg Bounding Plyometric',\n",
    "    'description': 'Horizontal plyometric exercise emphasizing forward propulsion and single leg power.',\n",
    "    'instructions': '1. Start on one leg with forward lean\\n2. Bound forward as far as possible\\n3. Land on same leg with control\\n4. Immediately bound again\\n5. Continue for distance or reps',\n",
    "    'exercise_type': 'Plyometric',\n",
    "    'movement_pattern': 'Bound',\n",
    "    'primary_muscles': ['Glutes', 'Hamstrings', 'Calves'],\n",
    "    'secondary_muscles': ['Quadriceps', 'Core', 'Hip flexors'],\n",
    "    'muscle_groups': 'Lower body',\n",
    "    'unilateral': True,\n",
    "    'difficulty_rating': 8,\n",
    "    'prerequisites': 'Excellent single leg strength and coordination',\n",
    "    'progressions': ['Walking lunges', 'Single leg hops in place'],\n",
    "    'regressions': ['Alternating bounds', 'Speed bounds'],\n",
    "    'equipment_required': [],\n",
    "    'equipment_optional': 'Grass or track surface',\n",
    "    'setup_time': 1,\n",
    "    'space_required': 'Large',\n",
    "    'rep_range_min': 3,\n",
    "    'rep_range_max': 8,\n",
    "    'tempo': 'Explosive, minimal ground contact',\n",
    "    'range_of_motion': 'Full',\n",
    "    'compound_vs_isolation': 'Compound',\n",
    "    'injury_risk_level': 'High',\n",
    "    'contraindications': 'Knee injuries, ankle problems, poor balance',\n",
    "    'common_mistakes': ['Too much vertical, not enough horizontal', 'Long ground contact time', 'Poor landing mechanics'],\n",
    "    'safety_notes': 'Requires advanced athletic ability, proper surface essential',\n",
    "    'category': 'Power',\n",
    "    'training_style': ['Athletic', 'Sports specific'],\n",
    "    'experience_level': ['Advanced'],\n",
    "    'goals': ['Power', 'Speed', 'Athletic performance'],\n",
    "    'duration_minutes': 4,\n",
    "    'popularity_score': 5,\n",
    "    'alternatives': ['Running bounds', 'Broad jumps', 'Single leg hops'],\n",
    "    'supersets_well_with': ['Recovery exercises', 'Upper body work']\n",
    "},\n",
    "{\n",
    "    'name': 'Box Drop Jump Plyometric',\n",
    "    'description': 'Advanced plyometric exercise involving dropping from height and immediately jumping to develop reactive strength.',\n",
    "    'instructions': '1. Stand on box 12-24 inches high\\n2. Step off (don\\'t jump off) landing on both feet\\n3. Immediately jump vertically as high as possible\\n4. Land softly with bent knees\\n5. Reset by stepping back onto box',\n",
    "    'exercise_type': 'Plyometric',\n",
    "    'movement_pattern': 'Jump',\n",
    "    'primary_muscles': ['Quadriceps', 'Glutes', 'Calves'],\n",
    "    'secondary_muscles': ['Hamstrings', 'Core', 'Stabilizers'],\n",
    "    'muscle_groups': 'Lower body',\n",
    "    'unilateral': False,\n",
    "    'difficulty_rating': 9,\n",
    "    'prerequisites': 'Excellent jump mechanics and eccentric strength',\n",
    "    'progressions': ['Basic jump squats', 'Box jumps'],\n",
    "    'regressions': ['Higher boxes', 'Single leg variations'],\n",
    "    'equipment_required': ['Sturdy box or platform'],\n",
    "    'equipment_optional': 'Soft landing surface',\n",
    "    'setup_time': 3,\n",
    "    'space_required': 'Large',\n",
    "    'rep_range_min': 3,\n",
    "    'rep_range_max': 6,\n",
    "    'tempo': 'Minimal ground contact time',\n",
    "    'range_of_motion': 'Full',\n",
    "    'compound_vs_isolation': 'Compound',\n",
    "    'injury_risk_level': 'Very High',\n",
    "    'contraindications': 'Knee injuries, ankle problems, inexperience with plyometrics',\n",
    "    'common_mistakes': ['Jumping off box instead of stepping', 'Too high starting height', 'Poor landing mechanics'],\n",
    "    'safety_notes': 'Advanced exercise only, master basic plyometrics first',\n",
    "    'category': 'Power',\n",
    "    'training_style': ['Athletic', 'Sports specific'],\n",
    "    'experience_level': ['Advanced'],\n",
    "    'goals': ['Reactive strength', 'Power', 'Athletic performance'],\n",
    "    'duration_minutes': 5,\n",
    "    'popularity_score': 4,\n",
    "    'alternatives': ['Depth jumps', 'Box jumps', 'Jump squats'],\n",
    "    'supersets_well_with': ['Long rest periods required']\n",
    "},\n",
    "\n",
    "{\n",
    "    'name': 'Weighted Lunge',\n",
    "    'description': 'Unilateral lower body exercise targeting quadriceps and glutes while holding additional weight.',\n",
    "    'instructions': '1. Stand holding dumbbells at sides or barbell across shoulders\\n2. Step forward into lunge position\\n3. Lower back knee toward ground\\n4. Push through front heel to return to start\\n5. Alternate legs or complete one side first',\n",
    "    'exercise_type': 'Free weights',\n",
    "    'movement_pattern': 'Push',\n",
    "    'primary_muscles': ['Quadriceps', 'Glutes'],\n",
    "    'secondary_muscles': ['Hamstrings', 'Calves', 'Core'],\n",
    "    'muscle_groups': 'Lower body',\n",
    "    'unilateral': True,\n",
    "    'difficulty_rating': 5,\n",
    "    'prerequisites': 'Basic balance and bodyweight lunge proficiency',\n",
    "    'progressions': ['Bodyweight lunges', 'Static lunges'],\n",
    "    'regressions': ['Walking lunges', 'Reverse lunges', 'Lateral lunges'],\n",
    "    'equipment_required': ['Dumbbells or barbell'],\n",
    "    'equipment_optional': 'Weight vest',\n",
    "    'setup_time': 2,\n",
    "    'space_required': 'Moderate',\n",
    "    'rep_range_min': 8,\n",
    "    'rep_range_max': 15,\n",
    "    'tempo': '2-1-2-1',\n",
    "    'range_of_motion': 'Full',\n",
    "    'compound_vs_isolation': 'Compound',\n",
    "    'injury_risk_level': 'Moderate',\n",
    "    'contraindications': 'Knee injuries, hip mobility issues, balance problems',\n",
    "    'common_mistakes': ['Knee extending past toes', 'Leaning forward', 'Insufficient depth'],\n",
    "    'safety_notes': 'Master bodyweight version first, keep torso upright',\n",
    "    'category': 'Strength',\n",
    "    'training_style': ['Functional', 'Athletic', 'Bodybuilding'],\n",
    "    'experience_level': ['Beginner', 'Intermediate', 'Advanced'],\n",
    "    'goals': ['Strength', 'Hypertrophy', 'Functional'],\n",
    "    'duration_minutes': 4,\n",
    "    'popularity_score': 9,\n",
    "    'alternatives': ['Split squats', 'Step ups', 'Bulgarian split squats'],\n",
    "    'supersets_well_with': ['Upper body exercises', 'Core work', 'Calf raises']\n",
    "},\n",
    "\n",
    "{\n",
    "    'name': 'Russian Twists',\n",
    "    'description': 'Core exercise targeting obliques and transverse abdominis through rotational movement.',\n",
    "    'instructions': '1. Sit with knees bent, feet lifted or on ground\\n2. Lean back to 45-degree angle\\n3. Hold weight or clasp hands together\\n4. Rotate torso left and right\\n5. Keep chest up and core engaged',\n",
    "    'exercise_type': 'Bodyweight',\n",
    "    'movement_pattern': 'Rotation',\n",
    "    'primary_muscles': ['Obliques', 'Transverse abdominis'],\n",
    "    'secondary_muscles': ['Rectus abdominis', 'Hip flexors'],\n",
    "    'muscle_groups': 'Core',\n",
    "    'unilateral': False,\n",
    "    'difficulty_rating': 4,\n",
    "    'prerequisites': 'Basic core strength',\n",
    "    'progressions': ['Seated twists', 'Dead bug'],\n",
    "    'regressions': ['Weighted Russian twists', 'Feet elevated twists'],\n",
    "    'equipment_required': [],\n",
    "    'equipment_optional': 'Medicine ball, dumbbell, or weight plate',\n",
    "    'setup_time': 1,\n",
    "    'space_required': 'Minimal',\n",
    "    'rep_range_min': 15,\n",
    "    'rep_range_max': 30,\n",
    "    'tempo': '1-0-1-0',\n",
    "    'range_of_motion': 'Full rotation',\n",
    "    'compound_vs_isolation': 'Isolation',\n",
    "    'injury_risk_level': 'Low',\n",
    "    'contraindications': 'Lower back injuries, neck problems',\n",
    "    'common_mistakes': ['Pulling on neck', 'Moving too fast', 'Not engaging core'],\n",
    "    'safety_notes': 'Keep movements controlled, avoid excessive spinal flexion',\n",
    "    'category': 'Strength',\n",
    "    'training_style': ['Core training', 'General fitness'],\n",
    "    'experience_level': ['Beginner', 'Intermediate', 'Advanced'],\n",
    "    'goals': ['Core strength', 'Stability', 'Functional'],\n",
    "    'duration_minutes': 3,\n",
    "    'popularity_score': 8,\n",
    "    'alternatives': ['Bicycle crunches', 'Wood chops', 'Plank variations'],\n",
    "    'supersets_well_with': ['Planks', 'Lower body exercises', 'Cardio']\n",
    "},\n",
    "{\n",
    "    'name': 'Banded Fire Hydrant',\n",
    "    'description': 'Hip abduction exercise using resistance band to target glute medius and improve hip stability.',\n",
    "    'instructions': '1. Start on hands and knees with band around thighs\\n2. Keep core engaged and spine neutral\\n3. Lift one knee out to side against band resistance\\n4. Hold briefly at top\\n5. Lower with control and repeat',\n",
    "    'exercise_type': 'Resistance band',\n",
    "    'movement_pattern': 'Abduction',\n",
    "    'primary_muscles': ['Glute medius', 'Glute minimus'],\n",
    "    'secondary_muscles': ['Glute maximus', 'Core', 'Hip stabilizers'],\n",
    "    'muscle_groups': 'Lower body',\n",
    "    'unilateral': True,\n",
    "    'difficulty_rating': 3,\n",
    "    'prerequisites': 'Basic hip mobility',\n",
    "    'progressions': ['Bodyweight fire hydrants'],\n",
    "    'regressions': ['Pulse variations', 'Heavier resistance bands'],\n",
    "    'equipment_required': ['Resistance band'],\n",
    "    'equipment_optional': 'Exercise mat',\n",
    "    'setup_time': 2,\n",
    "    'space_required': 'Minimal',\n",
    "    'rep_range_min': 12,\n",
    "    'rep_range_max': 20,\n",
    "    'tempo': '2-1-2-1',\n",
    "    'range_of_motion': 'Full hip abduction',\n",
    "    'compound_vs_isolation': 'Isolation',\n",
    "    'injury_risk_level': 'Low',\n",
    "    'contraindications': 'Knee injuries, hip impingement, wrist pain',\n",
    "    'common_mistakes': ['Rotating pelvis', 'Lifting leg too high', 'Arching back'],\n",
    "    'safety_notes': 'Keep pelvis square, focus on glute activation',\n",
    "    'category': 'Strength',\n",
    "    'training_style': ['Rehabilitation', 'Activation', 'Functional'],\n",
    "    'experience_level': ['Beginner', 'Intermediate'],\n",
    "    'goals': ['Hip stability', 'Glute activation', 'Injury prevention'],\n",
    "    'duration_minutes': 3,\n",
    "    'popularity_score': 7,\n",
    "    'alternatives': ['Side-lying leg lifts', 'Clamshells', 'Lateral walks'],\n",
    "    'supersets_well_with': ['Glute bridges', 'Squats', 'Other activation exercises']\n",
    "}\n",
    ",\n",
    "{\n",
    "    'name': 'Pushup',\n",
    "    'description': 'Classic bodyweight exercise targeting chest, shoulders, and triceps through horizontal pushing movement.',\n",
    "    'instructions': '1. Start in plank position with hands shoulder-width apart\\n2. Lower body until chest nearly touches ground\\n3. Keep body in straight line from head to heels\\n4. Push back up to starting position\\n5. Maintain core engagement throughout',\n",
    "    'exercise_type': 'Bodyweight',\n",
    "    'movement_pattern': 'Push',\n",
    "    'primary_muscles': ['Pectorals', 'Anterior deltoids', 'Triceps'],\n",
    "    'secondary_muscles': ['Core', 'Serratus anterior', 'Upper back'],\n",
    "    'muscle_groups': 'Upper body',\n",
    "    'unilateral': False,\n",
    "    'difficulty_rating': 4,\n",
    "    'prerequisites': 'Basic upper body and core strength',\n",
    "    'progressions': ['Wall pushups', 'Incline pushups', 'Knee pushups'],\n",
    "    'regressions': ['Diamond pushups', 'One-arm pushups', 'Weighted pushups'],\n",
    "    'equipment_required': [],\n",
    "    'equipment_optional': 'Exercise mat',\n",
    "    'setup_time': 1,\n",
    "    'space_required': 'Minimal',\n",
    "    'rep_range_min': 8,\n",
    "    'rep_range_max': 25,\n",
    "    'tempo': '2-0-2-0',\n",
    "    'range_of_motion': 'Full',\n",
    "    'compound_vs_isolation': 'Compound',\n",
    "    'injury_risk_level': 'Low',\n",
    "    'contraindications': 'Wrist injuries, shoulder impingement, lower back pain',\n",
    "    'common_mistakes': ['Sagging hips', 'Flaring elbows too wide', 'Partial range of motion'],\n",
    "    'safety_notes': 'Keep neutral spine, modify if wrist pain occurs',\n",
    "    'category': 'Strength',\n",
    "    'training_style': ['Calisthenics', 'General fitness', 'Military training'],\n",
    "    'experience_level': ['Beginner', 'Intermediate', 'Advanced'],\n",
    "    'goals': ['Strength', 'Endurance', 'Functional'],\n",
    "    'duration_minutes': 2,\n",
    "    'popularity_score': 10,\n",
    "    'alternatives': ['Chest press', 'Dumbbell press', 'Dips'],\n",
    "    'supersets_well_with': ['Pull exercises', 'Core work', 'Lower body exercises']\n",
    "},\n",
    "{\n",
    "    'name': 'Wood Chop Oblique Twist',\n",
    "    'description': 'Dynamic rotational core exercise targeting obliques through diagonal movement pattern mimicking wood chopping motion.',\n",
    "    'instructions': '1. Stand with feet shoulder-width apart holding weight\\n2. Start with weight at one shoulder\\n3. Rotate and chop diagonally across body to opposite knee\\n4. Engage core and pivot on back foot\\n5. Return to start position with control',\n",
    "    'exercise_type': 'Free weights',\n",
    "    'movement_pattern': 'Rotation',\n",
    "    'primary_muscles': ['Obliques', 'Transverse abdominis'],\n",
    "    'secondary_muscles': ['Rectus abdominis', 'Shoulders', 'Hip flexors'],\n",
    "    'muscle_groups': 'Core',\n",
    "    'unilateral': False,\n",
    "    'difficulty_rating': 5,\n",
    "    'prerequisites': 'Good core stability and coordination',\n",
    "    'progressions': ['Bodyweight wood chops', 'Half wood chops'],\n",
    "    'regressions': ['Cable wood chops', 'Medicine ball slams'],\n",
    "    'equipment_required': ['Dumbbell or medicine ball'],\n",
    "    'equipment_optional': 'Cable machine',\n",
    "    'setup_time': 2,\n",
    "    'space_required': 'Moderate',\n",
    "    'rep_range_min': 10,\n",
    "    'rep_range_max': 20,\n",
    "    'tempo': '2-0-2-1',\n",
    "    'range_of_motion': 'Full diagonal rotation',\n",
    "    'compound_vs_isolation': 'Compound',\n",
    "    'injury_risk_level': 'Moderate',\n",
    "    'contraindications': 'Lower back injuries, shoulder impingement, hip problems',\n",
    "    'common_mistakes': ['Using only arms', 'Moving too fast', 'Not engaging core'],\n",
    "    'safety_notes': 'Start with light weight, control the movement throughout',\n",
    "    'category': 'Strength',\n",
    "    'training_style': ['Functional', 'Athletic', 'Core training'],\n",
    "    'experience_level': ['Intermediate', 'Advanced'],\n",
    "    'goals': ['Core strength', 'Power', 'Functional movement'],\n",
    "    'duration_minutes': 3,\n",
    "    'popularity_score': 7,\n",
    "    'alternatives': ['Russian twists', 'Cable rotations', 'Bicycle crunches'],\n",
    "    'supersets_well_with': ['Planks', 'Anti-rotation exercises', 'Compound movements']\n",
    "}\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f508c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import utils.db_utils\n",
    "from config import Config\n",
    "\n",
    "def add_exercise(data):\n",
    "    with sqlite3.connect(Config.DB_PATH) as conn:\n",
    "        c = conn.cursor()\n",
    "        c.execute('''\n",
    "        INSERT INTO exercises (\n",
    "            name, description, instructions, exercise_type, movement_pattern,\n",
    "            primary_muscles, secondary_muscles, muscle_groups, unilateral,\n",
    "            difficulty_rating, prerequisites, progressions, regressions,\n",
    "            equipment_required, equipment_optional, setup_time, space_required,\n",
    "            rep_range_min, rep_range_max, tempo, range_of_motion, compound_vs_isolation,\n",
    "            injury_risk_level, contraindications, common_mistakes, safety_notes,\n",
    "            image_url, video_url, gif_url, diagram_url,\n",
    "            category, training_style, experience_level, goals,\n",
    "            duration_minutes, popularity_score, alternatives, supersets_well_with\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', [\n",
    "            data.get('name'), data.get('description'), data.get('instructions'), data.get('exercise_type'), data.get('movement_pattern'),\n",
    "            json.dumps(data.get('primary_muscles')), json.dumps(data.get('secondary_muscles')), data.get('muscle_groups'), data.get('unilateral'),\n",
    "            data.get('difficulty_rating'), data.get('prerequisites'), json.dumps(data.get('progressions')), json.dumps(data.get('regressions')),\n",
    "            json.dumps(data.get('equipment_required')), data.get('equipment_optional'), data.get('setup_time'), data.get('space_required'),\n",
    "            data.get('rep_range_min'), data.get('rep_range_max'), data.get('tempo'), data.get('range_of_motion'), data.get('compound_vs_isolation'),\n",
    "            data.get('injury_risk_level'), data.get('contraindications'), json.dumps(data.get('common_mistakes')), data.get('safety_notes'),\n",
    "            data.get('image_url'), data.get('video_url'), data.get('gif_url'), data.get('diagram_url'),\n",
    "            data.get('category'), json.dumps(data.get('training_style')), json.dumps(data.get('experience_level')), json.dumps(data.get('goals')),\n",
    "            data.get('duration_minutes'), data.get('popularity_score'), json.dumps(data.get('alternatives')), json.dumps(data.get('supersets_well_with'))\n",
    "        ])\n",
    "        conn.commit()\n",
    "\n",
    "# Function to populate database\n",
    "def populate_exercise_database():\n",
    "    \"\"\"\n",
    "    Populate the exercise database with all exercises.\n",
    "    Call this function to insert all exercise data into your database.\n",
    "    \"\"\"\n",
    "    print(\"Starting to populate exercise database...\")\n",
    "    \n",
    "    for i, exercise in enumerate(exercises_data, 1):\n",
    "        try:\n",
    "            add_exercise(exercise)\n",
    "            print(f\"âœ“ Added exercise {i}/{len(exercises_data)}: {exercise['name']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Failed to add {exercise['name']}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nDatabase population complete! Added {len(exercises_data)} exercises.\")\n",
    "\n",
    "# Function to add individual exercises (useful for testing)\n",
    "def add_single_exercise(exercise_name):\n",
    "    \"\"\"\n",
    "    Add a single exercise by name for testing purposes.\n",
    "    \"\"\"\n",
    "    exercise = next((ex for ex in exercises_data if ex['name'] == exercise_name), None)\n",
    "    if exercise:\n",
    "        try:\n",
    "            add_exercise(exercise)\n",
    "            print(f\"âœ“ Successfully added: {exercise_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Failed to add {exercise_name}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"Exercise '{exercise_name}' not found in dataset\")\n",
    "\n",
    "# Function to get exercise data (useful for inspection)\n",
    "def get_exercise_data(exercise_name):\n",
    "    \"\"\"\n",
    "    Get the data dictionary for a specific exercise.\n",
    "    \"\"\"\n",
    "    return next((ex for ex in exercises_data if ex['name'] == exercise_name), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21a8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 20:15:39,934 [INFO] Starting daily fatigue tracking update...\n",
      "2025-06-05 20:15:39,946 [INFO] Sample data inserted\n",
      "2025-06-05 20:15:39,948 [INFO] Updating muscle group fatigue...\n",
      "2025-06-05 20:15:39,950 [INFO] Processing muscle groups: ['Rear Deltoids', 'Rhomboids', 'Brachioradialis', 'Upper Body', 'Glute Maximus', 'Levator Scapulae', 'Lower Body', 'Latissimus Dorsi', 'Ankles', 'Shoulders', 'Lower Back', 'Upper Trapezius', 'Obliques', 'Full Body', 'Stabilizers', 'Erector Spinae', 'Calves', 'Back', 'Quadriceps', 'Glute Minimus', 'Lower Abdominals', 'Hip Flexors', 'Brachialis', 'Forearms', 'Glutes', 'Deep Abdominals', 'Transverse Abdominis', 'Hamstrings', 'Hip Stabilizers', 'Lower Trapezius', 'Glute Medius', 'Serratus Anterior', 'Middle Trapezius', 'Rectus Abdominis', 'Chest', 'Arms', 'Core', 'Pectorals', 'Achilles Tendon', 'Upper Back', 'Anterior Deltoids']\n",
      "2025-06-05 20:15:39,951 [INFO] Processing muscle group: Rear Deltoids\n",
      "2025-06-05 20:15:39,954 [INFO] Processing muscle group: Rhomboids\n",
      "2025-06-05 20:15:39,955 [INFO] Processing muscle group: Brachioradialis\n",
      "2025-06-05 20:15:39,957 [INFO] Processing muscle group: Upper Body\n",
      "2025-06-05 20:15:39,959 [INFO] Processing muscle group: Glute Maximus\n",
      "2025-06-05 20:15:39,960 [INFO] Processing muscle group: Levator Scapulae\n",
      "2025-06-05 20:15:39,960 [INFO] Processing muscle group: Lower Body\n",
      "2025-06-05 20:15:39,962 [INFO] Processing muscle group: Latissimus Dorsi\n",
      "2025-06-05 20:15:39,963 [INFO] Processing muscle group: Ankles\n",
      "2025-06-05 20:15:39,964 [INFO] Processing muscle group: Shoulders\n",
      "2025-06-05 20:15:39,965 [INFO] Processing muscle group: Lower Back\n",
      "2025-06-05 20:15:39,966 [INFO] Processing muscle group: Upper Trapezius\n",
      "2025-06-05 20:15:39,967 [INFO] Processing muscle group: Obliques\n",
      "2025-06-05 20:15:39,967 [INFO] Processing muscle group: Full Body\n",
      "2025-06-05 20:15:39,969 [INFO] Processing muscle group: Stabilizers\n",
      "2025-06-05 20:15:39,970 [INFO] Processing muscle group: Erector Spinae\n",
      "2025-06-05 20:15:39,971 [INFO] Processing muscle group: Calves\n",
      "2025-06-05 20:15:39,973 [INFO] Processing muscle group: Back\n",
      "2025-06-05 20:15:39,974 [INFO] Processing muscle group: Quadriceps\n",
      "2025-06-05 20:15:39,975 [INFO] Processing muscle group: Glute Minimus\n",
      "2025-06-05 20:15:39,976 [INFO] Processing muscle group: Lower Abdominals\n",
      "2025-06-05 20:15:39,978 [INFO] Processing muscle group: Hip Flexors\n",
      "2025-06-05 20:15:39,979 [INFO] Processing muscle group: Brachialis\n",
      "2025-06-05 20:15:39,980 [INFO] Processing muscle group: Forearms\n",
      "2025-06-05 20:15:39,981 [INFO] Processing muscle group: Glutes\n",
      "2025-06-05 20:15:39,982 [INFO] Processing muscle group: Deep Abdominals\n",
      "2025-06-05 20:15:39,987 [INFO] Processing muscle group: Transverse Abdominis\n",
      "2025-06-05 20:15:39,991 [INFO] Processing muscle group: Hamstrings\n",
      "2025-06-05 20:15:39,993 [INFO] Processing muscle group: Hip Stabilizers\n",
      "2025-06-05 20:15:39,995 [INFO] Processing muscle group: Lower Trapezius\n",
      "2025-06-05 20:15:39,996 [INFO] Processing muscle group: Glute Medius\n",
      "2025-06-05 20:15:39,999 [INFO] Processing muscle group: Serratus Anterior\n",
      "2025-06-05 20:15:40,001 [INFO] Processing muscle group: Middle Trapezius\n",
      "2025-06-05 20:15:40,004 [INFO] Processing muscle group: Rectus Abdominis\n",
      "2025-06-05 20:15:40,005 [INFO] Processing muscle group: Chest\n",
      "2025-06-05 20:15:40,006 [INFO] Processing muscle group: Arms\n",
      "2025-06-05 20:15:40,007 [INFO] Processing muscle group: Core\n",
      "2025-06-05 20:15:40,008 [INFO] Processing muscle group: Pectorals\n",
      "2025-06-05 20:15:40,009 [INFO] Processing muscle group: Achilles Tendon\n",
      "2025-06-05 20:15:40,010 [INFO] Processing muscle group: Upper Back\n",
      "2025-06-05 20:15:40,010 [INFO] Processing muscle group: Anterior Deltoids\n",
      "2025-06-05 20:15:40,019 [INFO] Muscle group fatigue update completed\n",
      "2025-06-05 20:15:40,028 [INFO] Fatigue tracking update complete.\n",
      "2025-06-05 20:15:40,030 [INFO] Fetching fatigue dashboard data...\n"
     ]
    }
   ],
   "source": [
    "from services import runstrong_service \n",
    "\n",
    "build = runstrong_service.RunStrongService('strava_data.db')\n",
    "# build.initialize_runstrong_database()\n",
    "x = build.run_daily_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eeeb618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(exercises_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f96bc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to populate exercise database...\n",
      "âœ— Failed to add Box Jump: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Kettlebell Romanian Deadlift with Dumbbells: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Deadlift: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Pull-up: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Plank: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Banded Clams: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Leg Raise: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Lateral Pull Down: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Weighted Bar Squat: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Eccentric Heel Drop: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Bulgarian Split Squat: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Single-Arm Press With Balance: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Weighted Offset Dead Bug: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Shrug: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add 45 lb Calf Raise: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Chest Press: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Chest Flies: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Single Leg Squat: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Pogo Hops: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Trap Raise: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Weighted Step Up: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Hammer Curl: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Back Bridge: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Tricep Pulldown: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Single Leg Jump Plyometric: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Single Leg Bounding Plyometric: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Box Drop Jump Plyometric: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Weighted Lunge: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Russian Twists: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Banded Fire Hydrant: UNIQUE constraint failed: exercises.name\n",
      "âœ— Failed to add Pushup: UNIQUE constraint failed: exercises.name\n",
      "âœ“ Added exercise 32/32: Wood Chop Oblique Twist\n",
      "\n",
      "Database population complete! Added 32 exercises.\n"
     ]
    }
   ],
   "source": [
    "populate_exercise_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc27d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 14695490446, 'resource_state': 2, 'athlete_id': 24266563, 'athlete_resource_state': 1, 'name': 'Morning Run', 'distance': 10284.1, 'moving_time': 3089, 'elapsed_time': 3089, 'total_elevation_gain': 35.0, 'type': 'Run', 'sport_type': 'Run', 'workout_type': 0, 'start_date': '2025-06-04T15:14:08Z', 'start_date_local': '2025-06-04T10:14:08Z', 'timezone': '(GMT-06:00) America/Chicago', 'utc_offset': -18000.0, 'location_city': None, 'location_state': None, 'location_country': None, 'achievement_count': 0, 'kudos_count': 1, 'comment_count': 0, 'athlete_count': 1, 'photo_count': 0, 'map_id': 'a14695490446', 'map_summary_polyline': '{}jqGnuqxPCoCi@uDKaCB}@D]XyA^_AT_@J[VYHCpAT`@Ax@KnBa@VCJCRO^KDIAOSu@SiCA]@MTg@F[Aa@IeA?_@L}@@qBRaCJkGD}FDaBPsBJcCCcAFuBAcARiDHm@Am@GQEEE?GFCJ?LDLR\\\\RRHDJ@JEj@k@VIJAL@VJZZNZBNBjCj@hCN\\\\JAL_@PyA`@cADO?KAKGCGBUZWp@sAfFSfAUx@UbBOvD@lACv@Br@Jl@XrCd@lCb@tBNbBX|AXz@j@x@t@nBn@z@`@z@JRJl@DJPR`An@l@f@`BdB~ArBx@z@dCpBpAz@lAj@jBh@rAZ`@FrBRj@Ll@FlABb@Fp@@h@Fz@Bv@FvAGn@KbAWv@_@pA{@v@Q`AEp@BXFbAj@XTHBFCFYHEJ?p@Tp@\\\\h@Rx@TbAPVAHEf@[RSVg@Ni@\\\\kBLeBAwAWeDJkB?uBIq@WsAC_@?QPaAJiCLo@`@eA`@u@^k@h@m@LYn@uDLaABa@?kBIuAEeC_@sBSgBOw@q@aC}BgFI]Gg@Ow@s@sASQk@UaA_AoA{@cAc@qBm@g@McBUaCK{AEkAM_ACgAOoBG{@?}@Hm@Ca@Ec@@a@DmBZULURc@LUN{@NkBjAoBt@yAhAkA`@uAl@UNm@Ni@Vo@Nm@Tq@NWA_A[YEe@?YDSNg@~@I|@]|@UVY@eAc@k@OEYRQNk@FqAI]OWa@QYEQ@UJUj@IDWBIAGIS}@Oa@Y]KCI@EHALAjACr@QzBObAUjDk@lDIdA[dCQdCShAMfAK^QZIHSPc@Pc@BY?iAQeA?gATg@V_@LIFEJCLOjGLtBL`AH\\\\HJf@`@v@f@HFBHAJGJaA`A{@rAQ~@?^N~@Xz@t@dAnAfADH@NAPO|@ARBfAAv@F^\\\\lARpALZRV', 'map_resource_state': 2, 'trainer': 0, 'commute': 0, 'manual': 0, 'private': 0, 'visibility': 'everyone', 'flagged': 0, 'gear_id': 'g17224321', 'start_latlng': '[44.949576, -93.324885]', 'end_latlng': '[44.949493, -93.32496]', 'average_speed': 3.329, 'max_speed': 4.7, 'average_cadence': 90.8, 'average_watts': 236.8, 'max_watts': 313, 'weighted_average_watts': 237, 'device_watts': 1, 'kilojoules': 731.5, 'has_heartrate': 1, 'average_heartrate': 137.2, 'max_heartrate': 155.0, 'heartrate_opt_out': 0, 'display_hide_heartrate_option': 1, 'elev_high': 275.0, 'elev_low': 265.0, 'upload_id': 15681917963, 'upload_id_str': '15681917963', 'external_id': '469508186766868499.fit', 'from_accepted_tag': 0, 'pr_count': 0, 'total_photo_count': 0, 'has_kudoed': 0, 'import_date': '2025-06-04T11:31:10.898612'}\n",
      "0    67.826236\n",
      "Name: ctl, dtype: object\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from config import Config\n",
    "import pandas as pd\n",
    "from utils import db_utils\n",
    "\n",
    "with db_utils.get_db_connection(Config.DB_PATH) as conn:\n",
    "        c = conn.cursor()\n",
    "        output = c.execute(\"\"\"\n",
    "select * from activities order by start_date_local desc limit 3\"\"\").fetchall()\n",
    "        # conn.commit()\n",
    "        # query = \"\"\"\n",
    "        # SELECT date, total_tss, ctl, atl, tsb\n",
    "        # FROM daily_training_metrics\n",
    "        # ORDER BY date DESC\n",
    "        # \"\"\"\n",
    "\n",
    "        # df = pd.read_sql(query, conn)\n",
    "        df_2 = db_utils.get_latest_daily_training_metrics(conn=conn)\n",
    "# print(db_eval)\n",
    "print(output[0])\n",
    "# print(round(df['total_tss']), 1)\n",
    "print(pd.DataFrame.from_dict(df_2[0], orient='index').loc[\"ctl\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1109cbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'activities'},\n",
       " {'name': 'streams'},\n",
       " {'name': 'gear'},\n",
       " {'name': 'daily_training_metrics'},\n",
       " {'name': 'sqlite_sequence'},\n",
       " {'name': 'workout_routines'},\n",
       " {'name': 'routine_exercises'},\n",
       " {'name': 'workout_performance'},\n",
       " {'name': 'exercises'},\n",
       " {'name': 'conversations'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2999c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "[{'name': 'activities'},\n",
    " {'name': 'streams'},\n",
    " {'name': 'gear'},\n",
    " {'name': 'daily_training_metrics'},\n",
    " {'name': 'sqlite_sequence'},\n",
    " {'name': 'workout_routines'},\n",
    " {'name': 'routine_exercises'},\n",
    " {'name': 'workout_performance'},\n",
    " {'name': 'exercises'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[('main', 'routine_exercises', 'table', 8, 0, 0),\n",
    " ('main', 'workout_routines', 'table', 3, 0, 0),\n",
    " ('main', 'exercises', 'table', 39, 0, 0),\n",
    " ('main', 'sqlite_sequence', 'table', 2, 0, 0),\n",
    " ('main', 'sqlite_schema', 'table', 5, 0, 0),\n",
    " ('temp', 'sqlite_temp_schema', 'table', 5, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c90e1cf",
   "metadata": {},
   "source": [
    "## Daily Metrics Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102ba9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Development\\RunningHub\\utils\\db_utils.py:887: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  daily_df['tss'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from config import Config\n",
    "import pandas as pd\n",
    "\n",
    "from utils import db_utils\n",
    "\n",
    "df = db_utils.get_ctl_atl_tsb_tss_data().tail(1)\n",
    "try:\n",
    "    with db_utils.get_db_connection(Config.DB_PATH) as conn:\n",
    "        db_utils.update_daily_training_metrics(conn=conn, df=df)\n",
    "except Exception as e:\n",
    "    print(f'db write failed: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3259afd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  tss        CTL        ATL       TSB\n",
      "90 2025-06-04  0.0  66.562369  65.019856  1.542514\n"
     ]
    }
   ],
   "source": [
    "print(df.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd52276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.06it/s]\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "LanguageModelError",
     "evalue": "Failed to extract SQL: Cannot operate on a closed database.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Development\\RunningHub\\utils\\db_utils.py:44\u001b[39m, in \u001b[36mConnectionPool.get_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m conn\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m sqlite3.Error \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Development\\RunningHub\\utils\\db_utils.py:74\u001b[39m, in \u001b[36mget_db_connection\u001b[39m\u001b[34m(db_path)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pool.get_connection() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m conn\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Development\\RunningHub\\utils\\language_model_utils.py:191\u001b[39m, in \u001b[36mLanguageModel.generate_daily_training_summary\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m db_utils.get_db_connection(Config.DB_PATH) \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m         training_metrics = \u001b[43mdb_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_latest_daily_training_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Development\\RunningHub\\utils\\db_utils.py:1495\u001b[39m, in \u001b[36mget_latest_daily_training_metrics\u001b[39m\u001b[34m(conn)\u001b[39m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1495\u001b[39m     conn.close()\n",
      "\u001b[31mProgrammingError\u001b[39m: Cannot operate on a closed database.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Development\\RunningHub\\utils\\language_model_utils.py:190\u001b[39m, in \u001b[36mLanguageModel.generate_daily_training_summary\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdb_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_db_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDB_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_latest_daily_training_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\smith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Development\\RunningHub\\utils\\db_utils.py:73\u001b[39m, in \u001b[36mget_db_connection\u001b[39m\u001b[34m(db_path)\u001b[39m\n\u001b[32m     72\u001b[39m pool = get_connection_pool(db_path)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\smith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Development\\RunningHub\\utils\\db_utils.py:47\u001b[39m, in \u001b[36mConnectionPool.get_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     46\u001b[39m logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDatabase operation failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrollback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception_utils.DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDatabase error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mProgrammingError\u001b[39m: Cannot operate on a closed database.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mLanguageModelError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m language_model_utils\n\u001b[32m      2\u001b[39m coach_g = language_model_utils.LanguageModel()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcoach_g\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_daily_training_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Development\\RunningHub\\utils\\language_model_utils.py:193\u001b[39m, in \u001b[36mLanguageModel.generate_daily_training_summary\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    191\u001b[39m         training_metrics = db_utils.get_latest_daily_training_metrics(conn=conn)\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception_utils.LanguageModelError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to extract SQL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[38;5;28mprint\u001b[39m(training_metrics[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtotal_tss\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    197\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[33m    You are a running coach assistant. Summarize today\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms training load.\u001b[39m\n\u001b[32m    199\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    213\u001b[39m \u001b[33m    Respond with 2-4 sentences.\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[31mLanguageModelError\u001b[39m: Failed to extract SQL: Cannot operate on a closed database."
     ]
    }
   ],
   "source": [
    "from utils import language_model_utils\n",
    "coach_g = language_model_utils.LanguageModel()\n",
    "print(coach_g.generate_daily_training_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96db8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_conversation_database():\n",
    "    \"\"\"Create the SQLite database and full 'activities' table.\"\"\"\n",
    "    conn = sqlite3.connect(Config.DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute('''\n",
    "    CREATE TABLE conversations (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    session_id TEXT,\n",
    "    role TEXT, -- \"user\" or \"coach\"\n",
    "    message TEXT,\n",
    "    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "    ''')\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c47197",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_conversation_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd3e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "372242b3",
   "metadata": {},
   "source": [
    "## Strava API Update catchup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847053be",
   "metadata": {},
   "source": [
    "After running all this, possible false alarm? Or strava updated their API docs without rolling out changes? \n",
    "\n",
    "Either way this works, and if needed in the future, just remove the constraints on running this for activities that were previously missing the columns and let it blast through all 2500 or so in a few calls\n",
    "\n",
    "Update: You misread the documentation by looking at the activity/id type of data pull, not athlete/activity section. Still not fully matching up but if we ever want all that data, this will make it happen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "254f27a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any, Union\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from utils import db_utils\n",
    "from config import Config\n",
    "\n",
    "# Configure module-level logger\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9ea0e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backfill_activities_from_api(access_token: str, db_path: str, \n",
    "                                 activity_ids: List[int] = None,\n",
    "                                 **optional_parameters) -> int:\n",
    "    \"\"\"\n",
    "    Fetch activities from Strava API and update database with new fields.\n",
    "    \n",
    "    Args:\n",
    "        access_token: Valid Strava access token\n",
    "        db_path: Path to the SQLite database\n",
    "        activity_ids: Specific activity IDs to update (if None, fetches all)\n",
    "        **optional_parameters: Additional query parameters (before, after timestamps)\n",
    "        \n",
    "    Returns:\n",
    "        Number of activities successfully updated\n",
    "        \n",
    "    Raises:\n",
    "        requests.HTTPError: If API request fails\n",
    "        sqlite3.Error: If database operations fail\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_activities_page(page: int = 1, per_page: int = 30) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Internal function to fetch a single page of activities.\"\"\"\n",
    "        url = \"https://www.strava.com/api/v3/athlete/activities\"\n",
    "        headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "        \n",
    "        params = {\n",
    "            \"page\": page,\n",
    "            \"per_page\": min(per_page, 200)\n",
    "        }\n",
    "        params.update(optional_parameters)\n",
    "        \n",
    "        try:\n",
    "            logger.debug(f\"Fetching activities page {page} with params: {params}\")\n",
    "            response = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            activities = response.json()\n",
    "            logger.info(f\"Successfully fetched {len(activities)} activities on page {page}\")\n",
    "            return activities\n",
    "            \n",
    "        except requests.exceptions.Timeout:\n",
    "            logger.error(\"Request timeout when fetching activities\")\n",
    "            raise\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            logger.error(f\"HTTP error fetching activities: {e}\")\n",
    "            raise\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Request error fetching activities: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def update_activities_in_db(activity_list: List[Dict[str, Any]]) -> int:\n",
    "        \"\"\"Internal function to update activities in database.\"\"\"\n",
    "        if not activity_list:\n",
    "            return 0\n",
    "            \n",
    "        try:\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                \n",
    "                data = []\n",
    "                for activity in activity_list:\n",
    "                    # Skip if filtering by activity_ids and this isn't in the list\n",
    "                    if activity_ids and activity.get(\"id\") not in activity_ids:\n",
    "                        continue\n",
    "                        \n",
    "                    gear_data = activity.get(\"gear\", {})\n",
    "                    photos_data = activity.get(\"photos\", {})\n",
    "                    \n",
    "                    data.append({\n",
    "                        \"id\": activity.get(\"id\"),\n",
    "                        \"average_temp\": activity.get(\"average_temp\"),\n",
    "                        \"calories\": activity.get(\"calories\"),\n",
    "                        \"suffer_score\": activity.get(\"suffer_score\"),\n",
    "                        \"description\": activity.get(\"description\"),\n",
    "                        \"segment_efforts\": json.dumps(activity.get(\"segment_efforts\")) if activity.get(\"segment_efforts\") else None,\n",
    "                        \"splits_metric\": json.dumps(activity.get(\"splits_metric\")) if activity.get(\"splits_metric\") else None,\n",
    "                        \"laps\": json.dumps(activity.get(\"laps\")) if activity.get(\"laps\") else None,\n",
    "                        \"gear\": json.dumps(gear_data) if gear_data else None,\n",
    "                        \"partner_brand_tag\": activity.get(\"partner_brand_tag\"),\n",
    "                        \"photos\": json.dumps(photos_data) if photos_data else None,\n",
    "                        \"highlighted_kudosers\": json.dumps(activity.get(\"highlighted_kudosers\")) if activity.get(\"highlighted_kudosers\") else None,\n",
    "                        \"hide_from_home\": activity.get(\"hide_from_home\"),\n",
    "                        \"device_name\": activity.get(\"device_name\"),\n",
    "                        \"embed_token\": activity.get(\"embed_token\"),\n",
    "                        \"segment_leaderboard_opt_out\": activity.get(\"segment_leaderboard_opt_out\"),\n",
    "                        \"leaderboard_opt_out\": activity.get(\"leaderboard_opt_out\")\n",
    "                    })\n",
    "                \n",
    "                if not data:\n",
    "                    return 0\n",
    "                \n",
    "                cursor.executemany('''\n",
    "                    UPDATE activities SET\n",
    "                        average_temp = :average_temp,\n",
    "                        calories = :calories,\n",
    "                        suffer_score = :suffer_score,\n",
    "                        description = :description,\n",
    "                        segment_efforts = :segment_efforts,\n",
    "                        splits_metric = :splits_metric,\n",
    "                        laps = :laps,\n",
    "                        gear = :gear,\n",
    "                        partner_brand_tag = :partner_brand_tag,\n",
    "                        photos = :photos,\n",
    "                        highlighted_kudosers = :highlighted_kudosers,\n",
    "                        hide_from_home = :hide_from_home,\n",
    "                        device_name = :device_name,\n",
    "                        embed_token = :embed_token,\n",
    "                        segment_leaderboard_opt_out = :segment_leaderboard_opt_out,\n",
    "                        leaderboard_opt_out = :leaderboard_opt_out\n",
    "                    WHERE id = :id\n",
    "                ''', data)\n",
    "                \n",
    "                rows_affected = cursor.rowcount\n",
    "                conn.commit()\n",
    "                return rows_affected\n",
    "                \n",
    "        except sqlite3.Error as e:\n",
    "            logger.error(f\"Database error during activity update: {e}\")\n",
    "            raise\n",
    "    \n",
    "    # Main execution\n",
    "    total_updated = 0\n",
    "    api_calls_used = 0\n",
    "    \n",
    "    try:\n",
    "        if activity_ids:\n",
    "            # If specific IDs provided, we still need to fetch from API\n",
    "            # Strava doesn't support filtering by ID in list activities endpoint\n",
    "            # So we fetch pages until we find all requested IDs\n",
    "            page = 1\n",
    "            found_ids = set()\n",
    "            \n",
    "            while len(found_ids) < len(activity_ids) and api_calls_used < 900:  # Leave buffer\n",
    "                activities = get_activities_page(page=page, per_page=200)\n",
    "                api_calls_used += 1\n",
    "                \n",
    "                if not activities:  # No more activities\n",
    "                    break\n",
    "                    \n",
    "                # Check which requested IDs are in this batch\n",
    "                page_ids = {act.get(\"id\") for act in activities if act.get(\"id\") in activity_ids}\n",
    "                found_ids.update(page_ids)\n",
    "                \n",
    "                if page_ids:  # Only update if we found requested activities\n",
    "                    updated = update_activities_in_db(activities)\n",
    "                    total_updated += updated\n",
    "                    logger.info(f\"Updated {updated} activities from page {page}\")\n",
    "                \n",
    "                page += 1\n",
    "                \n",
    "        else:\n",
    "            # Fetch all activities with pagination\n",
    "            page = 1\n",
    "            while api_calls_used < 900:  # Leave buffer for rate limit\n",
    "                activities = get_activities_page(page=page, per_page=200)\n",
    "                api_calls_used += 1\n",
    "                \n",
    "                if not activities:  # No more activities\n",
    "                    break\n",
    "                    \n",
    "                updated = update_activities_in_db(activities)\n",
    "                total_updated += updated\n",
    "                logger.info(f\"Updated {updated} activities from page {page}\")\n",
    "                \n",
    "                page += 1\n",
    "        \n",
    "        logger.info(f\"Backfill complete. Updated {total_updated} activities using {api_calls_used} API calls\")\n",
    "        return total_updated\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during backfill operation: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "302f2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activities_needing_update(db_path: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Get list of activity IDs that need new field updates.\n",
    "    \n",
    "    Returns:\n",
    "        List of activity IDs missing new field data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Find activities missing new field data (assuming average_temp is a good indicator)\n",
    "            cursor.execute('''\n",
    "                SELECT id FROM activities \n",
    "                WHERE average_temp IS NULL \n",
    "                   OR calories IS NULL \n",
    "                   OR device_name IS NULL\n",
    "                ORDER BY start_date DESC\n",
    "            ''')\n",
    "            \n",
    "            return [row[0] for row in cursor.fetchall()]\n",
    "            \n",
    "    except sqlite3.Error as e:\n",
    "        logger.error(f\"Database error getting activities needing update: {e}\")\n",
    "        raise\n",
    "\n",
    "def prioritized_backfill_strategy(access_token: str, db_path: str, \n",
    "                                 max_api_calls: int = 900) -> int:\n",
    "    \"\"\"\n",
    "    Efficient backfill strategy that prioritizes recent activities.\n",
    "    \n",
    "    Args:\n",
    "        access_token: Valid Strava access token\n",
    "        db_path: Path to the SQLite database\n",
    "        max_api_calls: Maximum API calls to use (default: 900 to leave buffer)\n",
    "        \n",
    "    Returns:\n",
    "        Number of activities successfully updated\n",
    "    \"\"\"\n",
    "    \n",
    "    # Strategy 1: Get activities that definitely need updates\n",
    "    activities_needing_update = get_activities_needing_update(db_path)\n",
    "    \n",
    "    if not activities_needing_update:\n",
    "        logger.info(\"All activities already have new field data\")\n",
    "        return 0\n",
    "    \n",
    "    logger.info(f\"Found {len(activities_needing_update)} activities needing updates\")\n",
    "    \n",
    "    # Strategy 2: Prioritize recent activities (last 6 months)\n",
    "    six_months_ago = datetime.now() - timedelta(days=180)\n",
    "    six_months_timestamp = int(six_months_ago.timestamp())\n",
    "    \n",
    "    # Start with recent activities first\n",
    "    recent_updated = backfill_activities_from_api(\n",
    "        access_token=access_token,\n",
    "        db_path=db_path,\n",
    "        activity_ids=activities_needing_update[:100],  # Limit to manage API calls\n",
    "        after=six_months_timestamp\n",
    "    )\n",
    "    \n",
    "    # Check remaining API call budget\n",
    "    # Estimate: ~4-5 API calls per 200 activities (depends on activity density)\n",
    "    remaining_calls = max_api_calls - (len(activities_needing_update[:100]) // 40)\n",
    "    \n",
    "    if remaining_calls > 50:\n",
    "        # Strategy 3: Fill remaining budget with older activities\n",
    "        older_activities = activities_needing_update[100:]\n",
    "        if older_activities:\n",
    "            older_updated = backfill_activities_from_api(\n",
    "                access_token=access_token,\n",
    "                db_path=db_path,\n",
    "                activity_ids=older_activities[:remaining_calls * 40],  # Rough estimate\n",
    "                before=six_months_timestamp\n",
    "            )\n",
    "            return recent_updated + older_updated\n",
    "    \n",
    "    return recent_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f6cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update only activities missing new data\n",
    "total_updated = prioritized_backfill_strategy(access_token = ACCESS_TOKEN, db_path=Config.DB_PATH, max_api_calls=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = get_activities(access_token=ACCESS_TOKEN, page = 1, per_page= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0bc0f20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'resource_state': 2,\n",
       "  'athlete': {'id': 24266563, 'resource_state': 1},\n",
       "  'name': 'Morning Run',\n",
       "  'distance': 10284.1,\n",
       "  'moving_time': 3089,\n",
       "  'elapsed_time': 3089,\n",
       "  'total_elevation_gain': 35.0,\n",
       "  'type': 'Run',\n",
       "  'sport_type': 'Run',\n",
       "  'workout_type': 0,\n",
       "  'id': 14695490446,\n",
       "  'start_date': '2025-06-04T15:14:08Z',\n",
       "  'start_date_local': '2025-06-04T10:14:08Z',\n",
       "  'timezone': '(GMT-06:00) America/Chicago',\n",
       "  'utc_offset': -18000.0,\n",
       "  'location_city': None,\n",
       "  'location_state': None,\n",
       "  'location_country': None,\n",
       "  'achievement_count': 0,\n",
       "  'kudos_count': 13,\n",
       "  'comment_count': 0,\n",
       "  'athlete_count': 1,\n",
       "  'photo_count': 0,\n",
       "  'map': {'id': 'a14695490446',\n",
       "   'summary_polyline': '{}jqGnuqxPCoCi@uDKaCB}@D]XyA^_AT_@J[VYHCpAT`@Ax@KnBa@VCJCRO^KDIAOSu@SiCA]@MTg@F[Aa@IeA?_@L}@@qBRaCJkGD}FDaBPsBJcCCcAFuBAcARiDHm@Am@GQEEE?GFCJ?LDLR\\\\RRHDJ@JEj@k@VIJAL@VJZZNZBNBjCj@hCN\\\\JAL_@PyA`@cADO?KAKGCGBUZWp@sAfFSfAUx@UbBOvD@lACv@Br@Jl@XrCd@lCb@tBNbBX|AXz@j@x@t@nBn@z@`@z@JRJl@DJPR`An@l@f@`BdB~ArBx@z@dCpBpAz@lAj@jBh@rAZ`@FrBRj@Ll@FlABb@Fp@@h@Fz@Bv@FvAGn@KbAWv@_@pA{@v@Q`AEp@BXFbAj@XTHBFCFYHEJ?p@Tp@\\\\h@Rx@TbAPVAHEf@[RSVg@Ni@\\\\kBLeBAwAWeDJkB?uBIq@WsAC_@?QPaAJiCLo@`@eA`@u@^k@h@m@LYn@uDLaABa@?kBIuAEeC_@sBSgBOw@q@aC}BgFI]Gg@Ow@s@sASQk@UaA_AoA{@cAc@qBm@g@McBUaCK{AEkAM_ACgAOoBG{@?}@Hm@Ca@Ec@@a@DmBZULURc@LUN{@NkBjAoBt@yAhAkA`@uAl@UNm@Ni@Vo@Nm@Tq@NWA_A[YEe@?YDSNg@~@I|@]|@UVY@eAc@k@OEYRQNk@FqAI]OWa@QYEQ@UJUj@IDWBIAGIS}@Oa@Y]KCI@EHALAjACr@QzBObAUjDk@lDIdA[dCQdCShAMfAK^QZIHSPc@Pc@BY?iAQeA?gATg@V_@LIFEJCLOjGLtBL`AH\\\\HJf@`@v@f@HFBHAJGJaA`A{@rAQ~@?^N~@Xz@t@dAnAfADH@NAPO|@ARBfAAv@F^\\\\lARpALZRV',\n",
       "   'resource_state': 2},\n",
       "  'trainer': False,\n",
       "  'commute': False,\n",
       "  'manual': False,\n",
       "  'private': False,\n",
       "  'visibility': 'everyone',\n",
       "  'flagged': False,\n",
       "  'gear_id': 'g17224321',\n",
       "  'start_latlng': [44.949576, -93.324885],\n",
       "  'end_latlng': [44.949493, -93.32496],\n",
       "  'average_speed': 3.329,\n",
       "  'max_speed': 4.7,\n",
       "  'average_cadence': 90.8,\n",
       "  'average_watts': 236.8,\n",
       "  'max_watts': 313,\n",
       "  'weighted_average_watts': 237,\n",
       "  'device_watts': True,\n",
       "  'kilojoules': 731.5,\n",
       "  'has_heartrate': True,\n",
       "  'average_heartrate': 137.2,\n",
       "  'max_heartrate': 155.0,\n",
       "  'heartrate_opt_out': False,\n",
       "  'display_hide_heartrate_option': True,\n",
       "  'elev_high': 275.0,\n",
       "  'elev_low': 265.0,\n",
       "  'upload_id': 15681917963,\n",
       "  'upload_id_str': '15681917963',\n",
       "  'external_id': '469508186766868499.fit',\n",
       "  'from_accepted_tag': False,\n",
       "  'pr_count': 0,\n",
       "  'total_photo_count': 0,\n",
       "  'has_kudoed': False}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf50006",
   "metadata": {},
   "outputs": [],
   "source": [
    "j2 = get_activities(access_token=ACCESS_TOKEN, page = 1, per_page= 1, include_all_efforts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6751cfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'resource_state': 2,\n",
       "  'athlete': {'id': 24266563, 'resource_state': 1},\n",
       "  'name': 'Morning Run',\n",
       "  'distance': 10284.1,\n",
       "  'moving_time': 3089,\n",
       "  'elapsed_time': 3089,\n",
       "  'total_elevation_gain': 35.0,\n",
       "  'type': 'Run',\n",
       "  'sport_type': 'Run',\n",
       "  'workout_type': 0,\n",
       "  'id': 14695490446,\n",
       "  'start_date': '2025-06-04T15:14:08Z',\n",
       "  'start_date_local': '2025-06-04T10:14:08Z',\n",
       "  'timezone': '(GMT-06:00) America/Chicago',\n",
       "  'utc_offset': -18000.0,\n",
       "  'location_city': None,\n",
       "  'location_state': None,\n",
       "  'location_country': None,\n",
       "  'achievement_count': 0,\n",
       "  'kudos_count': 13,\n",
       "  'comment_count': 0,\n",
       "  'athlete_count': 1,\n",
       "  'photo_count': 0,\n",
       "  'map': {'id': 'a14695490446',\n",
       "   'summary_polyline': '{}jqGnuqxPCoCi@uDKaCB}@D]XyA^_AT_@J[VYHCpAT`@Ax@KnBa@VCJCRO^KDIAOSu@SiCA]@MTg@F[Aa@IeA?_@L}@@qBRaCJkGD}FDaBPsBJcCCcAFuBAcARiDHm@Am@GQEEE?GFCJ?LDLR\\\\RRHDJ@JEj@k@VIJAL@VJZZNZBNBjCj@hCN\\\\JAL_@PyA`@cADO?KAKGCGBUZWp@sAfFSfAUx@UbBOvD@lACv@Br@Jl@XrCd@lCb@tBNbBX|AXz@j@x@t@nBn@z@`@z@JRJl@DJPR`An@l@f@`BdB~ArBx@z@dCpBpAz@lAj@jBh@rAZ`@FrBRj@Ll@FlABb@Fp@@h@Fz@Bv@FvAGn@KbAWv@_@pA{@v@Q`AEp@BXFbAj@XTHBFCFYHEJ?p@Tp@\\\\h@Rx@TbAPVAHEf@[RSVg@Ni@\\\\kBLeBAwAWeDJkB?uBIq@WsAC_@?QPaAJiCLo@`@eA`@u@^k@h@m@LYn@uDLaABa@?kBIuAEeC_@sBSgBOw@q@aC}BgFI]Gg@Ow@s@sASQk@UaA_AoA{@cAc@qBm@g@McBUaCK{AEkAM_ACgAOoBG{@?}@Hm@Ca@Ec@@a@DmBZULURc@LUN{@NkBjAoBt@yAhAkA`@uAl@UNm@Ni@Vo@Nm@Tq@NWA_A[YEe@?YDSNg@~@I|@]|@UVY@eAc@k@OEYRQNk@FqAI]OWa@QYEQ@UJUj@IDWBIAGIS}@Oa@Y]KCI@EHALAjACr@QzBObAUjDk@lDIdA[dCQdCShAMfAK^QZIHSPc@Pc@BY?iAQeA?gATg@V_@LIFEJCLOjGLtBL`AH\\\\HJf@`@v@f@HFBHAJGJaA`A{@rAQ~@?^N~@Xz@t@dAnAfADH@NAPO|@ARBfAAv@F^\\\\lARpALZRV',\n",
       "   'resource_state': 2},\n",
       "  'trainer': False,\n",
       "  'commute': False,\n",
       "  'manual': False,\n",
       "  'private': False,\n",
       "  'visibility': 'everyone',\n",
       "  'flagged': False,\n",
       "  'gear_id': 'g17224321',\n",
       "  'start_latlng': [44.949576, -93.324885],\n",
       "  'end_latlng': [44.949493, -93.32496],\n",
       "  'average_speed': 3.329,\n",
       "  'max_speed': 4.7,\n",
       "  'average_cadence': 90.8,\n",
       "  'average_watts': 236.8,\n",
       "  'max_watts': 313,\n",
       "  'weighted_average_watts': 237,\n",
       "  'device_watts': True,\n",
       "  'kilojoules': 731.5,\n",
       "  'has_heartrate': True,\n",
       "  'average_heartrate': 137.2,\n",
       "  'max_heartrate': 155.0,\n",
       "  'heartrate_opt_out': False,\n",
       "  'display_hide_heartrate_option': True,\n",
       "  'elev_high': 275.0,\n",
       "  'elev_low': 265.0,\n",
       "  'upload_id': 15681917963,\n",
       "  'upload_id_str': '15681917963',\n",
       "  'external_id': '469508186766868499.fit',\n",
       "  'from_accepted_tag': False,\n",
       "  'pr_count': 0,\n",
       "  'total_photo_count': 0,\n",
       "  'has_kudoed': False}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2922dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'activities'}, {'name': 'streams'}, {'name': 'gear'}, {'name': 'daily_training_metrics'}, {'name': 'conversations'}, {'name': 'muscle_groups'}, {'name': 'equipment'}, {'name': 'training_goals'}, {'name': 'exercises'}, {'name': 'exercise_muscle_groups'}, {'name': 'exercise_equipment'}, {'name': 'exercise_goals'}, {'name': 'exercise_relationships'}, {'name': 'workout_routines'}, {'name': 'routine_exercises'}, {'name': 'workout_performance'}, {'name': 'exercise_progression'}, {'name': 'muscle_group_fatigue'}]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RunStrong Database Schema Migration and Utilities - CORRECTED & ROBUST (v3)\n",
    "\n",
    "Migrates from a denormalized wide 'exercises' table to a properly normalized schema.\n",
    "This script ensures 100% data integrity by using a map-based strategy to handle\n",
    "duplicate or messy data in the original table, ensuring all historical workout\n",
    "data is correctly re-linked.\n",
    "\n",
    "Corrections implemented in v3:\n",
    "- Re-architected the exercise migration logic to insert exercises one-by-one\n",
    "  and capture their new IDs immediately using cursor.lastrowid.\n",
    "- This completely avoids the issue of a SELECT not seeing data from a pending\n",
    "  INSERT within the same transaction, which was causing the ID map to be empty\n",
    "  and preventing dependent data (workouts, routines) from being migrated.\n",
    "\"\"\"\n",
    "import sqlite3\n",
    "import json\n",
    "import logging\n",
    "import shutil\n",
    "from typing import Dict, List, Set, Any, Optional\n",
    "from contextlib import contextmanager\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Basic Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- Utility Functions ---\n",
    "\n",
    "@contextmanager\n",
    "def db_connection(db_path: str):\n",
    "    \"\"\"Context manager for SQLite connection with foreign keys enabled.\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        conn.execute(\"PRAGMA foreign_keys = ON\")\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        yield conn\n",
    "    except sqlite3.Error as e:\n",
    "        logger.error(f\"Database connection or operation failed: {e}\", exc_info=True)\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        raise\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "def backup_database(db_path: str) -> Optional[str]:\n",
    "    \"\"\"Create a timestamped backup of the database.\"\"\"\n",
    "    if not db_path:\n",
    "        logger.error(\"DB path is not specified. Cannot create backup.\")\n",
    "        return None\n",
    "    try:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        backup_path = f\"{db_path}.backup_{timestamp}\"\n",
    "        shutil.copy2(db_path, backup_path)\n",
    "        logger.info(f\"Database backed up to: {backup_path}\")\n",
    "        return backup_path\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Source database file not found at {db_path}. Cannot create backup.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create backup: {e}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "# --- Migration Class ---\n",
    "\n",
    "class RunStrongMigration:\n",
    "    \"\"\"Handles migration from a denormalized to a normalized schema efficiently and safely.\"\"\"\n",
    "\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self.maps = {\n",
    "            \"old_id_to_new_id\": {},\n",
    "            \"old_name_to_old_id\": {},\n",
    "            \"muscle_name_to_id\": {},\n",
    "            \"equipment_name_to_id\": {},\n",
    "            \"goal_name_to_id\": {},\n",
    "        }\n",
    "\n",
    "    def _create_normalized_schema(self, conn: sqlite3.Connection):\n",
    "        \"\"\"Creates all new tables with a '_new' suffix and CORRECT foreign key constraints.\"\"\"\n",
    "        cursor = conn.cursor()\n",
    "        logger.info(\"Creating new normalized schema...\")\n",
    "        # (Schema creation code is unchanged and correct)\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS muscle_groups (id INTEGER PRIMARY KEY, name TEXT UNIQUE NOT NULL, category TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS equipment (id INTEGER PRIMARY KEY, name TEXT UNIQUE NOT NULL, category TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS training_goals (id INTEGER PRIMARY KEY, name TEXT UNIQUE NOT NULL, description TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS exercises_new (\n",
    "                id INTEGER PRIMARY KEY, name TEXT UNIQUE NOT NULL, description TEXT,\n",
    "                instructions TEXT, unilateral BOOLEAN DEFAULT 0, difficulty_rating TEXT,\n",
    "                rep_range_min INTEGER, rep_range_max INTEGER, tempo TEXT,\n",
    "                compound_vs_isolation TEXT, image_url TEXT, video_url TEXT,\n",
    "                popularity_score INTEGER DEFAULT 0, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        ''')\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS exercise_muscle_groups (exercise_id INTEGER NOT NULL, muscle_group_id INTEGER NOT NULL, is_primary BOOLEAN DEFAULT 1, PRIMARY KEY (exercise_id, muscle_group_id, is_primary), FOREIGN KEY (exercise_id) REFERENCES exercises_new(id) ON DELETE CASCADE, FOREIGN KEY (muscle_group_id) REFERENCES muscle_groups(id) ON DELETE CASCADE)')\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS exercise_equipment (exercise_id INTEGER NOT NULL, equipment_id INTEGER NOT NULL, is_required BOOLEAN DEFAULT 1, PRIMARY KEY (exercise_id, equipment_id, is_required), FOREIGN KEY (exercise_id) REFERENCES exercises_new(id) ON DELETE CASCADE, FOREIGN KEY (equipment_id) REFERENCES equipment(id) ON DELETE CASCADE)')\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS exercise_goals (exercise_id INTEGER NOT NULL, goal_id INTEGER NOT NULL, PRIMARY KEY (exercise_id, goal_id), FOREIGN KEY (exercise_id) REFERENCES exercises_new(id) ON DELETE CASCADE, FOREIGN KEY (goal_id) REFERENCES training_goals(id) ON DELETE CASCADE)')\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS exercise_relationships (from_exercise_id INTEGER NOT NULL, to_exercise_id INTEGER NOT NULL, relationship_type TEXT NOT NULL CHECK(relationship_type IN (\"progression\", \"regression\", \"alternative\", \"superset\")), notes TEXT, UNIQUE (from_exercise_id, to_exercise_id, relationship_type), FOREIGN KEY (from_exercise_id) REFERENCES exercises_new(id) ON DELETE CASCADE, FOREIGN KEY (to_exercise_id) REFERENCES exercises_new(id) ON DELETE CASCADE)')\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS workout_routines_new (id INTEGER PRIMARY KEY, name TEXT, date_created DATE)')\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS routine_exercises_new (id INTEGER PRIMARY KEY, routine_id INTEGER, exercise_id INTEGER, sets INTEGER, reps INTEGER, load_lbs FLOAT, order_index INTEGER, notes TEXT, FOREIGN KEY (routine_id) REFERENCES workout_routines_new(id) ON DELETE CASCADE, FOREIGN KEY (exercise_id) REFERENCES exercises_new(id) ON DELETE CASCADE)')\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS workout_performance_new (id INTEGER PRIMARY KEY, routine_id INTEGER, exercise_id INTEGER, workout_date DATE, planned_sets INTEGER, actual_sets INTEGER, planned_reps INTEGER, actual_reps INTEGER, planned_load_lbs FLOAT, actual_load_lbs FLOAT, notes TEXT, completion_status TEXT, created_at TIMESTAMP, FOREIGN KEY (routine_id) REFERENCES workout_routines_new(id) ON DELETE CASCADE, FOREIGN KEY (exercise_id) REFERENCES exercises_new(id) ON DELETE CASCADE)')\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS exercise_progression_new (id INTEGER PRIMARY KEY, exercise_id INTEGER, current_1rm_estimate FLOAT, volume_trend_30day FLOAT, last_pr_date DATE, progression_rate FLOAT, stall_indicator BOOLEAN, FOREIGN KEY (exercise_id) REFERENCES exercises_new(id) ON DELETE CASCADE)')\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS muscle_group_fatigue_new (id INTEGER PRIMARY KEY, muscle_group_id INTEGER UNIQUE, last_trained_date DATE, volume_7day FLOAT, volume_14day FLOAT, recovery_score FLOAT, updated_at TIMESTAMP, FOREIGN KEY (muscle_group_id) REFERENCES muscle_groups(id) ON DELETE CASCADE)')\n",
    "        logger.info(\"Schema creation complete.\")\n",
    "\n",
    "    def _parse_delimited_field(self, field_value: Optional[str]) -> Set[str]:\n",
    "        \"\"\"Parses a comma-separated or JSON-array string field into a set of clean strings.\"\"\"\n",
    "        # (This helper function is unchanged and correct)\n",
    "        if not field_value: return set()\n",
    "        cleaned_set = set()\n",
    "        try:\n",
    "            if isinstance(field_value, str) and field_value.strip().startswith('['):\n",
    "                data = json.loads(field_value)\n",
    "                if isinstance(data, list): cleaned_set.update(str(item).strip() for item in data if str(item).strip())\n",
    "            else: cleaned_set.update(item.strip() for item in str(field_value).split(',') if item.strip())\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            cleaned_set.update(item.strip() for item in str(field_value).replace('[','').replace(']','').replace('\"','').split(',') if item.strip())\n",
    "        return cleaned_set\n",
    "\n",
    "    def _populate_lookup_tables(self, conn: sqlite3.Connection):\n",
    "        \"\"\"Populates lookup tables and the corresponding name-to-ID maps.\"\"\"\n",
    "        # (This method is unchanged and correct)\n",
    "        logger.info(\"Populating lookup tables (muscles, equipment, goals)...\")\n",
    "        cursor = conn.cursor()\n",
    "        all_muscles, all_equipment, all_goals = set(), set(), set()\n",
    "        cursor.execute(\"SELECT primary_muscles, secondary_muscles, equipment_required, equipment_optional, goals, training_style FROM exercises\")\n",
    "        for row in cursor.fetchall():\n",
    "            all_muscles.update(self._parse_delimited_field(row['primary_muscles']))\n",
    "            all_muscles.update(self._parse_delimited_field(row['secondary_muscles']))\n",
    "            all_equipment.update(self._parse_delimited_field(row['equipment_required']))\n",
    "            all_equipment.update(self._parse_delimited_field(row['equipment_optional']))\n",
    "            all_goals.update(self._parse_delimited_field(row['goals']))\n",
    "            all_goals.update(self._parse_delimited_field(row['training_style']))\n",
    "        if all_muscles: cursor.executemany(\"INSERT OR IGNORE INTO muscle_groups (name) VALUES (?)\", [(m,) for m in sorted(list(all_muscles))])\n",
    "        if all_equipment: cursor.executemany(\"INSERT OR IGNORE INTO equipment (name) VALUES (?)\", [(e,) for e in sorted(list(all_equipment))])\n",
    "        if all_goals: cursor.executemany(\"INSERT OR IGNORE INTO training_goals (name) VALUES (?)\", [(g,) for g in sorted(list(all_goals))])\n",
    "        cursor.execute(\"SELECT id, name FROM muscle_groups\"); self.maps[\"muscle_name_to_id\"] = {row['name']: row['id'] for row in cursor.fetchall()}\n",
    "        cursor.execute(\"SELECT id, name FROM equipment\"); self.maps[\"equipment_name_to_id\"] = {row['name']: row['id'] for row in cursor.fetchall()}\n",
    "        cursor.execute(\"SELECT id, name FROM training_goals\"); self.maps[\"goal_name_to_id\"] = {row['name']: row['id'] for row in cursor.fetchall()}\n",
    "        logger.info(\"Lookup tables and maps populated.\")\n",
    "\n",
    "    def _build_id_map_and_migrate_exercises(self, conn: sqlite3.Connection):\n",
    "        \"\"\"\n",
    "        Robustly migrates exercises by inserting them one-by-one to capture\n",
    "        their new ID, which guarantees the ID map is populated correctly.\n",
    "        \"\"\"\n",
    "        logger.info(\"Analyzing old exercises and migrating them to build ID map...\")\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT * FROM exercises\")\n",
    "        old_exercises = cursor.fetchall()\n",
    "        \n",
    "        if not old_exercises:\n",
    "            logger.warning(\"No exercises found in the old table. Nothing to migrate.\")\n",
    "            return\n",
    "\n",
    "        self.maps[\"old_name_to_old_id\"] = {ex['name']: ex['id'] for ex in old_exercises if 'name' in ex and ex['name']}\n",
    "        \n",
    "        # Determine canonical \"winner\" for each exercise name\n",
    "        cleaned_name_to_ids = defaultdict(list)\n",
    "        for ex in old_exercises:\n",
    "            if 'name' in ex and ex['name']:\n",
    "                cleaned_name = ex['name'].strip().lower()\n",
    "                cleaned_name_to_ids[cleaned_name].append(ex['id'])\n",
    "\n",
    "        canonical_map = {} # Maps every old ID -> winner old ID\n",
    "        for cleaned_name, old_ids in cleaned_name_to_ids.items():\n",
    "            winner_id = min(old_ids)\n",
    "            for old_id in old_ids:\n",
    "                canonical_map[old_id] = winner_id\n",
    "\n",
    "        # --- NEW LOGIC: INSERT 1-BY-1 AND MAP ---\n",
    "        old_winner_id_to_new_id = {}\n",
    "        winner_ids = sorted(list(set(canonical_map.values())))\n",
    "\n",
    "        logger.info(f\"Found {len(winner_ids)} canonical exercises to migrate.\")\n",
    "\n",
    "        for winner_id in winner_ids:\n",
    "            # Find the full row data for the winner\n",
    "            winner_row = next((ex for ex in old_exercises if ex['id'] == winner_id), None)\n",
    "            if not winner_row: continue\n",
    "\n",
    "            # Prepare tuple for insertion\n",
    "            data_tuple = (\n",
    "                winner_row['name'],\n",
    "                winner_row['description'] if 'description' in winner_row else None,\n",
    "                winner_row['instructions'] if 'instructions' in winner_row else None,\n",
    "                winner_row['unilateral'] if 'unilateral' in winner_row and winner_row['unilateral'] is not None else 0,\n",
    "                winner_row['difficulty_rating'] if 'difficulty_rating' in winner_row else None,\n",
    "                winner_row['rep_range_min'] if 'rep_range_min' in winner_row else None,\n",
    "                winner_row['rep_range_max'] if 'rep_range_max' in winner_row else None,\n",
    "                winner_row['tempo'] if 'tempo' in winner_row else None,\n",
    "                winner_row['compound_vs_isolation'] if 'compound_vs_isolation' in winner_row else None,\n",
    "                winner_row['image_url'] if 'image_url' in winner_row else None,\n",
    "                winner_row['video_url'] if 'video_url' in winner_row else None,\n",
    "                winner_row['popularity_score'] if 'popularity_score' in winner_row else 0\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                # Insert the single row\n",
    "                cursor.execute('''\n",
    "                    INSERT INTO exercises_new (name, description, instructions, unilateral, difficulty_rating,\n",
    "                                             rep_range_min, rep_range_max, tempo, compound_vs_isolation,\n",
    "                                             image_url, video_url, popularity_score)\n",
    "                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                ''', data_tuple)\n",
    "                \n",
    "                # Capture the new ID and map it\n",
    "                new_id = cursor.lastrowid\n",
    "                old_winner_id_to_new_id[winner_id] = new_id\n",
    "\n",
    "            except sqlite3.IntegrityError:\n",
    "                logger.warning(f\"Could not insert exercise '{winner_row['name']}' due to UNIQUE constraint. It might be a duplicate under a different old ID. Skipping.\")\n",
    "                # We need to find the new ID of the existing record\n",
    "                cursor.execute(\"SELECT id FROM exercises_new WHERE name = ?\", (winner_row['name'],))\n",
    "                existing_row = cursor.fetchone()\n",
    "                if existing_row:\n",
    "                    old_winner_id_to_new_id[winner_id] = existing_row['id']\n",
    "\n",
    "        # Finally, build the master map for ALL old exercises\n",
    "        for old_ex in old_exercises:\n",
    "            old_id = old_ex['id']\n",
    "            winner_id = canonical_map.get(old_id)\n",
    "            if winner_id:\n",
    "                new_id = old_winner_id_to_new_id.get(winner_id)\n",
    "                if new_id:\n",
    "                    self.maps[\"old_id_to_new_id\"][old_id] = new_id\n",
    "\n",
    "        logger.info(f\"Successfully built ID map for {len(self.maps['old_id_to_new_id'])} old exercises.\")\n",
    "\n",
    "\n",
    "    def _migrate_links_and_relationships(self, conn: sqlite3.Connection):\n",
    "        \"\"\"Migrates all many-to-many links and relationships using the maps.\"\"\"\n",
    "        # (This method is unchanged and correct)\n",
    "        logger.info(\"Migrating exercise links (muscles, equipment, goals, relationships)...\")\n",
    "        cursor = conn.cursor()\n",
    "        muscle_links, equipment_links, goal_links, relationship_links = [], [], [], []\n",
    "        cursor.execute(\"SELECT * FROM exercises\")\n",
    "        for old_ex in cursor.fetchall():\n",
    "            new_id = self.maps[\"old_id_to_new_id\"].get(old_ex['id'])\n",
    "            if not new_id: continue\n",
    "            for muscle in self._parse_delimited_field(old_ex['primary_muscles']):\n",
    "                if self.maps[\"muscle_name_to_id\"].get(muscle): muscle_links.append((new_id, self.maps[\"muscle_name_to_id\"][muscle], 1))\n",
    "            for muscle in self._parse_delimited_field(old_ex['secondary_muscles']):\n",
    "                if self.maps[\"muscle_name_to_id\"].get(muscle): muscle_links.append((new_id, self.maps[\"muscle_name_to_id\"][muscle], 0))\n",
    "            for item in self._parse_delimited_field(old_ex['equipment_required']):\n",
    "                if self.maps[\"equipment_name_to_id\"].get(item): equipment_links.append((new_id, self.maps[\"equipment_name_to_id\"][item], 1))\n",
    "            for goal in self._parse_delimited_field(old_ex['goals']):\n",
    "                if self.maps[\"goal_name_to_id\"].get(goal): goal_links.append((new_id, self.maps[\"goal_name_to_id\"][goal]))\n",
    "            rel_map = {'progressions': 'progression', 'regressions': 'regression', 'alternatives': 'alternative', 'supersets_well_with': 'superset'}\n",
    "            for field, rel_type in rel_map.items():\n",
    "                if field in old_ex and old_ex[field]:\n",
    "                    for related_name in self._parse_delimited_field(old_ex[field]):\n",
    "                        related_old_id = self.maps[\"old_name_to_old_id\"].get(related_name)\n",
    "                        related_new_id = self.maps[\"old_id_to_new_id\"].get(related_old_id) if related_old_id else None\n",
    "                        if related_new_id: relationship_links.append((new_id, related_new_id, rel_type))\n",
    "        if muscle_links: cursor.executemany(\"INSERT OR IGNORE INTO exercise_muscle_groups VALUES (?, ?, ?)\", muscle_links)\n",
    "        if equipment_links: cursor.executemany(\"INSERT OR IGNORE INTO exercise_equipment VALUES (?, ?, ?)\", equipment_links)\n",
    "        if goal_links: cursor.executemany(\"INSERT OR IGNORE INTO exercise_goals VALUES (?, ?)\", goal_links)\n",
    "        if relationship_links: cursor.executemany(\"INSERT OR IGNORE INTO exercise_relationships (from_exercise_id, to_exercise_id, relationship_type) VALUES (?, ?, ?)\", relationship_links)\n",
    "        logger.info(\"Finished migrating links and relationships.\")\n",
    "\n",
    "    def _migrate_dependent_data(self, conn: sqlite3.Connection):\n",
    "        \"\"\"Migrates data from dependent tables, correctly mapping foreign keys.\"\"\"\n",
    "        # (This method is unchanged and correct)\n",
    "        logger.info(\"Migrating dependent tables using the ID map...\")\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"INSERT INTO workout_routines_new (id, name, date_created) SELECT id, name, date_created FROM workout_routines\");\n",
    "        logger.info(\"Migrated workout_routines.\")\n",
    "        cursor.execute(\"SELECT * FROM routine_exercises\")\n",
    "        new_routine_exercises = []\n",
    "        for row in cursor.fetchall():\n",
    "            new_ex_id = self.maps[\"old_id_to_new_id\"].get(row['exercise_id'])\n",
    "            if new_ex_id: new_routine_exercises.append((row['id'], row['routine_id'], new_ex_id, row['sets'], row['reps'], row['load_lbs'], row['order_index'], row['notes']))\n",
    "        cursor.executemany(\"INSERT INTO routine_exercises_new VALUES (?, ?, ?, ?, ?, ?, ?, ?)\", new_routine_exercises)\n",
    "        logger.info(f\"Migrated {len(new_routine_exercises)} records for routine_exercises.\")\n",
    "        cursor.execute(\"SELECT * FROM workout_performance\")\n",
    "        new_performance_data = []\n",
    "        for row in cursor.fetchall():\n",
    "            new_ex_id = self.maps[\"old_id_to_new_id\"].get(row['exercise_id'])\n",
    "            if new_ex_id: new_performance_data.append((row['id'], row['routine_id'], new_ex_id, row['workout_date'], row['planned_sets'], row['actual_sets'], row['planned_reps'], row['actual_reps'], row['planned_load_lbs'], row['actual_load_lbs'], row['notes'], row['completion_status'], row['created_at']))\n",
    "        cursor.executemany(\"INSERT INTO workout_performance_new VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", new_performance_data)\n",
    "        logger.info(f\"Migrated {len(new_performance_data)} records for workout_performance.\")\n",
    "        cursor.execute(\"SELECT * FROM exercise_progression\")\n",
    "        new_progression_data = []\n",
    "        for row in cursor.fetchall():\n",
    "            new_ex_id = self.maps[\"old_id_to_new_id\"].get(row['exercise_id'])\n",
    "            if new_ex_id: new_progression_data.append((row['id'], new_ex_id, row['current_1rm_estimate'], row['volume_trend_30day'], row['last_pr_date'], row['progression_rate'], row['stall_indicator']))\n",
    "        cursor.executemany(\"INSERT INTO exercise_progression_new VALUES (?, ?, ?, ?, ?, ?, ?)\", new_progression_data)\n",
    "        logger.info(f\"Migrated {len(new_progression_data)} records for exercise_progression.\")\n",
    "        cursor.execute(\"SELECT * FROM muscle_group_fatigue\")\n",
    "        new_fatigue_data = []\n",
    "        for row in cursor.fetchall():\n",
    "            muscle_id = self.maps[\"muscle_name_to_id\"].get(row['muscle_group'])\n",
    "            if muscle_id: new_fatigue_data.append((row['id'], muscle_id, row['last_trained_date'], row['volume_7day'], row['volume_14day'], row['recovery_score'], row['updated_at']))\n",
    "        cursor.executemany(\"INSERT OR IGNORE INTO muscle_group_fatigue_new VALUES (?, ?, ?, ?, ?, ?, ?)\", new_fatigue_data)\n",
    "        logger.info(f\"Migrated {len(new_fatigue_data)} records for muscle_group_fatigue.\")\n",
    "\n",
    "    def _finalize_schema(self, conn: sqlite3.Connection):\n",
    "        \"\"\"Drops all old tables and renames new tables to finalize the migration.\"\"\"\n",
    "        # (This method is unchanged and correct)\n",
    "        logger.info(\"Finalizing schema: Dropping old tables and renaming new ones...\")\n",
    "        cursor = conn.cursor()\n",
    "        old_tables = ['exercise_progression', 'muscle_group_fatigue', 'weekly_training_summary', 'workout_performance', 'routine_exercises', 'workout_routines', 'exercises']\n",
    "        for table in old_tables: cursor.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "        new_to_final_map = {'exercises_new': 'exercises', 'workout_routines_new': 'workout_routines', 'routine_exercises_new': 'routine_exercises', 'workout_performance_new': 'workout_performance', 'exercise_progression_new': 'exercise_progression', 'muscle_group_fatigue_new': 'muscle_group_fatigue'}\n",
    "        for new_name, final_name in new_to_final_map.items(): cursor.execute(f\"ALTER TABLE {new_name} RENAME TO {final_name}\")\n",
    "        logger.info(\"Schema finalized successfully.\")\n",
    "\n",
    "    def run_migration(self) -> bool:\n",
    "        \"\"\"Executes the full, transactional migration process.\"\"\"\n",
    "        # (This method is unchanged and correct)\n",
    "        logger.info(\"--- Starting Database Migration Process ---\")\n",
    "        if not backup_database(self.db_path):\n",
    "            logger.error(\"Migration halted due to backup failure.\")\n",
    "            return False\n",
    "        try:\n",
    "            with db_connection(self.db_path) as conn:\n",
    "                try:\n",
    "                    conn.execute(\"BEGIN\")\n",
    "                    self._create_normalized_schema(conn)\n",
    "                    self._populate_lookup_tables(conn)\n",
    "                    self._build_id_map_and_migrate_exercises(conn)\n",
    "                    self._migrate_links_and_relationships(conn)\n",
    "                    self._migrate_dependent_data(conn)\n",
    "                    self._finalize_schema(conn)\n",
    "                    conn.commit()\n",
    "                    logger.info(\"Migration transaction committed successfully!\")\n",
    "                    return True\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Migration failed during transaction: {e}\", exc_info=True)\n",
    "                    conn.rollback()\n",
    "                    logger.critical(\"--- TRANSACTION ROLLED BACK. DATABASE UNCHANGED. ---\")\n",
    "                    return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to connect to the database: {e}\", exc_info=True)\n",
    "            return False\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DB_PATH = 'strava_data.db' \n",
    "    \n",
    "    logger.info(f\"--- Running Migration Script for: {DB_PATH} ---\")\n",
    "    \n",
    "    migration_handler = RunStrongMigration(DB_PATH)\n",
    "    success = migration_handler.run_migration()\n",
    "    \n",
    "    if success:\n",
    "        logger.info(\"--- MIGRATION SUCCEEDED ---\")\n",
    "    else:\n",
    "        logger.error(\"--- MIGRATION FAILED. Please check logs and restore from the created backup if necessary. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
