{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f018bf94",
   "metadata": {},
   "source": [
    "# Strava API Pipeline Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3426fd",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "776f027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sqlite3\n",
    "\n",
    "# Developer Docs\n",
    "# https://developers.strava.com/docs/getting-started/#basic\n",
    "\n",
    "# Streams API Details\n",
    "# https://developers.strava.com/docs/reference/#api-Streams-getActivityStreams\n",
    "\n",
    "# Replace with your actual credentials\n",
    "load_dotenv(dotenv_path=\"secrets.env\")\n",
    "CLIENT_ID = os.environ.get(\"CLIENT_ID\")\n",
    "CLIENT_SECRET = os.environ.get(\"CLIENT_SECRET\")\n",
    "REFRESH_TOKEN = os.environ.get(\"REFRESH_TOKEN\")\n",
    "\n",
    "DB_PATH = 'strava_data.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33d6a5",
   "metadata": {},
   "source": [
    "### Error Troubleshooting\n",
    "\n",
    "HTTP error occurred: 401 Client Error: Unauthorized for url: https://www.strava.com/api/v3/athlete/activities?page=1&per_page=1\n",
    "\n",
    "Go to this link, and note the scopes being used at the end of the URL - \n",
    "https://www.strava.com/oauth/authorize?client_id=64543&response_type=code&redirect_uri=http://localhost/exchange_token&approval_prompt=force&scope=profile:read_all,activity:read_all\n",
    "\n",
    "More details on scope here - https://developers.strava.com/docs/authentication/#detailsaboutrequestingaccess\n",
    "\n",
    "Extract the auth code from the reply URL and assign it using the below cell.\n",
    "\n",
    "Then, run the contents of the Code to Exchange Auth Code for Auth Token section to get a valid AUTH_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75cd832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTH_CODE = \"9c55a7ff2af5050e35c0968aecf9773c80f95080\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fdbaa",
   "metadata": {},
   "source": [
    "## Refresh Auth Token\n",
    "### STill Figuring this one out\n",
    "#### The Auth Code input here should be the code extracted from the blank webpage after a user approves a scope request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1564587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old gemini code don't know if useful or not\n",
    "# This SHOULD work \n",
    "def refresh_access_token(client_id, client_secret, refresh_token):\n",
    "    \"\"\"Refreshes the access token using the refresh token.\"\"\"\n",
    "    response = requests.post(\n",
    "        url=\"https://www.strava.com/oauth/token\",\n",
    "        data={\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"grant_type\": \"refresh_token\",\n",
    "            \"refresh_token\": refresh_token,\n",
    "        },\n",
    "    )\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cd1c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15e491443e6cffa8b9724e70c1ee0c78a5b2913f\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    AUTH_TOKEN = refresh_access_token(CLIENT_ID, CLIENT_SECRET, REFRESH_TOKEN)[\"access_token\"]\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    \n",
    "print(AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a8fed",
   "metadata": {},
   "source": [
    "## Get Auth Token\n",
    "#### The Auth Code input here should be the code extracted from the blank webpage after a user approves a scope request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61610c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth_token(client_id, client_secret, auth_code):\n",
    "    \"\"\"Refreshes the access token using the refresh token.\"\"\"\n",
    "    response = requests.post(\n",
    "        url=\"https://www.strava.com/oauth/token\",\n",
    "        data={\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"grant_type\": \"authorization_code\",\n",
    "            \"code\": auth_code,\n",
    "        },\n",
    "    )\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9cf232",
   "metadata": {},
   "source": [
    "#### Code to Exchange Auth Code for Auth Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ff5a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3ed238ae50aaea249d943cc8c45119b86b262e3\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    AUTH_TOKEN = get_auth_token(CLIENT_ID, CLIENT_SECRET, AUTH_CODE)[\"access_token\"]\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    \n",
    "print(AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb74a0",
   "metadata": {},
   "source": [
    "## Base Functions for retreiving activities and timeseries data from Strava API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc673e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activities(access_token, page=1, per_page=30, **optional_parameters):\n",
    "    \"\"\"Retrieves activities from the Strava API.\n",
    "    Optional parameters should be provided at the end of the call like so:\n",
    "    before = epoch_timestamp, after = epoch_timestamp\n",
    "    \"\"\"\n",
    "    url = f\"https://www.strava.com/api/v3/athlete/activities\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    params = {\"page\": page, \"per_page\": per_page}\n",
    "    params.update(optional_parameters)\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_streams(access_token, keys, activity_id):\n",
    "    \"\"\"Retrieves activities from the Strava API.\"\"\"\n",
    "    url = f\"https://www.strava.com/api/v3/activities/\" + str(activity_id) + \"/streams\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    params = {\"keys\" : keys, \"key_by_type\": True}\n",
    "    # valid keys includes [\"time\", \"distance\", \"latlng\", \"altitude\", \"heartrate\", \"cadence\", \"watts\"]\n",
    "    # https://developers.strava.com/docs/reference/#api-models-StreamSet\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d2c4f",
   "metadata": {},
   "source": [
    "## Base functions for storing data in db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd261b9",
   "metadata": {},
   "source": [
    "#### Initialize Activities Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735ef43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_database():\n",
    "    \"\"\"Create the SQLite database and full 'activities' table.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS activities (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        resource_state INTEGER,\n",
    "        athlete_id INTEGER,\n",
    "        athlete_resource_state INTEGER,\n",
    "        name TEXT,\n",
    "        distance REAL,\n",
    "        moving_time INTEGER,\n",
    "        elapsed_time INTEGER,\n",
    "        total_elevation_gain REAL,\n",
    "        type TEXT,\n",
    "        sport_type TEXT,\n",
    "        workout_type INTEGER,\n",
    "        start_date TEXT,\n",
    "        start_date_local TEXT,\n",
    "        timezone TEXT,\n",
    "        utc_offset REAL,\n",
    "        location_city TEXT,\n",
    "        location_state TEXT,\n",
    "        location_country TEXT,\n",
    "        achievement_count INTEGER,\n",
    "        kudos_count INTEGER,\n",
    "        comment_count INTEGER,\n",
    "        athlete_count INTEGER,\n",
    "        photo_count INTEGER,\n",
    "        map_id TEXT,\n",
    "        map_summary_polyline TEXT,\n",
    "        map_resource_state INTEGER,\n",
    "        trainer BOOLEAN,\n",
    "        commute BOOLEAN,\n",
    "        manual BOOLEAN,\n",
    "        private BOOLEAN,\n",
    "        visibility TEXT,\n",
    "        flagged BOOLEAN,\n",
    "        gear_id TEXT,\n",
    "        start_latlng TEXT,\n",
    "        end_latlng TEXT,\n",
    "        average_speed REAL,\n",
    "        max_speed REAL,\n",
    "        average_cadence REAL,\n",
    "        average_watts REAL,\n",
    "        max_watts INTEGER,\n",
    "        weighted_average_watts INTEGER,\n",
    "        device_watts BOOLEAN,\n",
    "        kilojoules REAL,\n",
    "        has_heartrate BOOLEAN,\n",
    "        average_heartrate REAL,\n",
    "        max_heartrate REAL,\n",
    "        heartrate_opt_out BOOLEAN,\n",
    "        display_hide_heartrate_option BOOLEAN,\n",
    "        elev_high REAL,\n",
    "        elev_low REAL,\n",
    "        upload_id INTEGER,\n",
    "        upload_id_str TEXT,\n",
    "        external_id TEXT,\n",
    "        from_accepted_tag BOOLEAN,\n",
    "        pr_count INTEGER,\n",
    "        total_photo_count INTEGER,\n",
    "        has_kudoed BOOLEAN,\n",
    "        import_date TEXT\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b2ad04",
   "metadata": {},
   "source": [
    "#### Activities Individual DB Entry Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf442b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def insert_activities(activity_list):\n",
    "    \"\"\"Insert activity records, skipping those with duplicate 'id'.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    for activity in activity_list:\n",
    "        try:\n",
    "            c.execute('''\n",
    "            INSERT INTO activities VALUES (\n",
    "                :id, :resource_state, \n",
    "                :athlete_id, :athlete_resource_state,\n",
    "                :name, :distance, :moving_time, :elapsed_time, :total_elevation_gain,\n",
    "                :type, :sport_type, :workout_type, :start_date, :start_date_local,\n",
    "                :timezone, :utc_offset, :location_city, :location_state, :location_country,\n",
    "                :achievement_count, :kudos_count, :comment_count, :athlete_count, :photo_count,\n",
    "                :map_id, :map_summary_polyline, :map_resource_state,\n",
    "                :trainer, :commute, :manual, :private, :visibility, :flagged, :gear_id,\n",
    "                :start_latlng, :end_latlng,\n",
    "                :average_speed, :max_speed, :average_cadence, :average_watts,\n",
    "                :max_watts, :weighted_average_watts, :device_watts, :kilojoules,\n",
    "                :has_heartrate, :average_heartrate, :max_heartrate,\n",
    "                :heartrate_opt_out, :display_hide_heartrate_option,\n",
    "                :elev_high, :elev_low,\n",
    "                :upload_id, :upload_id_str, :external_id, :from_accepted_tag,\n",
    "                :pr_count, :total_photo_count, :has_kudoed, :import_date\n",
    "            )\n",
    "            ''', {\n",
    "                \"id\": activity[\"id\"],\n",
    "                \"resource_state\": activity.get(\"resource_state\"),\n",
    "                \"athlete_id\": activity.get(\"athlete\", {}).get(\"id\"),\n",
    "                \"athlete_resource_state\": activity.get(\"athlete\", {}).get(\"resource_state\"),\n",
    "                \"name\": activity.get(\"name\"),\n",
    "                \"distance\": activity.get(\"distance\"),\n",
    "                \"moving_time\": activity.get(\"moving_time\"),\n",
    "                \"elapsed_time\": activity.get(\"elapsed_time\"),\n",
    "                \"total_elevation_gain\": activity.get(\"total_elevation_gain\"),\n",
    "                \"type\": activity.get(\"type\"),\n",
    "                \"sport_type\": activity.get(\"sport_type\"),\n",
    "                \"workout_type\": activity.get(\"workout_type\"),\n",
    "                \"start_date\": activity.get(\"start_date\"),\n",
    "                \"start_date_local\": activity.get(\"start_date_local\"),\n",
    "                \"timezone\": activity.get(\"timezone\"),\n",
    "                \"utc_offset\": activity.get(\"utc_offset\"),\n",
    "                \"location_city\": activity.get(\"location_city\"),\n",
    "                \"location_state\": activity.get(\"location_state\"),\n",
    "                \"location_country\": activity.get(\"location_country\"),\n",
    "                \"achievement_count\": activity.get(\"achievement_count\"),\n",
    "                \"kudos_count\": activity.get(\"kudos_count\"),\n",
    "                \"comment_count\": activity.get(\"comment_count\"),\n",
    "                \"athlete_count\": activity.get(\"athlete_count\"),\n",
    "                \"photo_count\": activity.get(\"photo_count\"),\n",
    "                \"map_id\": activity.get(\"map\", {}).get(\"id\"),\n",
    "                \"map_summary_polyline\": activity.get(\"map\", {}).get(\"summary_polyline\"),\n",
    "                \"map_resource_state\": activity.get(\"map\", {}).get(\"resource_state\"),\n",
    "                \"trainer\": activity.get(\"trainer\"),\n",
    "                \"commute\": activity.get(\"commute\"),\n",
    "                \"manual\": activity.get(\"manual\"),\n",
    "                \"private\": activity.get(\"private\"),\n",
    "                \"visibility\": activity.get(\"visibility\"),\n",
    "                \"flagged\": activity.get(\"flagged\"),\n",
    "                \"gear_id\": activity.get(\"gear_id\"),\n",
    "                \"start_latlng\": json.dumps(activity.get(\"start_latlng\")),\n",
    "                \"end_latlng\": json.dumps(activity.get(\"end_latlng\")),\n",
    "                \"average_speed\": activity.get(\"average_speed\"),\n",
    "                \"max_speed\": activity.get(\"max_speed\"),\n",
    "                \"average_cadence\": activity.get(\"average_cadence\"),\n",
    "                \"average_watts\": activity.get(\"average_watts\"),\n",
    "                \"max_watts\": activity.get(\"max_watts\"),\n",
    "                \"weighted_average_watts\": activity.get(\"weighted_average_watts\"),\n",
    "                \"device_watts\": activity.get(\"device_watts\"),\n",
    "                \"kilojoules\": activity.get(\"kilojoules\"),\n",
    "                \"has_heartrate\": activity.get(\"has_heartrate\"),\n",
    "                \"average_heartrate\": activity.get(\"average_heartrate\"),\n",
    "                \"max_heartrate\": activity.get(\"max_heartrate\"),\n",
    "                \"heartrate_opt_out\": activity.get(\"heartrate_opt_out\"),\n",
    "                \"display_hide_heartrate_option\": activity.get(\"display_hide_heartrate_option\"),\n",
    "                \"elev_high\": activity.get(\"elev_high\"),\n",
    "                \"elev_low\": activity.get(\"elev_low\"),\n",
    "                \"upload_id\": activity.get(\"upload_id\"),\n",
    "                \"upload_id_str\": activity.get(\"upload_id_str\"),\n",
    "                \"external_id\": activity.get(\"external_id\"),\n",
    "                \"from_accepted_tag\": activity.get(\"from_accepted_tag\"),\n",
    "                \"pr_count\": activity.get(\"pr_count\"),\n",
    "                \"total_photo_count\": activity.get(\"total_photo_count\"),\n",
    "                \"has_kudoed\": activity.get(\"has_kudoed\"),\n",
    "                \"import_date\": datetime.now().isoformat()\n",
    "            })\n",
    "        except sqlite3.IntegrityError:\n",
    "            print(f\"Skipping duplicate activity with id {activity['id']}\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb127101",
   "metadata": {},
   "source": [
    "#### Activities Batch Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2732bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_activities_batch(activity_list):\n",
    "    \"\"\"Efficiently insert multiple activity records into the database.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    data = []\n",
    "    for activity in activity_list:\n",
    "        data.append({\n",
    "            \"id\": activity[\"id\"],\n",
    "            \"resource_state\": activity.get(\"resource_state\"),\n",
    "            \"athlete_id\": activity.get(\"athlete\", {}).get(\"id\"),\n",
    "            \"athlete_resource_state\": activity.get(\"athlete\", {}).get(\"resource_state\"),\n",
    "            \"name\": activity.get(\"name\"),\n",
    "            \"distance\": activity.get(\"distance\"),\n",
    "            \"moving_time\": activity.get(\"moving_time\"),\n",
    "            \"elapsed_time\": activity.get(\"elapsed_time\"),\n",
    "            \"total_elevation_gain\": activity.get(\"total_elevation_gain\"),\n",
    "            \"type\": activity.get(\"type\"),\n",
    "            \"sport_type\": activity.get(\"sport_type\"),\n",
    "            \"workout_type\": activity.get(\"workout_type\"),\n",
    "            \"start_date\": activity.get(\"start_date\"),\n",
    "            \"start_date_local\": activity.get(\"start_date_local\"),\n",
    "            \"timezone\": activity.get(\"timezone\"),\n",
    "            \"utc_offset\": activity.get(\"utc_offset\"),\n",
    "            \"location_city\": activity.get(\"location_city\"),\n",
    "            \"location_state\": activity.get(\"location_state\"),\n",
    "            \"location_country\": activity.get(\"location_country\"),\n",
    "            \"achievement_count\": activity.get(\"achievement_count\"),\n",
    "            \"kudos_count\": activity.get(\"kudos_count\"),\n",
    "            \"comment_count\": activity.get(\"comment_count\"),\n",
    "            \"athlete_count\": activity.get(\"athlete_count\"),\n",
    "            \"photo_count\": activity.get(\"photo_count\"),\n",
    "            \"map_id\": activity.get(\"map\", {}).get(\"id\"),\n",
    "            \"map_summary_polyline\": activity.get(\"map\", {}).get(\"summary_polyline\"),\n",
    "            \"map_resource_state\": activity.get(\"map\", {}).get(\"resource_state\"),\n",
    "            \"trainer\": activity.get(\"trainer\"),\n",
    "            \"commute\": activity.get(\"commute\"),\n",
    "            \"manual\": activity.get(\"manual\"),\n",
    "            \"private\": activity.get(\"private\"),\n",
    "            \"visibility\": activity.get(\"visibility\"),\n",
    "            \"flagged\": activity.get(\"flagged\"),\n",
    "            \"gear_id\": activity.get(\"gear_id\"),\n",
    "            \"start_latlng\": json.dumps(activity.get(\"start_latlng\")),\n",
    "            \"end_latlng\": json.dumps(activity.get(\"end_latlng\")),\n",
    "            \"average_speed\": activity.get(\"average_speed\"),\n",
    "            \"max_speed\": activity.get(\"max_speed\"),\n",
    "            \"average_cadence\": activity.get(\"average_cadence\"),\n",
    "            \"average_watts\": activity.get(\"average_watts\"),\n",
    "            \"max_watts\": activity.get(\"max_watts\"),\n",
    "            \"weighted_average_watts\": activity.get(\"weighted_average_watts\"),\n",
    "            \"device_watts\": activity.get(\"device_watts\"),\n",
    "            \"kilojoules\": activity.get(\"kilojoules\"),\n",
    "            \"has_heartrate\": activity.get(\"has_heartrate\"),\n",
    "            \"average_heartrate\": activity.get(\"average_heartrate\"),\n",
    "            \"max_heartrate\": activity.get(\"max_heartrate\"),\n",
    "            \"heartrate_opt_out\": activity.get(\"heartrate_opt_out\"),\n",
    "            \"display_hide_heartrate_option\": activity.get(\"display_hide_heartrate_option\"),\n",
    "            \"elev_high\": activity.get(\"elev_high\"),\n",
    "            \"elev_low\": activity.get(\"elev_low\"),\n",
    "            \"upload_id\": activity.get(\"upload_id\"),\n",
    "            \"upload_id_str\": activity.get(\"upload_id_str\"),\n",
    "            \"external_id\": activity.get(\"external_id\"),\n",
    "            \"from_accepted_tag\": activity.get(\"from_accepted_tag\"),\n",
    "            \"pr_count\": activity.get(\"pr_count\"),\n",
    "            \"total_photo_count\": activity.get(\"total_photo_count\"),\n",
    "            \"has_kudoed\": activity.get(\"has_kudoed\"),\n",
    "            \"import_date\": datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "    try:\n",
    "        c.executemany('''\n",
    "        INSERT OR IGNORE INTO activities VALUES (\n",
    "            :id, :resource_state, :athlete_id, :athlete_resource_state,\n",
    "            :name, :distance, :moving_time, :elapsed_time, :total_elevation_gain,\n",
    "            :type, :sport_type, :workout_type, :start_date, :start_date_local,\n",
    "            :timezone, :utc_offset, :location_city, :location_state, :location_country,\n",
    "            :achievement_count, :kudos_count, :comment_count, :athlete_count, :photo_count,\n",
    "            :map_id, :map_summary_polyline, :map_resource_state,\n",
    "            :trainer, :commute, :manual, :private, :visibility, :flagged, :gear_id,\n",
    "            :start_latlng, :end_latlng,\n",
    "            :average_speed, :max_speed, :average_cadence, :average_watts,\n",
    "            :max_watts, :weighted_average_watts, :device_watts, :kilojoules,\n",
    "            :has_heartrate, :average_heartrate, :max_heartrate,\n",
    "            :heartrate_opt_out, :display_hide_heartrate_option,\n",
    "            :elev_high, :elev_low,\n",
    "            :upload_id, :upload_id_str, :external_id, :from_accepted_tag,\n",
    "            :pr_count, :total_photo_count, :has_kudoed, :import_date\n",
    "        )\n",
    "        ''', data)\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error inserting batch:\", e)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c38a58a",
   "metadata": {},
   "source": [
    "#### Function to Rebuild single activity from flattened version in db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b79298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_by_id(activity_id):\n",
    "    \"\"\"Retrieve a single activity and reconstruct its nested format.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\"SELECT * FROM activities WHERE id = ?\", (activity_id,))\n",
    "    row = c.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if row is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"id\": row[\"id\"],\n",
    "        \"resource_state\": row[\"resource_state\"],\n",
    "        \"athlete\": {\n",
    "            \"id\": row[\"athlete_id\"],\n",
    "            \"resource_state\": row[\"athlete_resource_state\"]\n",
    "        },\n",
    "        \"name\": row[\"name\"],\n",
    "        \"distance\": row[\"distance\"],\n",
    "        \"moving_time\": row[\"moving_time\"],\n",
    "        \"elapsed_time\": row[\"elapsed_time\"],\n",
    "        \"total_elevation_gain\": row[\"total_elevation_gain\"],\n",
    "        \"type\": row[\"type\"],\n",
    "        \"sport_type\": row[\"sport_type\"],\n",
    "        \"workout_type\": row[\"workout_type\"],\n",
    "        \"start_date\": row[\"start_date\"],\n",
    "        \"start_date_local\": row[\"start_date_local\"],\n",
    "        \"timezone\": row[\"timezone\"],\n",
    "        \"utc_offset\": row[\"utc_offset\"],\n",
    "        \"location_city\": row[\"location_city\"],\n",
    "        \"location_state\": row[\"location_state\"],\n",
    "        \"location_country\": row[\"location_country\"],\n",
    "        \"achievement_count\": row[\"achievement_count\"],\n",
    "        \"kudos_count\": row[\"kudos_count\"],\n",
    "        \"comment_count\": row[\"comment_count\"],\n",
    "        \"athlete_count\": row[\"athlete_count\"],\n",
    "        \"photo_count\": row[\"photo_count\"],\n",
    "        \"map\": {\n",
    "            \"id\": row[\"map_id\"],\n",
    "            \"summary_polyline\": row[\"map_summary_polyline\"],\n",
    "            \"resource_state\": row[\"map_resource_state\"]\n",
    "        },\n",
    "        \"trainer\": bool(row[\"trainer\"]),\n",
    "        \"commute\": bool(row[\"commute\"]),\n",
    "        \"manual\": bool(row[\"manual\"]),\n",
    "        \"private\": bool(row[\"private\"]),\n",
    "        \"visibility\": row[\"visibility\"],\n",
    "        \"flagged\": bool(row[\"flagged\"]),\n",
    "        \"gear_id\": row[\"gear_id\"],\n",
    "        \"start_latlng\": json.loads(row[\"start_latlng\"]),\n",
    "        \"end_latlng\": json.loads(row[\"end_latlng\"]),\n",
    "        \"average_speed\": row[\"average_speed\"],\n",
    "        \"max_speed\": row[\"max_speed\"],\n",
    "        \"average_cadence\": row[\"average_cadence\"],\n",
    "        \"average_watts\": row[\"average_watts\"],\n",
    "        \"max_watts\": row[\"max_watts\"],\n",
    "        \"weighted_average_watts\": row[\"weighted_average_watts\"],\n",
    "        \"device_watts\": bool(row[\"device_watts\"]),\n",
    "        \"kilojoules\": row[\"kilojoules\"],\n",
    "        \"has_heartrate\": bool(row[\"has_heartrate\"]),\n",
    "        \"average_heartrate\": row[\"average_heartrate\"],\n",
    "        \"max_heartrate\": row[\"max_heartrate\"],\n",
    "        \"heartrate_opt_out\": bool(row[\"heartrate_opt_out\"]),\n",
    "        \"display_hide_heartrate_option\": bool(row[\"display_hide_heartrate_option\"]),\n",
    "        \"elev_high\": row[\"elev_high\"],\n",
    "        \"elev_low\": row[\"elev_low\"],\n",
    "        \"upload_id\": row[\"upload_id\"],\n",
    "        \"upload_id_str\": row[\"upload_id_str\"],\n",
    "        \"external_id\": row[\"external_id\"],\n",
    "        \"from_accepted_tag\": bool(row[\"from_accepted_tag\"]),\n",
    "        \"pr_count\": row[\"pr_count\"],\n",
    "        \"total_photo_count\": row[\"total_photo_count\"],\n",
    "        \"has_kudoed\": bool(row[\"has_kudoed\"])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca75d58",
   "metadata": {},
   "source": [
    "#### Simple Query to get records loaded during current day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c64ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_activities_imported_today(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM activities \n",
    "        WHERE substr(import_date, 1, 10) = ?\n",
    "    \"\"\", (today_str,))\n",
    "    \n",
    "    count = c.fetchone()[0]\n",
    "    conn.close()\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9807a38d",
   "metadata": {},
   "source": [
    "#### Simple Query to Latest record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ff92056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_activity_imported(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT * \n",
    "        FROM activities \n",
    "        WHERE import_date = \n",
    "        (select max(import_date) from activities)\n",
    "    \"\"\")\n",
    "    \n",
    "    record = c.fetchone()\n",
    "    conn.close()\n",
    "    return record\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d36ce",
   "metadata": {},
   "source": [
    "#### Simple Query to Get Specific record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fee55d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_data_all(db_path, activity_id):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Run query and load into DataFrame (with column headers)\n",
    "    df = pd.read_sql_query(\n",
    "        \"SELECT * FROM activities WHERE id = ?\",\n",
    "        conn,\n",
    "        params=(activity_id,)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d568f71",
   "metadata": {},
   "source": [
    "#### Simple Query to get all Activity IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13e15b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_activity_ids(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT id\n",
    "        FROM activities \n",
    "        order by start_date desc\n",
    "              \"\"\")\n",
    "    \n",
    "    count = c.fetchall()\n",
    "    conn.close()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa82278",
   "metadata": {},
   "source": [
    "#### Simple Query to get all Activity IDs with HR and presumably Streams data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "633dd597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_activity_ids_with_HR(db_path):\n",
    "    \"\"\"Get all activity ids that have HR data, which hopefully will help us avoid a 404 call on the streams data.\n",
    "    My thinking is that if no HR data, we probably have no streams data at all.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT id\n",
    "        FROM activities \n",
    "        WHERE has_heartrate = 1\n",
    "        order by start_date desc\n",
    "              \"\"\")\n",
    "    \n",
    "    count = c.fetchall()\n",
    "    conn.close()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b6bcb",
   "metadata": {},
   "source": [
    "## Database Streams Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830ece9",
   "metadata": {},
   "source": [
    "#### Initialize DB  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b271fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_streams_db():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS streams (\n",
    "        activity_id INTEGER PRIMARY KEY,\n",
    "        \n",
    "        time_data TEXT,\n",
    "        time_series_type TEXT,\n",
    "        time_original_size INTEGER,\n",
    "        time_resolution TEXT,\n",
    "\n",
    "        distance_data TEXT,\n",
    "        distance_series_type TEXT,\n",
    "        distance_original_size INTEGER,\n",
    "        distance_resolution TEXT,\n",
    "\n",
    "        latlng_data TEXT,\n",
    "        latlng_series_type TEXT,\n",
    "        latlng_original_size INTEGER,\n",
    "        latlng_resolution TEXT,\n",
    "\n",
    "        altitude_data TEXT,\n",
    "        altitude_series_type TEXT,\n",
    "        altitude_original_size INTEGER,\n",
    "        altitude_resolution TEXT,\n",
    "\n",
    "        velocity_smooth_data TEXT,\n",
    "        velocity_smooth_series_type TEXT,\n",
    "        velocity_smooth_original_size INTEGER,\n",
    "        velocity_smooth_resolution TEXT,\n",
    "\n",
    "        heartrate_data TEXT,\n",
    "        heartrate_series_type TEXT,\n",
    "        heartrate_original_size INTEGER,\n",
    "        heartrate_resolution TEXT,\n",
    "\n",
    "        cadence_data TEXT,\n",
    "        cadence_series_type TEXT,\n",
    "        cadence_original_size INTEGER,\n",
    "        cadence_resolution TEXT,\n",
    "\n",
    "        watts_data TEXT,\n",
    "        watts_series_type TEXT,\n",
    "        watts_original_size INTEGER,\n",
    "        watts_resolution TEXT,\n",
    "\n",
    "        moving_data TEXT,\n",
    "        moving_series_type TEXT,\n",
    "        moving_original_size INTEGER,\n",
    "        moving_resolution TEXT,\n",
    "\n",
    "        grade_smooth_data TEXT,\n",
    "        grade_smooth_series_type TEXT,\n",
    "        grade_smooth_original_size INTEGER,\n",
    "        grade_smooth_resolution TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3edeb1",
   "metadata": {},
   "source": [
    "#### Insert Stream Data for Single Activity ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc06439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_stream_data(activity_id, stream_dict):\n",
    "    \"\"\"\n",
    "    Inserts or replaces a row in the streams table for a given activity_id.\n",
    "    stream_dict should have keys like 'time', 'distance', etc., with each value a dict containing:\n",
    "    {\n",
    "        'data': [...],\n",
    "        'series_type': '...',\n",
    "        'original_size': ...,\n",
    "        'resolution': '...'\n",
    "    }\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Create the column mappings dynamically\n",
    "    base_columns = []\n",
    "    placeholders = []\n",
    "    values = []\n",
    "\n",
    "    # Always include activity_id\n",
    "    base_columns.append(\"activity_id\")\n",
    "    placeholders.append(\"?\")\n",
    "    values.append(activity_id)\n",
    "\n",
    "    for key, val in stream_dict.items():\n",
    "        if not isinstance(val, dict):\n",
    "            continue  # skip malformed\n",
    "\n",
    "        base_columns.extend([\n",
    "            f\"{key}_data\",\n",
    "            f\"{key}_series_type\",\n",
    "            f\"{key}_original_size\",\n",
    "            f\"{key}_resolution\"\n",
    "        ])\n",
    "        placeholders.extend([\"?\"] * 4)\n",
    "\n",
    "        values.extend([\n",
    "            json.dumps(val.get(\"data\")),\n",
    "            val.get(\"series_type\"),\n",
    "            val.get(\"original_size\"),\n",
    "            val.get(\"resolution\")\n",
    "        ])\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        INSERT INTO streams ({', '.join(base_columns)})\n",
    "        VALUES ({', '.join(placeholders)})\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    try:\n",
    "        c.execute(sql, values)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    except sqlite3.IntegrityError:\n",
    "        print(f\"Activity {activity_id} already exists in the 'streams' table. Skipping insert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2685191d",
   "metadata": {},
   "source": [
    "#### Simple Query to Get all activity IDs from Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5fe5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_activity_ids_streams(db_path):\n",
    "    \"\"\"Count how many activities were imported today based on the full ISO 8601 import_date timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    today_str = date.today().isoformat()  # 'YYYY-MM-DD'\n",
    "\n",
    "    # Use substr to extract the date portion (first 10 characters)\n",
    "    c.execute(\"\"\"\n",
    "        SELECT activity_id\n",
    "        FROM streams \n",
    "              \"\"\")\n",
    "    \n",
    "    count = c.fetchall()\n",
    "    conn.close()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35414d6c",
   "metadata": {},
   "source": [
    "## Get Latest Activity and Associated Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7d71f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity ID: 14404286770, Name: Morning Run, Type: Run\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    activities = []\n",
    "    streams = []\n",
    "    page = 1\n",
    "    per_page = 1\n",
    "    while True:\n",
    "        activities_page = get_activities(AUTH_TOKEN, page=page, per_page=per_page)\n",
    "        if not activities_page:\n",
    "            break\n",
    "        activities.extend(activities_page)\n",
    "        page += 1\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "        break\n",
    "\n",
    "    # Process the activity data\n",
    "    for activity in activities:\n",
    "        print(f\"Activity ID: {activity['id']}, Name: {activity['name']}, Type: {activity['type']}\")\n",
    "\n",
    "    keys = [\"time\", \"distance\", \"latlng\", \"altitude\", \"heartrate\", \"cadence\", \"watts\"]\n",
    "    keys = \"time, latlng\"\n",
    "    # Process stream data\n",
    "    for a in activities:\n",
    "        stream = get_streams(AUTH_TOKEN, keys, a['id'])\n",
    "        if not stream:\n",
    "            break\n",
    "        streams.extend(stream)\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "        break\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b705f",
   "metadata": {},
   "source": [
    "## Bulk Historical Processing of Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1f83cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting point, build unix timestamps in 6 month batches\n",
    "\n",
    "# time_0 = time.mktime(datetime.datetime(2019, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_1 = time.mktime(datetime.datetime(2019, 7, 1, 0, 0, 0).timetuple()) \n",
    "# time_2 = time.mktime(datetime.datetime(2020, 1, 1, 0, 0, 0).timetuple()) \n",
    "# time_3 = time.mktime(datetime.datetime(2020, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_4 = time.mktime(datetime.datetime(2021, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_5 = time.mktime(datetime.datetime(2021, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_6 = time.mktime(datetime.datetime(2022, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_7 = time.mktime(datetime.datetime(2022, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_8 = time.mktime(datetime.datetime(2023, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_9 = time.mktime(datetime.datetime(2023, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_10 = time.mktime(datetime.datetime(2024, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_11 = time.mktime(datetime.datetime(2024, 7, 1, 0, 0, 0).timetuple())\n",
    "# time_12 = time.mktime(datetime.datetime(2025, 1, 1, 0, 0, 0).timetuple())\n",
    "# time_13 = time.mktime(datetime.datetime(2025, 7, 1, 0, 0, 0).timetuple())\n",
    "\n",
    "day_by_day_before = time.mktime(datetime(2025, 5, 10, 0, 0, 0).timetuple())\n",
    "day_by_day_after = time.mktime(datetime(2025, 5, 7, 0, 0, 0).timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3248bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4 activities were imported so far.\n",
      "4 activities were imported so far today\n",
      "5 activities were imported from the API this round.\n"
     ]
    }
   ],
   "source": [
    "# ensure db table exists\n",
    "initialize_database()\n",
    "\n",
    "# Get the data\n",
    "try:\n",
    "    activities = []\n",
    "    page = 1\n",
    "    per_page = 30\n",
    "    while True:\n",
    "        activities_page = get_activities(AUTH_TOKEN, page=page, per_page=per_page, before = day_by_day_before, after = day_by_day_after) # currently done, latest after time was time_12\n",
    "        if not activities_page:\n",
    "            break\n",
    "        print(len(activities_page)) # expect 30 each time unless final page\n",
    "        activities.extend(activities_page)\n",
    "        \n",
    "        insert_activities_batch(activities_page) # attempt to bulk write to db\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "\n",
    "        num_today = count_activities_imported_today(DB_PATH) # count objects in db now\n",
    "        print(f\"{num_today} activities were imported so far.\")\n",
    "\n",
    "        page += 1\n",
    "        time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "        if page > 50:\n",
    "            break\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "num_today = count_activities_imported_today(DB_PATH)\n",
    "print(f\"{num_today} activities were imported so far today\")\n",
    "print(f\"{len(activities)} activities were imported from the API this round.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17807bb1",
   "metadata": {},
   "source": [
    "## Bulk Historical Processing of Data Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46f95e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DB\n",
    "initialize_streams_db()\n",
    "\n",
    "# get all stream activity IDs\n",
    "stream_activity_ids = get_all_activity_ids_streams(\"strava_data.db\")\n",
    "stream_activity_ids = set(i[0] for i in stream_activity_ids)\n",
    "\n",
    "# get all activity ID's in db sorted by activity date desc as set\n",
    "sorted_activity_list = get_all_activity_ids_with_HR(\"strava_data.db\")\n",
    "sorted_activity_list = set(i[0] for i in sorted_activity_list)\n",
    "\n",
    "# Take the \n",
    "valid_activity_ids = tuple(sorted_activity_list - stream_activity_ids)\n",
    "\n",
    "keys = \"time,distance,latlng,altitude,velocity_smooth,heartrate,cadence,watts,temp,moving,grade_smooth\"\n",
    "\n",
    "for i, activity_integer in enumerate(valid_activity_ids):\n",
    "    \n",
    "    try:\n",
    "        stream = get_streams(AUTH_TOKEN, keys, activity_integer)\n",
    "        if not stream:\n",
    "            print('no stream')\n",
    "            continue\n",
    "    \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error occurred: {e}\")\n",
    "        if \"429\" in str(e):\n",
    "            print(\"RATE LIMITED!!!\")\n",
    "            break\n",
    "        if \"404\" in str(e):\n",
    "            print(\"Stream data unavailable for activity\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "    insert_stream_data(activity_integer, stream)\n",
    "    time.sleep(1)  # Respect rate limits, adjust if needed\n",
    "    if i > 25:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7b90233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305 streams in the db.\n",
      "2745 valid activities with potential streams data exist in the db.\n",
      "2440 to go!\n"
     ]
    }
   ],
   "source": [
    "num_today = count_activities_imported_today(DB_PATH)\n",
    "print(f\"{len(get_all_activity_ids_streams(\"strava_data.db\"))} streams in the db.\")\n",
    "print(f\"{len(get_all_activity_ids_with_HR(\"strava_data.db\"))} valid activities with potential streams data exist in the db.\")\n",
    "print(f\"{len(get_all_activity_ids_with_HR(\"strava_data.db\")) - len(get_all_activity_ids_streams(\"strava_data.db\"))} to go!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
